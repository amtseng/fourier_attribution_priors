import h5py
import os
import numpy as np
import tqdm
from collections import OrderedDict
import modisco
import click

def import_shap_scores(shap_scores_hdf5, center_cut_size=None):
    """
    Imports the SHAP scores generated/saved by `make_shap_scores.py`, and
    returns the hypothetical importance scores, actual importance scores, and
    one-hot encoded sequences.
    Arguments:
        `shap_scores_hdf5`: path to HDF5 of SHAP scores generated by
            `make_shap_scores.py`
        `center_cut_size`: if specified, keeps only scores/sequences of this
            centered length; by default uses the entire length given in the
            SHAP scores
    Returns the hypothetical importance scores, actual importance scores, and
    corresponding one-hot encoded input sequences. Each is an N x L x 4 array,
    where L is the cut size (or default size).
    """
    score_reader = h5py.File(shap_scores_hdf5, "r")

    # For defining shapes
    num_seqs, input_length, _ = score_reader["hyp_scores"].shape
    if not center_cut_size:
        center_cut_size = input_length
    cut_start = (input_length // 2) - (center_cut_size // 2)
    cut_end = cut_start + center_cut_size

    # For batching up data loading
    batch_size = min(1000, num_seqs)
    num_batches = int(np.ceil(num_seqs / batch_size))

    # Read in hypothetical scores and input sequences in batches
    hyp_scores = np.empty((num_seqs, center_cut_size, 4))
    act_scores = np.empty((num_seqs, center_cut_size, 4))
    one_hot_seqs = np.empty((num_seqs, center_cut_size, 4))

    for i in tqdm.trange(num_batches, desc="Importing SHAP scores"):
        batch_slice = slice(i * batch_size, (i + 1) * batch_size)
        hyp_score_batch = score_reader["hyp_scores"][
            batch_slice, cut_start:cut_end
        ]
        one_hot_seq_batch = score_reader["one_hot_seqs"][
            batch_slice, cut_start:cut_end
        ]
        hyp_scores[batch_slice] = hyp_score_batch
        one_hot_seqs[batch_slice] = one_hot_seq_batch
        act_scores[batch_slice] = hyp_score_batch * one_hot_seq_batch

    score_reader.close()
    
    return hyp_scores, act_scores, one_hot_seqs


@click.command()
@click.argument("shap_scores_hdf5", nargs=1)
@click.option(
    "--outfile", "-o", required=True,
    help="Where to store the HDF5 with TF-MoDISco results"
)
@click.option(
    "--seqlet-outfile", "-s", default=None,
    help="If specified, save the seqlets here in a FASTA file"
)
@click.option(
    "--center-cut-size", "-c", default=None,
    help="Size of central input sequence to run TF-MoDISco on; by default uses the whole sequence"
)
def main(shap_scores_hdf5, outfile, seqlet_outfile, center_cut_size):
    """
    Takes the set of importance scores generated by `make_shap_scores.py` and
    runs TF-MoDISco on them.
    """
    if center_cut_size:
        center_cut_size = int(center_cut_size)

    hyp_scores, act_scores, input_seqs = import_shap_scores(
        shap_scores_hdf5, center_cut_size
    )
    task_to_hyp_scores, task_to_act_scores = OrderedDict(), OrderedDict()
    task_to_hyp_scores["task0"] = hyp_scores
    task_to_act_scores["task0"] = act_scores

    # Construct workflow pipeline
    tfm_workflow = modisco.tfmodisco_workflow.workflow.TfModiscoWorkflow(
    	sliding_window_size=15,
    	flank_size=5,
        target_seqlet_fdr=0.05,
    	seqlets_to_patterns_factory=modisco.tfmodisco_workflow.seqlets_to_patterns.TfModiscoSeqletsToPatternsFactory(
    	    trim_to_window_size=15,
    	    initial_flank_to_add=5,
    	    kmer_len=5,
    	    num_gaps=1,
    	    num_mismatches=0,
    	    final_min_cluster_size=60
    	)
    )

    # Move to output directory to do work
    cwd = os.getcwd()
    os.makedirs(os.path.dirname(outfile), exist_ok=True)
    os.chdir(os.path.dirname(outfile))

    tfm_results = tfm_workflow(
        task_names=list(task_to_act_scores.keys()),
        contrib_scores=task_to_act_scores,
        hypothetical_contribs=task_to_hyp_scores,
        one_hot=input_seqs
    )

    os.chdir(cwd)
    print("Saving results to %s" % outfile)
    with h5py.File(outfile, "w") as f:
        tfm_results.save_hdf5(f)

    if seqlet_outfile:
        print("Saving seqlets to %s" % seqlet_outfile)
        seqlets = \
            tfm_results.metacluster_idx_to_submetacluster_results[0].seqlets
        bases = np.array(["A", "C", "G", "T"])
        with open(seqlet_outfile, "w") as f:
            for seqlet in seqlets:
                sequence = "".join(
                    bases[np.argmax(seqlet["sequence"].fwd, axis=-1)]
                )
                example_index = seqlet.coor.example_idx
                start, end = seqlet.coor.start, seqlet.coor.end
                f.write(">example%d:%d-%d\n" % (example_index, start, end))
                f.write(sequence + "\n")


if __name__ == "__main__":
    main()
