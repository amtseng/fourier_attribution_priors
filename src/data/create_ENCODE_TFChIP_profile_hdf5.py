import os
import h5py
import pyBigWig
import numpy as np
import tqdm
import click

def fetch_bigwig_paths(base_path, tf_name, tf_cont_mapping_path):
    """
    Reads in the set of BigWig paths corresponding to TF-ChIPseq profiles and
    control profiles. These BigWigs should be generated by
    `generate_ENCODE_profile_labels.sh`. This function performs error-checking
    to ensure that the proper files are there under `base_path`.
    Arguments:
        `base_path`: path containing the BigWig profiles
        `tf_name`: name of the TF (i.e. the profiles for the TF-ChIPseq runs
            should start with this name)
        `tf_cont_mapping_path`: path to TSV mapping TF-ChIPseq experiment IDs
            to their matched control ChIPseq experiment IDs
    Returns a list of pairs, where each pair is the BigWig tracks for the
    negative and positive strands (in that order). The first half of this
    list-of-pairs is for the TF-ChIPseq profiles, and the second half are the
    corresponding control profiles. The BigWigs are ordered such that the
    TF-ChIPseq experiment IDs are in sorted order, and the control experiment
    IDs are in a parallel matched order.
    """
    tf_cont_mapping = {}
    with open(tf_cont_mapping_path, "r") as f:
        for line in f:
            tokens = line.strip().split("\t")
            tf_cont_mapping[tokens[0]] = tokens[1]  # Map TF ID to control ID

    bigwig_list = [
        item for item in os.listdir(base_path) if item.endswith(".bw")
    ]

    # Read in names, organizing into
    # tf_name/control : experiment/cell line : strand
    bigwig_dict = {}
    for name in bigwig_list:
        tokens = name[:-3].split("_")
        assert len(tokens) == 4, \
            "Found BigWig of improperly formatted name: %s" % name
        cond = tokens[0]
        expid_cline = (tokens[1], tokens[2])
        strand = tokens[3]
        assert cond in (tf_name, "control"), \
            "Found BigWig not of type %s or control" % tf_name
        assert strand in ("neg", "pos"), "Found BigWig of strand other than pos/neg"
    
        if cond not in bigwig_dict:
            bigwig_dict[cond] = {}
        if expid_cline not in bigwig_dict[cond]:
            bigwig_dict[cond][expid_cline] = {}
        assert strand not in bigwig_dict[cond][expid_cline], \
            "Found duplicate BigWig for %s, %s, %s" % \
            (cond, expid_cline, strand)
        bigwig_dict[cond][expid_cline][strand] = os.path.join(base_path, name)

    # Verify that the expected conditions, experiments/cell lines, and strands
    # are all present
    assert sorted(bigwig_dict.keys()) == sorted([tf_name, "control"]), \
        "Did not find tracks for both %s and control" % tf_name

    tf_clines = sorted([pair[1] for pair in bigwig_dict[tf_name].keys()])
    cont_clines = sorted([pair[1] for pair in bigwig_dict["control"].keys()])
    assert tf_clines == cont_clines, \
        "Did not have same cell lines for %s and control" %  tf_name
   
    for cond, cond_dict in bigwig_dict.items():
        for expid_cline, expid_cline_dict in cond_dict.items():
            assert sorted(expid_cline_dict.keys()) == ["neg", "pos"], \
                "Did not find both strands for %s, %s" % (cond, expid_cline)

    # Reformat dictionary into list of pairs
    paths = []
    tf_expids = []
    for expid_cline in sorted(bigwig_dict[tf_name].keys(), key=lambda p: p[0]):
        expid = expid_cline[0]
        assert expid in tf_cont_mapping.keys(), \
            "Did not find %s as TF-ChIPseq experiment in mapping" % expid
        strand_dict = bigwig_dict[tf_name][expid_cline]
        paths.append([strand_dict["neg"], strand_dict["pos"]])
        tf_expids.append(expid)
    assert len(tf_expids) == len(set(tf_expids)), \
        "Found duplicate TF-ChIPseq experiment IDs"
    for tf_expid in tf_expids:
        try:
            cont_expid = tf_cont_mapping[tf_expid]
        except KeyError:
            raise ValueError("Did not find mapped control for %s" % tf_expid)
        expid_cline = [
            key for key in bigwig_dict["control"] if key[0] == cont_expid
        ]
        assert len(expid_cline) == 1, \
            "Did not find exactly 1 experiment for mapped control %s" % \
            cont_expid
        strand_dict = bigwig_dict["control"][expid_cline[0]]
        paths.append([strand_dict["neg"], strand_dict["pos"]])

    return paths


def create_hdf5(
    bigwig_paths, chrom_sizes_path, out_path, chunk_size, batch_size=100
):
    """
    Creates an HDF5 file containing all BigWig tracks.
    Arguments:
        `bigwig_paths`: a list of pairs of paths, as returned by
            `fetch_bigwig_paths`
        `chrom_sizes_path`: path to canonical chromosome sizes
        `out_path`: where to write the HDF5
        `chunk_size`: chunk size to use in HDF5 along the chromosome size
            dimension; this is recommended to be the expected size of the
            queries made
        `batch_size`: number of chunks to write at a time
    This creates an HDF5 file, containing a dataset for each chromosome. Each
    dataset will be a large array of shape L x 2T x 2, where L is the length of
    the chromosome, T is the number of tasks (i.e. T experiment/cell lines, one
    for each TF and one for matched control), 2 is for both strands. The HDF5
    will also contain a dataset which has the paths to the corresponding source
    BigWigs, stored as a 2T x 2 array of paths.
    """
    bigwig_readers = [
        [pyBigWig.open(path1), pyBigWig.open(path2)]
        for path1, path2 in bigwig_paths
    ]
   
    # Read in chromosome sizes
    with open(chrom_sizes_path, "r") as f:
        chrom_sizes = {}
        for line in f:
            tokens = line.strip().split("\t")
            chrom_sizes[tokens[0]] = int(tokens[1])
   
    # Convert batch size to be in terms of rows, not number of chunks
    batch_size = batch_size * chunk_size

    with h5py.File(out_path, "w") as f:
        # Store source paths
        f.create_dataset("bigwig_paths", data=np.array(bigwig_paths, dtype="S"))
        for chrom in sorted(chrom_sizes.keys()):
            chrom_size = chrom_sizes[chrom]
            num_batches = int(np.ceil(chrom_size / batch_size))
            chrom_dset = f.create_dataset(
                chrom, (chrom_size, len(bigwig_paths), 2), dtype="f",
                compression="gzip", chunks=(chunk_size, len(bigwig_paths), 2)
            )
            for i in tqdm.trange(num_batches, desc=chrom):
                start = i * batch_size
                end = min(chrom_size, (i + 1) * batch_size)

                values = np.stack([
                    np.stack([
                        np.nan_to_num(reader1.values(chrom, start, end)),
                        np.nan_to_num(reader2.values(chrom, start, end))
                    ], axis=1) for reader1, reader2 in bigwig_readers
                ], axis=1)

                chrom_dset[start : end] = values

@click.command()
@click.option(
    "--tf-name", "-t", required=True,
    help="Name of TF, needs to match prefix of TF-ChIPseq BigWig files"
)
@click.option(
    "--base-path", "-b", default=None,
    help="Path to directory containing BigWigs; defaults to /users/amtseng/att_priors/data/interim/ENCODE_TFChIP/profile/{tf_name}/"
)
@click.option(
    "--tf-cont-mapping-path", "-m", default=None,
    help="Path to mapping between TF-ChIPseq and control ChIPseq experiment IDs; defaults to /users/amtseng/att_priors/data/raw/ENCODE_TFChIP/{tf_name}/tf_cont_mapping.tsv"
)
@click.option(
    "--chrom-sizes-path", "-c",
    default="/users/amtseng/genomes/hg38.canon.chrom.sizes",
    help="Path to canonical chromosome sizes"
)
@click.option(
    "--out-path", "-o", default=None,
    help="Destination for new HDF5; defaults to /users/amtseng/att_priors/data/processed/ENCODE_TFChIP/profile/labels/{tf_name}/{tf_name}_profiles.h5"
)
@click.option(
    "--chunk-size", "-s", default=1500,
    help="Chunk size along chromosome length dimension for HDF5"
)
def main(
    tf_name, base_path, tf_cont_mapping_path, chrom_sizes_path, out_path,
    chunk_size
):
    """
    Converts TF-ChIPseq and control ChIPseq profile BigWigs into an HDF5 file.
    HDF5 has separate datasets for each chromosome. Each chromosome's dataset
    is stored as an L x 2T x 2 array, where L is the size of the chromosome,
    T is the number of matched experiments (i.e. tasks), and 2 is for each
    strand. The dataset under the key `bigwig_paths` stores the paths for the
    source BigWigs.
    """
    if not base_path: 
        base_path = "/users/amtseng/att_priors/data/interim/ENCODE_TFChIP/profile/%s" % tf_name
    if not tf_cont_mapping_path:
        tf_cont_mapping_path = \
            "/users/amtseng/att_priors/data/raw/ENCODE_TFChIP/%s/tf_cont_mapping.tsv" % tf_name
    if not out_path:
        out_path = \
            "/users/amtseng/att_priors/data/processed/ENCODE_TFChIP/profile/labels/%s/%s_profiles.h5" % (tf_name, tf_name)

    bigwig_paths = fetch_bigwig_paths(base_path, tf_name, tf_cont_mapping_path)
    print("Found %d matched experiments/tasks" % (len(bigwig_paths) // 2))
    create_hdf5(bigwig_paths, chrom_sizes_path, out_path, chunk_size)


if __name__ == "__main__":
    main()
