{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../src/\"))\n",
    "import model.util as model_util\n",
    "import model.profile_models as profile_models\n",
    "import model.binary_models as binary_models\n",
    "import extract.data_loading as data_loading\n",
    "import extract.compute_predictions as compute_predictions\n",
    "import extract.compute_shap as compute_shap\n",
    "import plot.viz_sequence as viz_sequence\n",
    "import pyBigWig\n",
    "import torch\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "import scipy.stats\n",
    "import json\n",
    "import tqdm\n",
    "import h5py\n",
    "tqdm.tqdm_notebook()  # It is necessary to call this before the tqdm.notebook submodule is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting defaults\n",
    "font_manager.fontManager.ttflist.extend(\n",
    "    font_manager.createFontList(\n",
    "        font_manager.findSystemFonts(fontpaths=\"/users/amtseng/modules/fonts\")\n",
    "    )\n",
    ")\n",
    "plot_params = {\n",
    "    \"figure.titlesize\": 22,\n",
    "    \"axes.titlesize\": 22,\n",
    "    \"axes.labelsize\": 20,\n",
    "    \"legend.fontsize\": 18,\n",
    "    \"xtick.labelsize\": 16,\n",
    "    \"ytick.labelsize\": 16,\n",
    "    \"font.family\": \"Roboto\",\n",
    "    \"font.weight\": \"bold\"\n",
    "}\n",
    "plt.rcParams.update(plot_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define paths for the model and data of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"binary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared paths/constants\n",
    "raw_data_base_path = \"/users/amtseng/att_priors/data/raw/\"\n",
    "proc_data_base_path = \"/users/amtseng/att_priors/data/processed/\"\n",
    "model_base_path = \"/users/amtseng/att_priors/models/trained_models/%s/\" % model_type\n",
    "tfm_results_path = \"/users/amtseng/att_priors/results/tfmodisco/%s/\" % model_type\n",
    "chrom_set = [\"chr1\"]\n",
    "input_length = 1346 if model_type == \"profile\" else 1000\n",
    "profile_length = 1000\n",
    "reference_fasta = \"/users/amtseng/genomes/mm10.fasta\"\n",
    "chrom_sizes = \"/users/amtseng/genomes/mm10.canon.chrom.sizes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BPNet\n",
    "condition_name = \"BPNet\"\n",
    "files_spec_path = os.path.join(proc_data_base_path, \"BPNet_ChIPseq/%s/config/BPNet_training_paths.json\" % model_type)\n",
    "num_tasks = 3\n",
    "num_strands = 2\n",
    "if model_type == \"profile\":\n",
    "    controls = \"shared\"\n",
    "    model_class = profile_models.ProfilePredictorWithSharedControls\n",
    "else:\n",
    "    model_class = binary_models.BinaryPredictor\n",
    "\n",
    "bpnet_tasks = [\"Nanog\", \"Oct4\", \"Sox2\"]\n",
    "task_index = None\n",
    "\n",
    "if task_index is None:\n",
    "    footprints_paths = [\n",
    "        os.path.join(raw_data_base_path, \"BPNet_ChIPnexus/BPNet_%s_peaks-idr.bed.gz\" % task.upper())\n",
    "        for task in bpnet_tasks\n",
    "    ]\n",
    "    pos_bigwigs = [\n",
    "        os.path.join(raw_data_base_path, \"BPNet_ChIPnexus/BPNet_%s_pos.bw\" % task.upper())\n",
    "        for task in bpnet_tasks\n",
    "    ]\n",
    "    neg_bigwigs = [\n",
    "        os.path.join(raw_data_base_path, \"BPNet_ChIPnexus/BPNet_%s_neg.bw\" % task.upper())\n",
    "        for task in bpnet_tasks\n",
    "    ]\n",
    "else:\n",
    "    footprints_paths = [os.path.join(raw_data_base_path, \"BPNet_ChIPnexus/BPNet_%s_peaks-idr.bed.gz\" % bpnet_tasks[task_index].upper())]\n",
    "    pos_bigwigs = [os.path.join(raw_data_base_path, \"BPNet_ChIPnexus/BPNet_%s_pos.bw\" % bpnet_tasks[task_index].upper())]\n",
    "    neg_bigwigs = [os.path.join(raw_data_base_path, \"BPNet_ChIPnexus/BPNet_%s_neg.bw\" % bpnet_tasks[task_index].upper())]\n",
    "# noprior_model_path = os.path.join(model_base_path, \"BPNet/20/model_ckpt_epoch_18.pt\")\n",
    "# prior_model_path = os.path.join(model_base_path, \"BPNet_prior/25/model_ckpt_epoch_17.pt\")\n",
    "# noprior_tfm_path = os.path.join(tfm_results_path, \"BPNet/BPNet_r20_e18_task%s_tfm.h5\" % (\"agg\" if task_index is None else str(task_index)))\n",
    "# prior_tfm_path = os.path.join(tfm_results_path, \"BPNet/BPNet_prior_r25_e17_task%s_tfm.h5\" % (\"agg\" if task_index is None else str(task_index)))\n",
    "noprior_model_path = os.path.join(model_base_path, \"BPNet/22/model_ckpt_epoch_1.pt\")\n",
    "prior_model_path = os.path.join(model_base_path, \"BPNet_prior/27/model_ckpt_epoch_11.pt\")\n",
    "noprior_tfm_path = os.path.join(tfm_results_path, \"BPNet/BPNet_r22_e1_task%s_tfm.h5\" % (\"agg\" if task_index is None else str(task_index)))\n",
    "prior_tfm_path = os.path.join(tfm_results_path, \"BPNet/BPNet_prior_r27_e11_task%s_tfm.h5\" % (\"agg\" if task_index is None else str(task_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(True)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "def restore_model(model_path):\n",
    "    model = model_util.restore_model(model_class, model_path)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model without priors\n",
    "noprior_model = restore_model(noprior_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model with priors\n",
    "prior_model = restore_model(prior_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import footprits\n",
    "For BPNet, use the ChIP-nexus peaks, which can act as an easy proxy for footprints, althought they are very wide footprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "footprints = [\n",
    "    pd.read_csv(\n",
    "        path, sep=\"\\t\", header=None,\n",
    "        names=[\n",
    "            \"chrom\", \"peak_start\", \"peak_end\", \"name\", \"score\", \"strand\",\n",
    "            \"signal\", \"pval\", \"qval\", \"summit_offset\"\n",
    "        ]\n",
    "    )\n",
    "    for path in footprints_paths\n",
    "]\n",
    "footprints = pd.concat(footprints)\n",
    "footprints = footprints[footprints[\"chrom\"].isin(chrom_set)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create reader for BigWigs\n",
    "Only for something like BPNet, which has ChIP-nexus profiles, which offer a \"continuous\" view of footprint confidence, rather than a simple binary footprint classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_profiles(chrom, start, end):\n",
    "    \"\"\"\n",
    "    Returns N-array of BigWig values, as sum of negative and positive strands.\n",
    "    \"\"\"\n",
    "    result = np.zeros((end - start, 2))\n",
    "    for i in range(len(neg_bigwigs)):\n",
    "        with pyBigWig.open(neg_bigwigs[i], \"r\") as f:\n",
    "            result[:, 0] = f.values(chrom, start, end)\n",
    "        with pyBigWig.open(pos_bigwigs[i], \"r\") as f:\n",
    "            result[:, 1] = f.values(chrom, start, end)\n",
    "    return np.sum(np.nan_to_num(result), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "Create an input data loader, that maps coordinates or bin indices to data needed for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type == \"profile\":\n",
    "    input_func = data_loading.get_profile_input_func(\n",
    "        files_spec_path, input_length, profile_length, reference_fasta\n",
    "    )\n",
    "    pos_set = data_loading.get_positive_profile_coords(\n",
    "        files_spec_path, task_ind=task_index, chrom_set=chrom_set\n",
    "    )\n",
    "else:\n",
    "    input_func = data_loading.get_binary_input_func(\n",
    "        files_spec_path, input_length, reference_fasta\n",
    "    )\n",
    "    pos_set = data_loading.get_positive_binary_bins(\n",
    "        files_spec_path, task_ind=task_index, chrom_set=chrom_set\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradients(model, sample):\n",
    "    \"\"\"\n",
    "    Given an array of N coordinates or bins, computes the input gradients\n",
    "    for the model, returning an N x I x 4 array of gradient values and an\n",
    "    N x I x 4 array of one-hot encoded sequence.\n",
    "    \"\"\"\n",
    "    if model_type == \"profile\":\n",
    "        results = compute_predictions.get_profile_model_predictions(                                              \n",
    "            model, sample, num_tasks, input_func, controls=controls,                        \n",
    "            return_losses=False, return_gradients=True, show_progress=True                                         \n",
    "        )\n",
    "    else:\n",
    "        results = compute_predictions.get_binary_model_predictions(                                              \n",
    "            model, sample, input_func,                      \n",
    "            return_losses=False, return_gradients=True, show_progress=True                                         \n",
    "        )\n",
    "    return results[\"input_grads\"], results[\"input_seqs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_shap_scores(model, sample, batch_size=128):\n",
    "    \"\"\"\n",
    "    Given an array of N coordinates or bins, computes the SHAP scores\n",
    "    for the model, returning an N x I x 4 array of SHAP scores and an\n",
    "    N x I x 4 array of one-hot encoded sequence.\n",
    "    \"\"\"\n",
    "    num_samples = len(sample)\n",
    "    num_batches = int(np.ceil(num_samples / batch_size))\n",
    "    \n",
    "    all_shap_scores = np.empty((num_samples, input_length, 4))\n",
    "    all_one_hot_seqs = np.empty((num_samples, input_length, 4))\n",
    "        \n",
    "    if model_type == \"profile\":\n",
    "        shap_explainer = compute_shap.create_profile_explainer(\n",
    "            model, input_length, profile_length, num_tasks, num_strands, controls,\n",
    "            task_index=task_index\n",
    "        )\n",
    "    else:\n",
    "        shap_explainer = compute_shap.create_binary_explainer(\n",
    "            model, input_length, task_index=task_index\n",
    "        )\n",
    "\n",
    "    for i in tqdm.notebook.trange(num_batches):\n",
    "        batch_slice = slice(i * batch_size, (i + 1) * batch_size)\n",
    "        batch = sample[batch_slice]\n",
    "\n",
    "        if model_type == \"profile\":\n",
    "            input_seqs, profiles = input_func(batch)\n",
    "            shap_scores = shap_explainer(\n",
    "                input_seqs, cont_profs=profiles[:, num_tasks:], hide_shap_output=True\n",
    "            )\n",
    "        else:\n",
    "            input_seqs, _, _ = input_func(batch)\n",
    "            shap_scores = shap_explainer(\n",
    "                input_seqs, hide_shap_output=True\n",
    "            )\n",
    "\n",
    "        all_shap_scores[batch_slice] = shap_scores\n",
    "        all_one_hot_seqs[batch_slice] = input_seqs\n",
    "    return all_shap_scores, all_one_hot_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "rng = np.random.RandomState(20200318)\n",
    "sample = pos_set[rng.choice(len(pos_set), size=num_samples, replace=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get coordinates for the sample\n",
    "if model_type == \"profile\":\n",
    "    # For profile models, add a random jitter to avoid center-bias\n",
    "    jitters = np.random.randint(-128, 128 + 1, size=len(sample))\n",
    "    sample[:, 1] = sample[:, 1] + jitters\n",
    "    sample[:, 2] = sample[:, 2] + jitters\n",
    "    sample_coords = sample\n",
    "else:\n",
    "    sample_coords = input_func(sample)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the importance scores and 1-hot seqs\n",
    "imp_type = (\"DeepSHAP scores\", \"input gradients\")[0]\n",
    "imp_func = compute_shap_scores if imp_type == \"DeepSHAP scores\" else compute_gradients\n",
    "noprior_imp_scores, sample_input_seqs = imp_func(\n",
    "    noprior_model, sample\n",
    ")\n",
    "prior_imp_scores, _ = imp_func(\n",
    "    prior_model, sample\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the coordinates on both sides symmetrically to make them `input_length` \n",
    "centers = (sample_coords[:, 1] + sample_coords[:, 2]) // 2\n",
    "starts = centers - (input_length // 2)\n",
    "ends = starts + input_length\n",
    "sample_coords[:, 1] = starts\n",
    "sample_coords[:, 2] = ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot out a few examples\n",
    "for i in np.random.choice(num_samples, size=3, replace=False):\n",
    "    print(i, sample[i])\n",
    "    print(\"=========================\")\n",
    "    print(\"Without priors:\")\n",
    "    plt.figure(figsize=(20, 2))\n",
    "    plt.plot(np.sum(noprior_imp_scores[i] * sample_input_seqs[i], axis=1))\n",
    "    plt.show()\n",
    "    print(\"With priors:\")\n",
    "    plt.figure(figsize=(20, 2))\n",
    "    plt.plot(np.sum(prior_imp_scores[i] * sample_input_seqs[i], axis=1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantify agreement of importances with footprints using overlap\n",
    "In each importance score track (over the entire input region), do the importances tend to be elevated more in known footprints?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_footprint_overlap_amount(coords, score_tracks, footprints):\n",
    "    \"\"\"\n",
    "    From an N x 3 object array of coordinates, a parallel N x I x 4 array\n",
    "    of score tracks, and a table of imported footprints, this function computes\n",
    "    and returns the overlap amount for each of the N examples, where the overlap\n",
    "    for an example is the fraction of score magnitudes in its track that fall\n",
    "    within a footprint. An overlap will be NaN if there are no footprints in the\n",
    "    coordinate. Returns an N-array.\n",
    "    \"\"\"\n",
    "    score_tracks = np.abs(score_tracks)  # Take absolute value of score tracks\n",
    "    overlaps = np.empty(len(coords))\n",
    "    for i in tqdm.notebook.trange(len(coords)):\n",
    "        chrom, start, end = coords[i]\n",
    "        # Filter down the set of footprints to only those that overlap with the\n",
    "        # coordinate\n",
    "        fps = footprints[\n",
    "            (footprints[\"chrom\"] == chrom) & (footprints[\"peak_start\"] <= end) & \\\n",
    "            (start <= footprints[\"peak_end\"])\n",
    "        ]\n",
    "        mask = np.zeros(end - start, dtype=bool)\n",
    "        intervals = fps[[\"peak_start\", \"peak_end\"]].values - start\n",
    "        for interval in intervals:\n",
    "            mask[interval[0]:interval[1]] = True\n",
    "        if not np.sum(mask):\n",
    "            overlaps[i] = np.nan\n",
    "        else:\n",
    "            overlaps[i] = np.sum(score_tracks[i][mask]) / np.sum(score_tracks[i])\n",
    "    return overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noprior_imp_fp_overlaps = compute_footprint_overlap_amount(\n",
    "    sample_coords, noprior_imp_scores * sample_input_seqs, footprints\n",
    ")\n",
    "prior_imp_fp_overlaps = compute_footprint_overlap_amount(\n",
    "    sample_coords, prior_imp_scores * sample_input_seqs, footprints\n",
    ")\n",
    "\n",
    "# Remove the NaNs, which is where no footprint was in the coordinate\n",
    "noprior_imp_fp_overlaps = noprior_imp_fp_overlaps[np.isfinite(noprior_imp_fp_overlaps)]\n",
    "prior_imp_fp_overlaps = prior_imp_fp_overlaps[np.isfinite(prior_imp_fp_overlaps)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_num = 30\n",
    "all_vals = np.concatenate([noprior_imp_fp_overlaps, prior_imp_fp_overlaps])\n",
    "bins = np.linspace(np.min(all_vals), np.max(all_vals), bin_num)\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "ax.hist(noprior_imp_fp_overlaps, bins=bins, color=\"coral\", label=\"No prior\", alpha=0.7)\n",
    "ax.hist(prior_imp_fp_overlaps, bins=bins, color=\"slateblue\", label=\"With Fourier prior\", alpha=0.7)\n",
    "plt.legend()\n",
    "title = \"Histogram of %s overlap with BPNet %s ChIP-nexus peaks\" % (imp_type, \"aggregated\" if task_index is None else bpnet_tasks[task_index])\n",
    "title += \"\\n%s %s models\" % (condition_name, model_type)\n",
    "title += \"\\nComputed on %d randomly drawn test peaks\" % num_samples\n",
    "plt.title(title)\n",
    "plt.xlabel(\"Proportion of importance in footprints\")\n",
    "\n",
    "print(\"Average score without priors: %f\" % np.nanmean(noprior_imp_fp_overlaps))\n",
    "print(\"Average score with priors: %f\" % np.nanmean(prior_imp_fp_overlaps))\n",
    "print(\"Standard error without priors: %f\" % scipy.stats.sem(noprior_imp_fp_overlaps))\n",
    "print(\"Standard error with priors: %f\" % scipy.stats.sem(prior_imp_fp_overlaps))\n",
    "w, p = scipy.stats.wilcoxon(prior_imp_fp_overlaps, noprior_imp_fp_overlaps, alternative=\"greater\")\n",
    "print(\"One-sided Wilcoxon test: W = %f, p = %f\" % (w, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.scatter(noprior_imp_fp_overlaps, prior_imp_fp_overlaps, color=\"mediumorchid\", alpha=0.5)\n",
    "title = \"Pairwise comparison of %s overlap with BPNet %s ChIP-nexus peaks\" % (imp_type, \"aggregated\" if task_index is None else bpnet_tasks[task_index])\n",
    "title += \"\\n%s %s models\" % (condition_name, model_type)\n",
    "title += \"\\nComputed on %d randomly drawn test peaks\" % num_samples\n",
    "plt.title(title)\n",
    "limits = [\n",
    "    np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "    np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "]\n",
    "ax.plot(limits, limits, \"--\", alpha=0.5, color=\"black\")\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.set_xlim(limits)\n",
    "ax.set_ylim(limits)\n",
    "plt.xlabel(\"Proportion of importance in footprints without prior\")\n",
    "plt.ylabel(\"Proportion of importance in footprints with Fourier prior\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantify agreement of importance windows with footprints using ranks\n",
    "Rank all of the windows by importance; do the windows at the top tend to overlap with footprints?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_single_footprint_overlap_mask(chrom, start, end, footprints):\n",
    "    \"\"\"\n",
    "    Given a coordinate, returns a boolean mask for that coordinate\n",
    "    for which bases lie within a footprint\n",
    "    \"\"\"\n",
    "    mask = np.zeros(end - start, dtype=bool)\n",
    "    for peak_bed in peak_beds:\n",
    "        rows = footprints[\n",
    "            (footprints[\"chrom\"] == chrom) & (footprints[\"peak_start\"] <= end) & \\\n",
    "            (start <= footprints[\"peak_end\"])\n",
    "        ]\n",
    "        intervals = rows[[\"peak_start\", \"peak_end\"]].values - start\n",
    "        for interval in intervals:\n",
    "            mask[interval[0]:interval[1]] = True\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_single_footprint_overlap_mask(chrom, start, end, footprints):\n",
    "    \"\"\"\n",
    "    Given a coordinate, returns a boolean mask for that coordinate\n",
    "    for which bases lie within a footprint\n",
    "    \"\"\"\n",
    "    mask = np.zeros(end - start, dtype=bool)\n",
    "    rows = footprints[\n",
    "        (footprints[\"chrom\"] == chrom) & (footprints[\"peak_start\"] <= end) & \\\n",
    "        (start <= footprints[\"peak_end\"])\n",
    "    ]\n",
    "    intervals = rows[[\"peak_start\", \"peak_end\"]].values - start\n",
    "    for interval in intervals:\n",
    "        mask[interval[0]:interval[1]] = True\n",
    "    return mask\n",
    "\n",
    "def compute_footprint_overlap_mask(coords, footprints):\n",
    "    \"\"\"\n",
    "    Given a sample of N coordinates or bins, extracts a boolean mask\n",
    "    denoting which locations in each sample overlap a footprint.\n",
    "    Returns an N x I boolean array, where each subarray is a boolean mask\n",
    "    for which bases in that coordinate lie within a footprint.\n",
    "    \"\"\"\n",
    "    masks = []\n",
    "    for coord in tqdm.notebook.tqdm(coords):\n",
    "        # Pad to profile length\n",
    "        masks.append(compute_single_footprint_overlap_mask(coord[0], coord[1], coord[2], footprints))\n",
    "    return np.stack(masks, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_windowed_footprint_overlap_mask(scores, one_hot_seqs, seq_footprint_masks, window_size=10):\n",
    "    \"\"\"\n",
    "    Windowing by `window_size`, computes the total importance magnitude for the\n",
    "    actual importance in each window, and identifies which windows overlap a footprint.\n",
    "    Returns a boolean NumPy array denoting which windows overlap a peak, sorted in\n",
    "    descending order of window importance, and the indices of each window. This requires\n",
    "    a mask of whether or not each base in each input sequence overlaps a footprint,\n",
    "    computed by `compute_footprint_overlap_mask`.\n",
    "    \"\"\"\n",
    "    num_samples = len(scores)\n",
    "    all_window_imps, all_footprint_masks = [], []\n",
    "    all_window_inds = []\n",
    "    for i in tqdm.notebook.trange(num_samples):\n",
    "        score_track = np.sum(np.abs(scores[i] * one_hot_seqs[i]), axis=1)  # Actual importance\n",
    "        num_windows = len(score_track) - window_size + 1\n",
    "        \n",
    "        # Compute windowed peak mask\n",
    "        window_locs = np.arange(num_windows) + ((len(score_track) - num_windows) / 2)\n",
    "        windowed_footprint_mask = seq_footprint_masks[i][window_locs.astype(int)]\n",
    "        \n",
    "        # Compute sum of importance in each window\n",
    "        importances = np.empty(num_windows)\n",
    "        for j in range(num_windows):\n",
    "            importances[j] = np.sum(score_track[j : j + window_size])\n",
    "            all_window_inds.append([i, j])\n",
    "        \n",
    "        all_window_imps.append(importances)\n",
    "        all_footprint_masks.append(windowed_footprint_mask)\n",
    "    \n",
    "    window_imps, all_footprint_masks = np.concatenate(all_window_imps), np.concatenate(all_footprint_masks)\n",
    "    all_window_inds = np.stack(all_window_inds)\n",
    "    return all_footprint_masks[np.flip(np.argsort(window_imps))], all_window_inds[np.flip(np.argsort(window_imps))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normed_rank_enrichment(ordered_mask):\n",
    "    \"\"\"\n",
    "    From a binary mask array (in order from best to worst thresholds), computes\n",
    "    the rank enrichment at each threshold. Specifically, this computes a\n",
    "    normalized CDF of how many 1s are seen in the first k instances.\n",
    "    \"\"\"\n",
    "    cdf = np.cumsum(ordered_mask)\n",
    "    # To normalize, divide by the expectation if there all 1s were spread\n",
    "    # out evenly across the instances\n",
    "    expectation = np.sum(ordered_mask) / len(ordered_mask) * np.arange(1, len(cdf) + 1)\n",
    "    return cdf / expectation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "footprint_masks = compute_footprint_overlap_mask(sample_coords, footprints)\n",
    "noprior_window_overlap_mask, noprior_windows = compute_windowed_footprint_overlap_mask(\n",
    "    noprior_imp_scores, sample_input_seqs, footprint_masks, window_size=window_size\n",
    ")\n",
    "prior_window_overlap_mask, prior_windows = compute_windowed_footprint_overlap_mask(\n",
    "    prior_imp_scores, sample_input_seqs, footprint_masks, window_size=window_size\n",
    ")\n",
    "noprior_window_overlap_cdf = normed_rank_enrichment(noprior_window_overlap_mask)\n",
    "prior_window_overlap_cdf = normed_rank_enrichment(prior_window_overlap_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see what was missed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(indexes):\n",
    "    i, j = indexes\n",
    "    print(j)\n",
    "    print(sample_coords[i])\n",
    "    plt.figure(figsize=(20, 3))\n",
    "    plt.plot(np.sum(prior_imp_scores[i] * sample_input_seqs[i], axis=1))\n",
    "    plt.show()\n",
    "    viz_sequence.plot_weights(prior_imp_scores[i][j - 10: j + 10])\n",
    "    viz_sequence.plot_weights((prior_imp_scores[i] * sample_input_seqs[i])[j - 10: j + 10])\n",
    "    \n",
    "    plt.figure(figsize=(20, 3))\n",
    "    plt.plot(np.sum(noprior_imp_scores[i] * sample_input_seqs[i], axis=1))\n",
    "    plt.show()\n",
    "    viz_sequence.plot_weights(noprior_imp_scores[i][j - 10: j + 10])\n",
    "    viz_sequence.plot_weights((noprior_imp_scores[i] * sample_input_seqs[i])[j - 10: j + 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = np.where(~prior_window_overlap_mask[:1000])[0]\n",
    "print(inds)\n",
    "# show(prior_windows[750])\n",
    "# show(prior_windows[79])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all the missed sequences\n",
    "# save_file = \"/users/amtseng/att_priors/results/missed_seqlets/%s_%s_missed_seqlets.h5\" % (condition_name, model_type)\n",
    "# with h5py.File(save_file, \"w\") as f:\n",
    "#     f.create_dataset(\"input_seqs\", data=sample_input_seqs)\n",
    "#     f.create_dataset(\"prior_hyp_scores\", data=prior_imp_scores)\n",
    "#     f.create_dataset(\"noprior_hyp_scores\", data=noprior_imp_scores)\n",
    "#     f.create_dataset(\"prior_ranked_bases\", data=prior_windows)\n",
    "#     f.create_dataset(\"noprior_ranked_bases\", data=noprior_windows)\n",
    "#     f.create_dataset(\"prior_missed_inds\", data=np.where(~prior_window_overlap_mask)[0])\n",
    "#     f.create_dataset(\"noprior_missed_inds\", data=np.where(~noprior_window_overlap_mask)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(20, 10), sharex=True)\n",
    "title = \"Cumulative BPNet %s ChIP-nexus peak overlap over bases ranked by %s\" % (\"aggregated\" if task_index is None else bpnet_tasks[task_index], imp_type)\n",
    "title += \"\\n%s %s models\" % (condition_name, model_type)\n",
    "title += \"\\nComputed on %d randomly drawn test peaks\" % num_samples\n",
    "fig.suptitle(title)\n",
    "ax[0].plot(np.cumsum(noprior_window_overlap_mask), label=\"No prior\", color=\"coral\")\n",
    "ax[0].plot(np.cumsum(prior_window_overlap_mask), label=\"With Fourier prior\", color=\"slateblue\")\n",
    "ax[0].set_ylabel(\"Number of bases in footprints (x1000)\")\n",
    "ax[0].set_yticklabels((ax[0].get_yticks() / 1000).astype(int))\n",
    "ax[1].plot(noprior_window_overlap_cdf, label=\"No prior\", color=\"coral\")\n",
    "ax[1].plot(prior_window_overlap_cdf, label=\"With Fourier prior\", color=\"slateblue\")\n",
    "ax[1].set_ylabel(\"Enrichment of number of bases\")\n",
    "fig.text(0.45, 0.05, \"Top k bases by importance\", fontsize=18)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noprior_precis, noprior_recall, _ = sklearn.metrics.precision_recall_curve(\n",
    "    noprior_window_overlap_mask.astype(int),\n",
    "    np.flip(np.arange(len(noprior_window_overlap_mask))) / len(noprior_window_overlap_mask)\n",
    ")\n",
    "prior_precis, prior_recall, _ = sklearn.metrics.precision_recall_curve(\n",
    "    prior_window_overlap_mask.astype(int),\n",
    "    np.flip(np.arange(len(prior_window_overlap_mask))) / len(prior_window_overlap_mask)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "title = \"Precision - Recall of BPNet %s ChIP-nexus peak overlap over bases ranked by %s\" % (\"aggregated\" if task_index is None else bpnet_tasks[task_index], imp_type)\n",
    "title += \"\\n%s %s models\" % (condition_name, model_type)\n",
    "title += \"\\nComputed on %d randomly drawn test peaks\" % num_samples\n",
    "plt.title(title)\n",
    "plt.plot(noprior_recall[:-1], noprior_precis[:-1], color=\"coral\", label=\"No prior\")\n",
    "plt.plot(prior_recall[:-1], prior_precis[:-1], color=\"slateblue\", label=\"With Fourier prior\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend()\n",
    "\n",
    "print(\"auPRC without priors: %f\" % sklearn.metrics.auc(noprior_recall[:-1], noprior_precis[:-1]))\n",
    "print(\"auPRC with priors: %f\" % sklearn.metrics.auc(prior_recall[:-1], prior_precis[:-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantify agreement of importance windows with profile-derived footprints using ranks\n",
    "Rank all of the windows by importance; do the windows at the top tend to overlap with footprints? Instead of using pre-determined footprints, we use profile heights to binarize footprint classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_max_profile_heights(chrom, start, end, profile_func, flank_size=35):\n",
    "    \"\"\"\n",
    "    Given a coordinate, returns the maximum profile height within the given flank\n",
    "    size (to the left and right), for each base. Returns an array of size equal to\n",
    "    the size of the coordinate.\n",
    "    \"\"\"\n",
    "    max_heights = np.empty(end - start)\n",
    "    heights = profile_func(chrom, start - flank_size, end + flank_size)\n",
    "    for i in range(end - start):\n",
    "        max_heights[i] = np.max(heights[i : i + (flank_size * 2)])\n",
    "    return max_heights\n",
    "\n",
    "def compute_footprint_overlap_mask_by_profile(coords, profile_func, flank_size=35, quant_cutoff=0.9):\n",
    "    \"\"\"\n",
    "    Given an N x 3 object array of coordinates, extracts a boolean mask\n",
    "    denoting which locations in each sample overlap a footprint, based on\n",
    "    profile height. For each coordinate, this will look `flank_size` base pairs\n",
    "    left and right of each base pair and record the maximum profile height seen.\n",
    "    A base is deemed to overlie a footprint if its maximum profile height is in the\n",
    "    `quant_cutoff` percentile (default 90th percentile) over all given bases given.\n",
    "    Returns an N x I boolean array, where each subarray is a boolean mask for which\n",
    "    bases in that coordinate lie within a footprint based on the profile height.\n",
    "    \"\"\"\n",
    "    max_heights = []\n",
    "    for coord in tqdm.notebook.tqdm(coords):\n",
    "        max_heights.append(compute_max_profile_heights(coord[0], coord[1], coord[2], profile_func, flank_size))\n",
    "    max_heights = np.stack(max_heights, axis=0)\n",
    "    cutoff = np.sort(np.ravel(max_heights))[int(quant_cutoff * max_heights.size)]\n",
    "    return max_heights >= cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "footprint_masks_by_profile = compute_footprint_overlap_mask_by_profile(sample_coords, get_profiles)\n",
    "noprior_window_profoverlap_mask, noprior_windows = compute_windowed_footprint_overlap_mask(\n",
    "    noprior_imp_scores, sample_input_seqs, footprint_masks_by_profile, window_size=window_size\n",
    ")\n",
    "prior_window_profoverlap_mask, prior_windows = compute_windowed_footprint_overlap_mask(\n",
    "    prior_imp_scores, sample_input_seqs, footprint_masks_by_profile, window_size=window_size\n",
    ")\n",
    "noprior_window_profoverlap_cdf = normed_rank_enrichment(noprior_window_profoverlap_mask)\n",
    "prior_window_profoverlap_cdf = normed_rank_enrichment(prior_window_profoverlap_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert condition_name == \"BPNet\"\n",
    "top_limit = 10000\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20, 6))\n",
    "title = \"Cumulative BPNet %s ChIP-nexus peak overlap by profile height in top windows of size %d by %s\" % (\"aggregated\" if task_index is None else bpnet_tasks[task_index], window_size, imp_type)\n",
    "title += \"\\n%s %s models\" % (condition_name, model_type)\n",
    "title += \"\\nOver %d random test peaks\" % len(sample)\n",
    "fig.suptitle(title)\n",
    "ax[0].plot(np.cumsum(noprior_window_profoverlap_mask[:top_limit]), label=\"No prior\", color=\"red\")\n",
    "ax[0].plot(np.cumsum(prior_window_profoverlap_mask[:top_limit]), label=\"With Fourier prior\", color=\"blue\")\n",
    "ax[0].set_ylabel(\"Number of overlapping windows\")\n",
    "ax[1].plot(np.cumsum(noprior_window_profoverlap_mask), label=\"No prior\", color=\"red\")\n",
    "ax[1].plot(np.cumsum(prior_window_profoverlap_mask), label=\"With Fourier prior\", color=\"blue\")\n",
    "ax[1].set_ylabel(\"Number of overlapping windows\")\n",
    "ax[2].plot(noprior_window_profoverlap_cdf, label=\"No prior\", color=\"red\")\n",
    "ax[2].plot(prior_window_profoverlap_cdf, label=\"With Fourier prior\", color=\"blue\")\n",
    "ax[2].set_ylabel(\"Hypergeometric enrichment of number of overlapping windows\")\n",
    "fig.text(0.45, 0.05, \"Top k windows of importance\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the TF-MoDISco results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_freqs = np.array([0.27, 0.23, 0.23, 0.27])\n",
    "def pfm_info_content(pfm, pseudocount=0.001):\n",
    "    \"\"\"\n",
    "    Given an L x 4 PFM, computes information content for each base and\n",
    "    returns it as an L-array.\n",
    "    \"\"\"\n",
    "    num_bases = pfm.shape[1]\n",
    "    # Normalize track to probabilities along base axis\n",
    "    pfm_norm = (pfm + pseudocount) / (np.sum(pfm, axis=1, keepdims=True) + (num_bases * pseudocount))\n",
    "    ic = pfm_norm * np.log2(pfm_norm / np.expand_dims(background_freqs, axis=0))\n",
    "    return np.sum(ic, axis=1)\n",
    "\n",
    "def pfm_to_pwm(pfm, pseudocount=0.001):\n",
    "    \"\"\"\n",
    "    Converts and L x 4 PFM into an L x 4 PWM.\n",
    "    \"\"\"\n",
    "    num_bases = pfm.shape[1]\n",
    "    # Incorporate pseudocount by adding it to every element and renormalizing\n",
    "    pfm_norm = (pfm + pseudocount) / (np.sum(pfm, axis=1, keepdims=True) + (num_bases * pseudocount))\n",
    "    return np.log2(pfm_norm / np.expand_dims(background_freqs, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revcomp_motif(motif):\n",
    "    return np.flip(motif, axis=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_tfmodisco_motifs(\n",
    "    tfm_results_hdf5, min_seqlets=750, min_ic=0.6, ic_window=6, trim_flank_ic_frac=0.2,\n",
    "    plot_all_motifs=False, plot_passed_motifs=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Imports the TF-MoDISco motifs, and a final set of motifs, trimmed by info content.\n",
    "    The motifs returned must have at least `min_seqlets` supporting them, and there must\n",
    "    be a window of size `ic_window` with at IC at least `min_ic`. Finally, the resulting\n",
    "    motifs are trimmed by cutting off flanks whose base-level IC is below\n",
    "    `trim_flank_ic_frac` of the highest IC of the motif. This also only keeps motifs with\n",
    "    overall positive contributions (i.e. no negative seqlets).\n",
    "    Returns 2 parallel lists: a list of motif CWMs, and a list of motif PWMs.\n",
    "    \"\"\"\n",
    "    cwms, pwms = [], []\n",
    "    num_seqlets = []\n",
    "    with h5py.File(tfm_results_hdf5, \"r\") as f:\n",
    "        metaclusters = f[\"metacluster_idx_to_submetacluster_results\"]\n",
    "        num_metaclusters = len(metaclusters.keys())\n",
    "        for metacluster_i, metacluster_key in enumerate(metaclusters.keys()):\n",
    "            metacluster = metaclusters[metacluster_key]\n",
    "            if plot_all_motifs:\n",
    "                print(\"Metacluster: %s (%d/%d)\" % (metacluster_key, metacluster_i + 1, num_metaclusters))\n",
    "                print(\"==========================================\")\n",
    "            patterns = metacluster[\"seqlets_to_patterns_result\"][\"patterns\"]\n",
    "            num_patterns = len(patterns[\"all_pattern_names\"][:])\n",
    "            for pattern_i, pattern_name in enumerate(patterns[\"all_pattern_names\"][:]):\n",
    "                pattern_name = pattern_name.decode()\n",
    "                pattern = patterns[pattern_name]\n",
    "                seqlets = pattern[\"seqlets_and_alnmts\"][\"seqlets\"]\n",
    "                \n",
    "                if plot_all_motifs:\n",
    "                    print(\"Pattern: %s (%d/%d)\" % (pattern_name, pattern_i + 1, num_patterns))\n",
    "                    print(\"--------------------------------------\")\n",
    "\n",
    "                    print(\"%d seqlets\" % len(seqlets))\n",
    "                    print(\"Sequence\")\n",
    "                    viz_sequence.plot_weights(pattern[\"sequence\"][\"fwd\"][:])\n",
    "                    print(\"Hypothetical contributions\")\n",
    "                    viz_sequence.plot_weights(pattern[\"task0_hypothetical_contribs\"][\"fwd\"][:])\n",
    "                    print(\"Contribution_scores\")\n",
    "                    viz_sequence.plot_weights(pattern[\"task0_contrib_scores\"][\"fwd\"][:])\n",
    "                \n",
    "                pfm = pattern[\"sequence\"][\"fwd\"][:]\n",
    "                act_contribs = pattern[\"task0_contrib_scores\"][\"fwd\"][:]\n",
    "                \n",
    "                # Check that the contribution scores are overall positive\n",
    "                if np.sum(act_contribs) < 0:\n",
    "                    continue\n",
    "                \n",
    "                # Check number of seqlets and IC\n",
    "                if len(seqlets) < min_seqlets:\n",
    "                    continue\n",
    "                \n",
    "                pwm = pfm_to_pwm(pfm)\n",
    "                pwm_ic = pfm_info_content(pfm)\n",
    "                max_windowed_ic = max(\n",
    "                    np.sum(pwm_ic[i : (i + ic_window)]) for i in range(len(pwm_ic) - ic_window + 1)\n",
    "                )\n",
    "                if max_windowed_ic / ic_window < min_ic:\n",
    "                    continue\n",
    "                    \n",
    "                # Cut off flanks from actual contribution scores and PWM based on IC of PWM\n",
    "                ic_trim_thresh = np.max(pwm_ic) * trim_flank_ic_frac\n",
    "                pass_inds = np.where(pwm_ic >= ic_trim_thresh)[0]\n",
    "                trimmed_cwm = act_contribs[np.min(pass_inds): np.max(pass_inds) + 1]\n",
    "                trimmed_pwm = pwm[np.min(pass_inds): np.max(pass_inds) + 1]\n",
    "                \n",
    "                # Last check to make sure motif is overall positive\n",
    "                if np.sum(trimmed_cwm) < 0:\n",
    "                    continue\n",
    "\n",
    "                cwms.append(trimmed_cwm)\n",
    "                pwms.append(trimmed_pwm)\n",
    "                num_seqlets.append(len(seqlets))\n",
    "\n",
    "    if plot_passed_motifs:\n",
    "        print(\"Final motifs: %d total\" % len(cwms))\n",
    "        print(\"==========================================\")\n",
    "        for i in range(len(cwms)):\n",
    "            print(\"Motif %d (%d seqlets)\" % (i + 1, num_seqlets[i]))\n",
    "            viz_sequence.plot_weights(cwms[i])\n",
    "            viz_sequence.plot_weights(pwms[i])\n",
    "    return cwms, pwms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "noprior_cwms, noprior_pwms = import_tfmodisco_motifs(noprior_tfm_path, plot_all_motifs=False, plot_passed_motifs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_cwms, prior_pwms = import_tfmodisco_motifs(prior_tfm_path, plot_all_motifs=False, plot_passed_motifs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call motif instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_sim(seq_1, seq_2, normalize=True):\n",
    "    \"\"\"\n",
    "    Takes two windows (W x 4 arrays) and computes a similarity between them,\n",
    "    using a continuous Jaccard metric. If `normalize` is True, L1 normalizes\n",
    "    both sequences first.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        seq_1 = seq_1 / np.sum(np.abs(seq_1))\n",
    "        seq_2 = seq_2 / np.sum(np.abs(seq_2))\n",
    "    ab_1, ab_2 = np.abs(seq_1), np.abs(seq_2)\n",
    "    inter = np.minimum(ab_1, ab_2) * np.sign(seq_1) * np.sign(seq_2)\n",
    "    union = np.maximum(ab_1, ab_2)\n",
    "    cont_jaccard = np.sum(inter, axis=1) / np.sum(union, axis=1)\n",
    "    return np.sum(cont_jaccard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_motifs(coords, imp_scores, one_hot_seqs, cwms, pwms, top_contrib_frac=0.1):\n",
    "    \"\"\"\n",
    "    From an N x 3 object array of coordinates and parallel N x I x 4 array\n",
    "    of actual importance scores, this calls motifs based on Jaccard similarity.\n",
    "    For each motif in `cwms` and `pwms`, scans to find the best instances. Returns\n",
    "    the result of all scans (over all motifs together) as an M x 3 object array\n",
    "    of instance coordinates, a parallel M-array of match scores, and an M-array\n",
    "    of CWM source indices, all in reverse order by match score.\n",
    "    \"\"\"\n",
    "    assert len(coords) == len(imp_scores)\n",
    "    assert np.all(coords[:, 2] - coords[:, 1] == input_length), \\\n",
    "        \"Expect all coordinates to be of length %d\" % input_length\n",
    "    assert imp_scores.shape[1] == input_length, \\\n",
    "        \"Expect important scores to have sequence length %d\" % input_length\n",
    "    \n",
    "    # Allocate arrays\n",
    "    array_len = 0\n",
    "    for cwm in cwms:\n",
    "        num_windows_per_coord = input_length - len(cwm) + 1\n",
    "        array_len += num_windows_per_coord * len(coords)\n",
    "    motif_coords = np.empty((array_len, 3), dtype=object)\n",
    "    cwm_scores = np.empty(array_len)  # CWM match score; for ranking at the end\n",
    "    pwm_scores = np.empty(array_len)  # PWM match score; for filtering\n",
    "    motif_sources = np.empty(array_len, dtype=int)\n",
    "    contrib_scores = np.empty(array_len)  # Total contribution score; for filtering\n",
    "    \n",
    "    next_index = 0\n",
    "    # For each coordinate, for each CWM, for each window, compute the match\n",
    "    for i in tqdm.notebook.trange(len(coords)):\n",
    "        chrom, start, end = coords[i]\n",
    "        imp_score_track = imp_scores[i]\n",
    "        one_hot_seq_track = one_hot_seqs[i]\n",
    "            \n",
    "        for motif_i in range(len(cwms)):\n",
    "            cwm, pwm = cwms[motif_i], pwms[motif_i]\n",
    "            rc_cwm, rc_pwm = revcomp_motif(cwm), revcomp_motif(pwm)\n",
    "            motif_len = len(cwm)\n",
    "            num_windows_per_coord = input_length - motif_len + 1\n",
    "\n",
    "            for j in range(num_windows_per_coord):\n",
    "                motif_coords[next_index, 0] = chrom\n",
    "                motif_coords[next_index, 1] = start + j\n",
    "                motif_coords[next_index, 2] = start + j + motif_len\n",
    "                imp_score_window = imp_score_track[j:(j + motif_len)]\n",
    "                one_hot_seq_window = one_hot_seq_track[j:(j + motif_len)]\n",
    "                fwd_score, rev_score = jaccard_sim(imp_score_window, cwm), jaccard_sim(imp_score_window, rc_cwm)\n",
    "                if fwd_score > rev_score:\n",
    "                    cwm_scores[next_index] = fwd_score\n",
    "                    pwm_scores[next_index] = np.sum(one_hot_seq_window * pwm)\n",
    "                else:\n",
    "                    cwm_scores[next_index] = rev_score\n",
    "                    pwm_scores[next_index] = np.sum(one_hot_seq_window * rc_pwm)\n",
    "                motif_sources[next_index] = motif_i\n",
    "                contrib_scores[next_index] = np.sum(np.abs(imp_score_window))\n",
    "                next_index += 1\n",
    "\n",
    "    # Filter out anything with a negative PWM match score\n",
    "    mask = pwm_scores > 0\n",
    "    motif_coords = motif_coords[mask]\n",
    "    cwm_scores = cwm_scores[mask]\n",
    "    motif_sources = motif_sources[mask]\n",
    "    contrib_scores = contrib_scores[mask]\n",
    "    \n",
    "    # For each CWM, keep only the top few based on CWM match score\n",
    "    mask = np.zeros(len(motif_sources), dtype=bool)\n",
    "    for cwm_i in range(len(cwms)):\n",
    "        cwm_mask = motif_sources == cwm_i\n",
    "        cwm_match_scores = cwm_scores[cwm_mask]\n",
    "        limit = np.flip(np.sort(cwm_match_scores))[int(len(cwm_match_scores) * top_contrib_frac)]\n",
    "        mask = mask | (cwm_mask & (cwm_scores >= limit))  # Update mask for wherever it is this CWM and score in top %ile\n",
    "    motif_coords = motif_coords[mask]\n",
    "    cwm_scores = cwm_scores[mask]\n",
    "    motif_sources = motif_sources[mask]\n",
    "    contrib_scores = contrib_scores[mask]\n",
    "    \n",
    "    # Now order by contribution score\n",
    "    inds = np.flip(np.argsort(contrib_scores))\n",
    "    return motif_coords[inds], cwm_scores[inds], motif_sources[inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noprior_motif_call_coords, noprior_cwm_scores, noprior_motif_sources = call_motifs(\n",
    "    sample_coords, (noprior_imp_scores * sample_input_seqs), sample_input_seqs, noprior_cwms, noprior_pwms\n",
    ")\n",
    "prior_motif_call_coords, prior_cwm_scores, prior_motif_sources = call_motifs(\n",
    "    sample_coords, (prior_imp_scores * sample_input_seqs), sample_input_seqs, prior_cwms, prior_pwms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some examples of motif calls\n",
    "for i in np.random.choice(1000, size=10, replace=False):\n",
    "    chrom, start, end = prior_motif_call_coords[i]\n",
    "    sample_index = np.where(\n",
    "        (sample_coords[:, 0] == chrom) & (sample_coords[:, 1] <= start) & (sample_coords[:, 2] > end)\n",
    "    )[0][0]\n",
    "    _, sample_start, sample_end = sample_coords[sample_index]\n",
    "    seq_start = start - sample_start\n",
    "    seq_end = seq_start + (end - start)\n",
    "    viz_sequence.plot_weights(prior_imp_scores[sample_index][seq_start:seq_end] * sample_input_seqs[sample_index][seq_start:seq_end])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantify agreement of motif instances with footprints using ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_footprint_overlap(coords, footprints):\n",
    "    \"\"\"\n",
    "    From an N x 3 object array of coordinates and a table of imported footprints,\n",
    "    this function determines which coordinates overlap with a footprint.\n",
    "    Returns a N-array binary mask, denoting which coordinates overlap with a\n",
    "    footprint.\n",
    "    \"\"\"\n",
    "    mask = np.zeros(len(coords), dtype=int)\n",
    "    for i in tqdm.notebook.trange(len(coords)):\n",
    "        chrom, start, end = coords[i]\n",
    "        fps = footprints[\n",
    "            (footprints[\"chrom\"] == chrom) & (footprints[\"peak_start\"] <= end) & \\\n",
    "            (start <= footprints[\"peak_end\"])\n",
    "        ]\n",
    "        if len(fps):\n",
    "            mask[i] = 1\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noprior_motif_overlap_mask = compute_footprint_overlap(\n",
    "    noprior_motif_call_coords[:10000], footprints\n",
    ")\n",
    "prior_motif_overlap_mask = compute_footprint_overlap(\n",
    "    prior_motif_call_coords[:10000], footprints\n",
    ")\n",
    "noprior_motif_overlap_cdf = normed_rank_enrichment(noprior_motif_overlap_mask)\n",
    "prior_motif_overlap_cdf = normed_rank_enrichment(prior_motif_overlap_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(prior_motif_sources[:1000], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "title = \"Cumulative BPNet %s ChIP-nexus peak overlap in top motif calls\" % (\"aggregated\" if task_index is None else bpnet_tasks[task_index])\n",
    "title += \"\\n%s %s models\" % (condition_name, model_type)\n",
    "title += \"\\nComputed on %d randomly drawn test peaks\" % num_samples\n",
    "plt.title(title)\n",
    "ax.plot(np.cumsum(noprior_motif_overlap_mask), label=\"No prior\", color=\"coral\")\n",
    "ax.plot(np.cumsum(prior_motif_overlap_mask), label=\"With Fourier prior\", color=\"slateblue\")\n",
    "ax.set_ylabel(\"Number of motif calls in footprints\")\n",
    "ax.set_xlabel(\"Top k motif calls by importance\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantify agreement of motif instances with profile-derived footprints using ranks\n",
    "Instead of using pre-determined footprints, we use profile heights to binarize footprint classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_footprints_by_profiles(coords, profile_func, flank_size=35, quant_cutoff=0.9):\n",
    "    \"\"\"\n",
    "    Given an N x 3 object array of coordinates and a function that returns\n",
    "    the profile given any coordinate (chrom, start, and end), determines\n",
    "    which of the N coordinates overlie a footprint, based on profile counts.\n",
    "    For each coordinate, this will look `flank_size` base pairs left and right\n",
    "    of the center, and record the maximum profile height seen. A coordinate is\n",
    "    deemed to overlie a footprint if its maximum profile height is in the\n",
    "    `quant_cutoff` percentile (default 90th percentile) over all given\n",
    "    coordinates. Returns an N-array as a binary mask of which centers overlie a\n",
    "    footprint.\n",
    "    \"\"\"\n",
    "    heights = np.empty(len(coords))\n",
    "    for i in tqdm.notebook.trange(len(coords)):\n",
    "        chrom, start, end = coords[i]\n",
    "        center = (start + end) // 2\n",
    "        heights[i] = np.max(\n",
    "            profile_func(chrom, center - flank_size, center + flank_size)\n",
    "        )\n",
    "    inds = np.flip(np.argsort(heights))  # Best (highest) height first\n",
    "    num_keep = int(quant_cutoff * len(coords))\n",
    "    mask = np.zeros(len(coords), dtype=int)\n",
    "    mask[inds[:num_keep]] = 1\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noprior_motif_profoverlap_mask = binarize_footprints_by_profiles(\n",
    "    noprior_motif_call_coords[:10000], get_profiles\n",
    ")\n",
    "prior_motif_profoverlap_mask = binarize_footprints_by_profiles(\n",
    "    prior_motif_call_coords[:10000], get_profiles\n",
    ")\n",
    "noprior_motif_profoverlap_cdf = normed_rank_enrichment(noprior_motif_profoverlap_mask)\n",
    "prior_motif_profoverlap_cdf = normed_rank_enrichment(prior_motif_profoverlap_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert condition_name == \"BPNet\"\n",
    "plt.figure()\n",
    "title = \"Cumulative BPNet %s ChIP-nexus peak overlap by profile height in top motif calls\" % (\"aggregated\" if task_index is None else bpnet_tasks[task_index])\n",
    "title += \"\\n%s %s models\" % (condition_name, model_type)\n",
    "title += \"\\nOver %d random test peaks\" % len(sample)\n",
    "plt.title(title)\n",
    "plt.plot(np.cumsum(noprior_motif_profoverlap_mask), label=\"No prior\", color=\"red\")\n",
    "plt.plot(np.cumsum(prior_motif_profoverlap_mask), label=\"With Fourier prior\", color=\"blue\")\n",
    "plt.ylabel(\"Number of overlapping motif calls\")\n",
    "plt.xlabel(\"Top k motif calls\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
