{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importance scores without priors\n",
    "!ls /users/amtseng/att_priors/results/shap_scores/profile/BPNet/BPNet_r20_e18_task*\n",
    "\n",
    "#Importance scores with priors\n",
    "!ls /users/amtseng/att_priors/results/shap_scores/profile/BPNet/BPNet_prior_r25_e17_task*_shap_scores.h5\n",
    "\n",
    "#TF-modisco results without priors:\n",
    "!ls /users/amtseng/att_priors/results/tfmodisco/profile/BPNet/BPNet_r20_e18_task*_tfm.h5\n",
    "\n",
    "#TF-MoDISco results WITH priors:\n",
    "!ls /users/amtseng/att_priors/results/tfmodisco/profile/BPNet/BPNet_prior_r25_e17_task*_tfm.h5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "noprior_impscores =\\\n",
    "    h5py.File(\"/users/amtseng/att_priors/results/shap_scores/\"+\n",
    "              \"profile/BPNet/BPNet_r20_e18_task0_shap_scores.h5\", \"r\")\n",
    "withprior_impscores =\\\n",
    "    h5py.File(\"/users/amtseng/att_priors/results/shap_scores/\"+\n",
    "              \"profile/BPNet/BPNet_prior_r25_e17_task0_shap_scores.h5\", \"r\")\n",
    "\n",
    "noprior_modisco_h5 = h5py.File(\"/users/amtseng/att_priors/results/\"\n",
    "                               +\"tfmodisco/profile/BPNet/BPNet_r20_e18_task0_tfm.h5\", \"r\")\n",
    "withprior_modisco_h5 = h5py.File(\"/users/amtseng/att_priors/results/tfmodisco/\"\n",
    "                              +\"profile/BPNet/BPNet_prior_r25_e17_task0_tfm.h5\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import modisco\n",
    "from modisco.tfmodisco_workflow import workflow\n",
    "\n",
    "onehot = np.array(noprior_impscores[\"one_hot_seqs\"])\n",
    "noprior_hypscores = np.array(noprior_impscores[\"hyp_scores\"])\n",
    "withprior_hypscores = np.array(withprior_impscores[\"hyp_scores\"])\n",
    "noprior_contribscores = noprior_hypscores*onehot\n",
    "withprior_contribscores = withprior_hypscores*onehot\n",
    "\n",
    "noprior_track_set = modisco.tfmodisco_workflow.workflow.prep_track_set(\n",
    "                task_names=[\"task0\"],\n",
    "                contrib_scores={\"task0\": noprior_contribscores},\n",
    "                hypothetical_contribs={\"task0\": noprior_hypscores},\n",
    "                one_hot=onehot)\n",
    "noprior_tfmodisco_results =\\\n",
    "    workflow.TfModiscoResults.from_hdf5(noprior_modisco_h5,\n",
    "                                        track_set=noprior_track_set)\n",
    "\n",
    "withprior_track_set = modisco.tfmodisco_workflow.workflow.prep_track_set(\n",
    "                task_names=[\"task0\"],\n",
    "                contrib_scores={\"task0\": withprior_contribscores},\n",
    "                hypothetical_contribs={\"task0\": withprior_hypscores},\n",
    "                one_hot=onehot)\n",
    "withprior_tfmodisco_results =\\\n",
    "    workflow.TfModiscoResults.from_hdf5(withprior_modisco_h5,\n",
    "                                        track_set=withprior_track_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noprior_patterns = (noprior_tfmodisco_results.\n",
    "                    metacluster_idx_to_submetacluster_results['metacluster_1']\n",
    "                    .seqlets_to_patterns_result.patterns)\n",
    "withprior_patterns = (withprior_tfmodisco_results.\n",
    "                      metacluster_idx_to_submetacluster_results['metacluster_0']\n",
    "                      .seqlets_to_patterns_result.patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from modisco.visualization import viz_sequence\n",
    "print(\"No prior - patterns\")\n",
    "for idx,pattern in enumerate(noprior_patterns):\n",
    "    print(idx, len(pattern.seqlets))\n",
    "    viz_sequence.plot_weights(pattern[\"task0_contrib_scores\"].fwd)\n",
    "    viz_sequence.plot_weights(pattern[\"sequence\"].fwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from modisco.visualization import viz_sequence\n",
    "print(\"With prior - patterns\")\n",
    "for idx,pattern in enumerate(withprior_patterns):\n",
    "    print(idx, len(pattern.seqlets))\n",
    "    viz_sequence.plot_weights(pattern[\"task0_contrib_scores\"].fwd)\n",
    "    viz_sequence.plot_weights(pattern[\"sequence\"].fwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's look at the scores underlying the 'Nanog-alt' motif discovered by the with-priors model\n",
    "motif_to_study = withprior_patterns[4]\n",
    "viz_sequence.plot_weights(motif_to_study[\"task0_contrib_scores\"].fwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get coordinates centered around this motif\n",
    "\n",
    "input_length = 1346\n",
    "idx_within_motif_of_centerpos = 22 #where to center, within the modisco motif\n",
    "\n",
    "orig_coord_starts = noprior_impscores['coords_start']\n",
    "orig_coord_ends = noprior_impscores['coords_end']\n",
    "\n",
    "genomic_coords = []\n",
    "is_revcomp = []\n",
    "debug_coords = []\n",
    "noprior_aroundmotif_contribscores = []\n",
    "withprior_aroundmotif_contribscores = []\n",
    "flank_to_show = 50\n",
    "num_seqlets_to_use = 10\n",
    "for seqlet in motif_to_study.seqlets[:num_seqlets_to_use]:\n",
    "    region_start = ((orig_coord_starts[seqlet.coor.example_idx]\n",
    "                    + orig_coord_ends[seqlet.coor.example_idx])//2\n",
    "                    -input_length//2)\n",
    "    within_region_center = ((seqlet.coor.start + idx_within_motif_of_centerpos) if seqlet.coor.is_revcomp==False\n",
    "                            else (seqlet.coor.end-idx_within_motif_of_centerpos))\n",
    "    if (within_region_center > flank_to_show\n",
    "        and (noprior_contribscores.shape[1]-within_region_center) > flank_to_show):\n",
    "        genomic_motif_center = region_start + within_region_center\n",
    "        genomic_coords.append(('chr1', genomic_motif_center, genomic_motif_center+1))\n",
    "        is_revcomp.append(seqlet.coor.is_revcomp)\n",
    "        noprior_aroundmotif_contribscores.append(\n",
    "            noprior_contribscores[seqlet.coor.example_idx,\n",
    "                                   within_region_center-flank_to_show:\n",
    "                                   within_region_center+flank_to_show])\n",
    "        withprior_aroundmotif_contribscores.append(\n",
    "            withprior_contribscores[seqlet.coor.example_idx,\n",
    "                                     within_region_center-flank_to_show:\n",
    "                                     within_region_center+flank_to_show])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the Dataset Loader\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"../src/\"))\n",
    "import feature.util\n",
    "import feature.make_profile_dataset\n",
    "\n",
    "reference_fasta = \"/users/amtseng/genomes/mm10.fasta\"\n",
    "profile_hdf5_path = \"/users/amtseng/att_priors/data/processed/BPNet_ChIPseq/profile/labels/BPNet_profiles.h5\"\n",
    "profile_length = 1000\n",
    "coords_to_seq = feature.util.CoordsToSeq(\n",
    "    reference_fasta,\n",
    "    center_size_to_use=input_length)\n",
    "coords_to_vals = feature.make_profile_dataset.CoordsToVals(\n",
    "                    profile_hdf5_path, profile_length)\n",
    "\n",
    "#genomic_coords = list(zip(['chr1' for x in range(len(noprior_impscores['coords_start']))],\n",
    "#                  noprior_impscores['coords_start'][:],\n",
    "#                  noprior_impscores['coords_end'][:]))\n",
    "\n",
    "seqs_onehot = coords_to_seq(genomic_coords)\n",
    "profiles = np.swapaxes(coords_to_vals(genomic_coords),1,2)\n",
    "tf_profile = profiles[:,:3,:,:]\n",
    "control_profile = profiles[:,3:,:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model.util as model_util\n",
    "import model.profile_models as profile_models\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "def restore_model(model_class, load_path):\n",
    "    \"\"\"\n",
    "    Restores a model from the given path. `model_class` must be the class for\n",
    "    which the saved model was created from. This will create a model of this\n",
    "    class, using the loaded creation arguments. It will then restore the learned\n",
    "    parameters to the model.\n",
    "    \"\"\"\n",
    "    load_dict = torch.load(load_path, map_location=torch.device('cpu'))\n",
    "    model_state = load_dict[\"model_state\"]\n",
    "    model_creation_args = load_dict[\"model_creation_args\"]\n",
    "    model = model_class(**model_creation_args)\n",
    "    model.load_state_dict(model_state)\n",
    "    return model\n",
    "\n",
    "def load_model(model_path):\n",
    "    model = restore_model(profile_models.ProfilePredictorWithSharedControls, model_path)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "def get_model_preds(model, input_data_list):\n",
    "    seqs_onehot, control_profile = input_data_list\n",
    "    seqs_onehot = model_util.place_tensor(torch.tensor(seqs_onehot)).float()\n",
    "    control_profile = model_util.place_tensor(torch.tensor(control_profile)).float()\n",
    "    to_return = model(seqs_onehot, control_profile)\n",
    "    return (to_return[0].detach().cpu().numpy(), to_return[1].detach().cpu().numpy())\n",
    "\n",
    "def get_batched_model_preds(model, seqs_onehot, control_profile, batch_size):\n",
    "    profiles = []\n",
    "    counts = []\n",
    "    for i in range(int(np.ceil(len(seqs_onehot)/batch_size))):\n",
    "        if (i%10 == 0):\n",
    "            print(\"Done\",i,\"batches\")\n",
    "        (batch_profiles, batch_counts) = get_model_preds(\n",
    "            model=model,\n",
    "            input_data_list=[seqs_onehot[batch_size*i: batch_size*(i+1)],\n",
    "                             control_profile[batch_size*i: batch_size*(i+1)]])\n",
    "        profiles.extend(batch_profiles)\n",
    "        counts.extend(batch_counts)\n",
    "    return np.array(profiles), np.array(counts)\n",
    "    \n",
    "withprior_model = load_model(withprior_impscores['model'].attrs['model'])\n",
    "noprior_model = load_model(noprior_impscores['model'].attrs['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withprior_profilepreds = get_batched_model_preds(\n",
    "    model=withprior_model, seqs_onehot=seqs_onehot,\n",
    "    control_profile=control_profile, batch_size=40)\n",
    "\n",
    "noprior_profilepreds = get_batched_model_preds(\n",
    "    model=noprior_model, seqs_onehot=seqs_onehot,\n",
    "    control_profile=control_profile, batch_size=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copying over some ism code\n",
    "import scipy.special\n",
    "\n",
    "def list_wrapper(func):\n",
    "    def wrapped_func(input_data_list, **kwargs):\n",
    "        if (isinstance(input_data_list, list)):\n",
    "            remove_list_on_return=False\n",
    "        else:\n",
    "            remove_list_on_return=True\n",
    "            input_data_list = [input_data_list]\n",
    "        to_return = func(input_data_list=input_data_list,\n",
    "                         **kwargs)\n",
    "        return to_return\n",
    "    return wrapped_func\n",
    "\n",
    "def empty_ism_buffer(results_arr,\n",
    "                     input_data_onehot,\n",
    "                     perturbed_inputs_preds,\n",
    "                     perturbed_inputs_info):\n",
    "    for perturbed_input_pred,perturbed_input_info\\\n",
    "        in zip(perturbed_inputs_preds, perturbed_inputs_info):\n",
    "        example_idx = perturbed_input_info[0]\n",
    "        if (perturbed_input_info[1]==\"original\"):\n",
    "            results_arr[example_idx] +=\\\n",
    "                (perturbed_input_pred*input_data_onehot[example_idx])\n",
    "        else:\n",
    "            pos_idx,base_idx = perturbed_input_info[1]\n",
    "            results_arr[example_idx,pos_idx,base_idx] = perturbed_input_pred\n",
    "\n",
    "def make_ism_func(prediction_func,\n",
    "                  flank_around_middle_to_perturb,\n",
    "                  batch_size=200):\n",
    "    @list_wrapper\n",
    "    def ism_func(input_data_list, progress_update=10000, **kwargs):\n",
    "        input_data_onehot=input_data_list[0]\n",
    "        \n",
    "        results_arr = np.zeros_like(input_data_onehot).astype(\"float64\")\n",
    "        \n",
    "        perturbed_inputs_info = []\n",
    "        perturbed_onehot_seqs = []\n",
    "        control_inputs = []\n",
    "        perturbed_inputs_preds = []\n",
    "        num_done = 0\n",
    "        for i,onehot_seq in enumerate(input_data_onehot):\n",
    "            perturbed_onehot_seqs.append(onehot_seq)\n",
    "            control_inputs.append(input_data_list[-1][i])\n",
    "            perturbed_inputs_info.append((i,\"original\"))\n",
    "            for pos in range(int(len(onehot_seq)/2)-flank_around_middle_to_perturb,\n",
    "                             int(len(onehot_seq)/2)+flank_around_middle_to_perturb):\n",
    "                for base_idx in range(4):\n",
    "                    if onehot_seq[pos,base_idx]==0:\n",
    "                        assert len(onehot_seq.shape)==2\n",
    "                        new_onehot = np.zeros_like(onehot_seq) + onehot_seq\n",
    "                        new_onehot[pos,:] = 0\n",
    "                        new_onehot[pos,base_idx] = 1\n",
    "                        perturbed_onehot_seqs.append(new_onehot)\n",
    "                        control_inputs.append(input_data_list[-1][i])\n",
    "                        perturbed_inputs_info.append((i,(pos,base_idx)))\n",
    "                        num_done += 1\n",
    "                        if ((progress_update is not None)\n",
    "                            and num_done%progress_update==0):\n",
    "                            print(\"Done\",num_done)\n",
    "                        if (len(perturbed_inputs_info)>=batch_size):\n",
    "                            empty_ism_buffer(\n",
    "                                 results_arr=results_arr,\n",
    "                                 input_data_onehot=input_data_onehot,\n",
    "                                 perturbed_inputs_preds=\n",
    "                                  prediction_func([np.array(perturbed_onehot_seqs), np.array(control_inputs)]),\n",
    "                                 perturbed_inputs_info=perturbed_inputs_info)\n",
    "                            perturbed_inputs_info = []\n",
    "                            perturbed_onehot_seqs = []\n",
    "                            control_inputs = []\n",
    "        if (len(perturbed_inputs_info)>0):\n",
    "            empty_ism_buffer(\n",
    "                 results_arr=results_arr,\n",
    "                 input_data_onehot=input_data_onehot,\n",
    "                 perturbed_inputs_preds=\n",
    "                  prediction_func([np.array(perturbed_onehot_seqs), np.array(control_inputs)]),\n",
    "                 perturbed_inputs_info=perturbed_inputs_info)\n",
    "        perturbed_inputs_info = []\n",
    "        perturbed_onehot_seqs = []\n",
    "        results_arr = results_arr - np.mean(results_arr,axis=-1)[:,:,None]\n",
    "        return input_data_onehot*results_arr\n",
    "    return ism_func\n",
    "\n",
    "def get_prediction_func(model, task_idx):\n",
    "    def pred_func(x):\n",
    "        logits = get_model_preds(model,x)[0][:,task_idx]\n",
    "        softmax_out = scipy.special.softmax(logits, axis=1)\n",
    "        assert np.max(np.abs(np.sum(softmax_out, axis=1)-1)) < 1e-5, print(np.sum(softmax_out, axis=1))\n",
    "        assert len(softmax_out.shape)==3\n",
    "        return np.sum(softmax_out*logits, axis=(1,2))\n",
    "    return pred_func\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noprior_ismfunc = make_ism_func(\n",
    "    prediction_func=get_prediction_func(noprior_model, task_idx=0),\n",
    "    flank_around_middle_to_perturb=flank_to_show,\n",
    "    batch_size=40)\n",
    "\n",
    "withprior_ismfunc = make_ism_func(\n",
    "    prediction_func=get_prediction_func(withprior_model, task_idx=0),\n",
    "    flank_around_middle_to_perturb=flank_to_show,\n",
    "    batch_size=40)\n",
    "\n",
    "noprior_ism = noprior_ismfunc([seqs_onehot, control_profile], progress_update=100)\n",
    "withprior_ism = withprior_ismfunc([seqs_onehot, control_profile], progress_update=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for idx,(genomic_coord, is_rc) in enumerate(zip(genomic_coords, is_revcomp)):\n",
    "    print(genomic_coord[0],\n",
    "          genomic_coord[1]-flank_to_show,\n",
    "          genomic_coord[1]+flank_to_show,\n",
    "          \"revcomp:\"+str(is_rc))\n",
    "    center_offset = int(noprior_ism.shape[1]/2)\n",
    "    print(\"No prior - DeepSHAP scores\")\n",
    "    viz_sequence.plot_weights(noprior_aroundmotif_contribscores[idx], subticks_frequency=20)\n",
    "    print(\"No prior - ISM scores\")\n",
    "    viz_sequence.plot_weights(noprior_ism[idx][center_offset-flank_to_show:center_offset+flank_to_show],\n",
    "                              subticks_frequency=20)\n",
    "    print(\"With prior - DeepSHAP scores\")\n",
    "    viz_sequence.plot_weights(withprior_aroundmotif_contribscores[idx], subticks_frequency=20)\n",
    "    print(\"With prior - ISM scores\")\n",
    "    viz_sequence.plot_weights(withprior_ism[idx][center_offset-flank_to_show:center_offset+flank_to_show],\n",
    "                              subticks_frequency=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
