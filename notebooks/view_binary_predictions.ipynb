{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../src/\"))\n",
    "import extract.data_loading as data_loading\n",
    "import extract.compute_predictions as compute_predictions\n",
    "import extract.compute_shap as compute_shap\n",
    "import extract.compute_ism as compute_ism\n",
    "import model.util as model_util\n",
    "import model.binary_models as binary_models\n",
    "import model.train_binary_model as train_binary_model\n",
    "import plot.viz_sequence as viz_sequence\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "import scipy.stats\n",
    "import json\n",
    "import tqdm\n",
    "tqdm.tqdm_notebook()  # It is necessary to call this before the tqdm.notebook submodule is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting defaults\n",
    "font_manager.fontManager.ttflist.extend(\n",
    "    font_manager.createFontList(\n",
    "        font_manager.findSystemFonts(fontpaths=\"/users/amtseng/modules/fonts\")\n",
    "    )\n",
    ")\n",
    "plot_params = {\n",
    "    \"figure.titlesize\": 22,\n",
    "    \"axes.titlesize\": 22,\n",
    "    \"axes.labelsize\": 20,\n",
    "    \"legend.fontsize\": 18,\n",
    "    \"xtick.labelsize\": 16,\n",
    "    \"ytick.labelsize\": 16,\n",
    "    \"font.family\": \"Roboto\",\n",
    "    \"font.weight\": \"bold\"\n",
    "}\n",
    "plt.rcParams.update(plot_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define paths for the model and data of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared paths/constants\n",
    "reference_fasta = \"/users/amtseng/genomes/hg38.fasta\"\n",
    "chrom_sizes = \"/users/amtseng/genomes/hg38.canon.chrom.sizes\"\n",
    "data_base_path = \"/users/amtseng/att_priors/data/processed/\"\n",
    "model_base_path = \"/users/amtseng/att_priors/models/trained_models/binary/\"\n",
    "chrom_set = [\"chr1\"]\n",
    "input_length = 1000\n",
    "fourier_att_prior_freq_limit = 150\n",
    "fourier_att_prior_freq_limit_softness = 0.2\n",
    "att_prior_grad_smooth_sigma = 3\n",
    "task_index = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SPI1 L2\n",
    "# condition_name = \"SPI1\"\n",
    "# files_spec_path = os.path.join(data_base_path, \"ENCODE_TFChIP/binary/config/SPI1/SPI1_training_paths.json\")\n",
    "# num_tasks = 4\n",
    "# task_index = None\n",
    "# model_class = binary_models.BinaryPredictor\n",
    "# noprior_model_path = os.path.join(model_base_path, \"SPI1_l2/1/model_ckpt_epoch_19.pt\")\n",
    "# prior_model_path = os.path.join(model_base_path, \"SPI1_prior/16/model_ckpt_epoch_6.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SPI1\n",
    "# condition_name = \"SPI1\"\n",
    "# files_spec_path = os.path.join(data_base_path, \"ENCODE_TFChIP/binary/config/SPI1/SPI1_training_paths.json\")\n",
    "# num_tasks = 4\n",
    "# task_index = None\n",
    "# model_class = binary_models.BinaryPredictor\n",
    "# noprior_model_path = os.path.join(model_base_path, \"SPI1/4/model_ckpt_epoch_2.pt\")\n",
    "# prior_model_path = os.path.join(model_base_path, \"SPI1_prior/16/model_ckpt_epoch_6.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GATA2\n",
    "# condition_name = \"GATA2\"\n",
    "# files_spec_path = os.path.join(data_base_path, \"ENCODE_TFChIP/binary/config/GATA2/GATA2_training_paths.json\")\n",
    "# num_tasks = 4\n",
    "# task_index = None\n",
    "# model_class = binary_models.BinaryPredictor\n",
    "# noprior_model_path = os.path.join(model_base_path, \"GATA2/8/model_ckpt_epoch_1.pt\")\n",
    "# prior_model_path = os.path.join(model_base_path, \"GATA2_prior/21/model_ckpt_epoch_6.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # K562\n",
    "# condition_name = \"K562\"\n",
    "# files_spec_path = os.path.join(data_base_path, \"ENCODE_DNase/binary/config/K562/K562_training_paths.json\")\n",
    "# num_tasks = 1\n",
    "# task_index = None\n",
    "# model_class = binary_models.BinaryPredictor\n",
    "# noprior_model_path = os.path.join(model_base_path, \"K562/18/model_ckpt_epoch_1.pt\")\n",
    "# prior_model_path = os.path.join(model_base_path, \"K562_prior/12/model_ckpt_epoch_6.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BPNet\n",
    "condition_name = \"BPNet\"\n",
    "reference_fasta = \"/users/amtseng/genomes/mm10.fasta\"\n",
    "chrom_sizes = \"/users/amtseng/genomes/mm10.canon.chrom.sizes\"\n",
    "files_spec_path = os.path.join(data_base_path, \"BPNet_ChIPseq/binary/config/BPNet_training_paths.json\")\n",
    "num_tasks = 3\n",
    "task_index = None\n",
    "model_class = binary_models.BinaryPredictor\n",
    "noprior_model_path = os.path.join(model_base_path, \"BPNet/22/model_ckpt_epoch_1.pt\")\n",
    "prior_model_path = os.path.join(model_base_path, \"BPNet_prior/27/model_ckpt_epoch_11.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(True)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "def restore_model(model_path):\n",
    "    model = model_util.restore_model(model_class, model_path)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model without priors\n",
    "noprior_model = restore_model(noprior_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model with priors\n",
    "prior_model = restore_model(prior_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "Create an input data loader, that maps coordinates to data needed for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_func = data_loading.get_binary_input_func(\n",
    "    files_spec_path, input_length, reference_fasta\n",
    ")\n",
    "pos_bins = data_loading.get_positive_binary_bins(\n",
    "    files_spec_path, task_ind=task_index, chrom_set=chrom_set\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shap explainer\n",
    "Create DeepSHAP explainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noprior_shap_explainer = compute_shap.create_binary_explainer(\n",
    "    noprior_model, input_length, task_index=task_index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_shap_explainer = compute_shap.create_binary_explainer(\n",
    "    prior_model, input_length, task_index=task_index\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute loss values over test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a subset of bins randomly to compute predictions for\n",
    "num_samples = 1000\n",
    "rng = np.random.RandomState(20200318)\n",
    "sample_bins = pos_bins[np.random.choice(len(pos_bins), size=num_samples, replace=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noprior_preds = compute_predictions.get_binary_model_predictions(                                              \n",
    "    noprior_model, sample_bins, input_func,                        \n",
    "    fourier_att_prior_freq_limit=fourier_att_prior_freq_limit,\n",
    "    fourier_att_prior_freq_limit_softness=fourier_att_prior_freq_limit_softness,\n",
    "    att_prior_grad_smooth_sigma=att_prior_grad_smooth_sigma,\n",
    "    return_losses=True, return_gradients=True, show_progress=True                                         \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_preds = compute_predictions.get_binary_model_predictions(                                              \n",
    "    prior_model, sample_bins, input_func,                        \n",
    "    fourier_att_prior_freq_limit=fourier_att_prior_freq_limit,\n",
    "    fourier_att_prior_freq_limit_softness=fourier_att_prior_freq_limit_softness,\n",
    "    att_prior_grad_smooth_sigma=att_prior_grad_smooth_sigma,\n",
    "    return_losses=True, return_gradients=True, show_progress=True                                         \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of profile loss and prior loss over these conditions\n",
    "bin_num = 20\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 6))\n",
    "all_vals = np.concatenate([noprior_preds[\"corr_losses\"], prior_preds[\"corr_losses\"]])\n",
    "bins = np.linspace(np.min(all_vals), np.max(all_vals), bin_num)\n",
    "ax[0].hist(noprior_preds[\"corr_losses\"], bins=bins, color=\"coral\", label=\"No prior\", alpha=0.7)\n",
    "ax[0].hist(prior_preds[\"corr_losses\"], bins=bins, color=\"slateblue\", label=\"With Fourier prior\", alpha=0.7)\n",
    "ax[0].set_title(\"Histogram of correctness loss over %d random test peaks\" % num_samples)\n",
    "ax[0].set_xlabel(\"Correctness loss\")\n",
    "ax[0].legend()\n",
    "all_vals = np.concatenate([noprior_preds[\"att_losses\"], prior_preds[\"att_losses\"]])\n",
    "bins = np.linspace(np.min(all_vals), np.max(all_vals), bin_num)\n",
    "ax[1].hist(noprior_preds[\"att_losses\"], bins=bins, color=\"coral\", label=\"No prior\", alpha=0.7)\n",
    "ax[1].hist(prior_preds[\"att_losses\"], bins=bins, color=\"slateblue\", label=\"With Fourier prior\", alpha=0.7)\n",
    "ax[1].set_title(\"Histogram of Fourier prior loss over %d random test peaks\" % num_samples)\n",
    "ax[1].set_xlabel(\"Fourier prior loss\")\n",
    "ax[1].legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of gradients and SHAP scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_shap_scores(model, sample, batch_size=128):\n",
    "    \"\"\"\n",
    "    Given an array of N coordinates or bins, computes the SHAP scores\n",
    "    for the model, returning an N x I x 4 array of SHAP scores and an\n",
    "    N x I x 4 array of one-hot encoded sequence.\n",
    "    \"\"\"\n",
    "    num_samples = len(sample)\n",
    "    num_batches = int(np.ceil(num_samples / batch_size))\n",
    "    \n",
    "    all_shap_scores = np.empty((num_samples, input_length, 4))\n",
    "    all_one_hot_seqs = np.empty((num_samples, input_length, 4))\n",
    "        \n",
    "    shap_explainer = compute_shap.create_binary_explainer(\n",
    "        model, input_length, task_index=task_index\n",
    "    )\n",
    "\n",
    "    for i in tqdm.notebook.trange(num_batches):\n",
    "        batch_slice = slice(i * batch_size, (i + 1) * batch_size)\n",
    "        batch = sample[batch_slice]\n",
    "\n",
    "        input_seqs, _, _ = input_func(batch)\n",
    "        shap_scores = shap_explainer(\n",
    "            input_seqs, hide_shap_output=True\n",
    "        )\n",
    "\n",
    "        all_shap_scores[batch_slice] = shap_scores\n",
    "        all_one_hot_seqs[batch_slice] = input_seqs\n",
    "    return all_shap_scores, all_one_hot_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noprior_grads = noprior_preds[\"input_grads\"]\n",
    "prior_grads = prior_preds[\"input_grads\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noprior_shap, _ = compute_shap_scores(noprior_model, sample_bins)\n",
    "prior_shap, one_hot_seqs = compute_shap_scores(prior_model, sample_bins)\n",
    "assert np.all(one_hot_seqs == noprior_preds[\"input_seqs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dft(signal):\n",
    "    fourier_coeffs = np.fft.fft(signal)\n",
    "    fourier_freqs = 2 * np.pi * np.fft.fftfreq(signal.size)\n",
    "    fourier_freqs = fourier_freqs[:int(len(fourier_freqs) / 2)]  # Only the positive frequencies\n",
    "    mags = np.abs(fourier_coeffs)[:int(len(fourier_coeffs) / 2)]  # Frequency magnitudes are symmetric\n",
    "    return fourier_freqs, mags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier_highfreq_mags(imp_scores, freq_limit):\n",
    "    \"\"\"\n",
    "    For an N x I x 4 array of actual importance scores, computes the sum of the\n",
    "    Fourier magnitudes in high frequencies, defined by `freq_limit`. Returns an\n",
    "    N-array of Fourier scores (i.e. sum of low-frequency magnitudes)\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    # Normalize\n",
    "    imp_scores_sum = np.sum(np.abs(imp_scores), axis=2)  # Make into N x I\n",
    "    \n",
    "    for score_track in imp_scores_sum:\n",
    "        freqs, mags = dft(score_track)\n",
    "        freqs, mags = freqs[1:], mags[1:]  # Cut off DC\n",
    "        mags = mags / np.sum(mags)  # Normalize\n",
    "        scores.append(np.sum(mags[freq_limit:]))\n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(imp_scores, pseudocount=0.001):\n",
    "    \"\"\"\n",
    "    For an N x I x 4 array of actual importance scores, computes the entropy\n",
    "    of each track. Returns an N-array of entropy values.\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    # Normalize\n",
    "    imp_scores_sum = np.sum(np.abs(imp_scores), axis=2)  # Make into N x I\n",
    "    imp_scores_sum = imp_scores_sum + pseudocount\n",
    "    imp_scores_norm = imp_scores_sum / np.sum(imp_scores_sum, axis=1, keepdims=True)\n",
    "    \n",
    "    return -np.sum(imp_scores_norm * np.log2(imp_scores_norm), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noprior_grad_fourier_scores = fourier_highfreq_mags(noprior_grads * one_hot_seqs, fourier_att_prior_freq_limit)\n",
    "prior_grad_fourier_scores = fourier_highfreq_mags(prior_grads * one_hot_seqs, fourier_att_prior_freq_limit)\n",
    "noprior_grad_entropy_scores = entropy(noprior_grads * one_hot_seqs)\n",
    "prior_grad_entropy_scores = entropy(prior_grads * one_hot_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noprior_shap_fourier_scores = fourier_highfreq_mags(noprior_shap * one_hot_seqs, fourier_att_prior_freq_limit)\n",
    "prior_shap_fourier_scores = fourier_highfreq_mags(prior_shap * one_hot_seqs, fourier_att_prior_freq_limit)\n",
    "noprior_shap_entropy_scores = entropy(noprior_shap * one_hot_seqs)\n",
    "prior_shap_entropy_scores = entropy(prior_shap * one_hot_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_global_smoothness(\n",
    "    noprior_imp_fourier_scores, prior_imp_fourier_scores, noprior_imp_entropy_scores,\n",
    "    prior_imp_entropy_scores, imp_type\n",
    "):\n",
    "    bin_num = 20\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 6))\n",
    "    all_vals = np.concatenate([noprior_imp_fourier_scores, prior_imp_fourier_scores])\n",
    "    bins = np.linspace(np.min(all_vals), np.max(all_vals), bin_num)\n",
    "    ax[0].hist(noprior_imp_fourier_scores, bins=bins, color=\"coral\", label=\"No prior\", alpha=0.7)\n",
    "    ax[0].hist(prior_imp_fourier_scores, bins=bins, color=\"slateblue\", label=\"With Fourier prior\", alpha=0.7)\n",
    "    ax[0].set_xlabel(\"Sum of high-frequency Fourier magnitudes\")\n",
    "    all_vals = np.concatenate([noprior_imp_entropy_scores, prior_imp_entropy_scores])\n",
    "    bins = np.linspace(np.min(all_vals), np.max(all_vals), bin_num)\n",
    "    ax[1].hist(noprior_imp_entropy_scores, bins=bins, color=\"coral\", label=\"No prior\", alpha=0.7)\n",
    "    ax[1].hist(prior_imp_entropy_scores, bins=bins, color=\"slateblue\", label=\"With Fourier prior\", alpha=0.7)\n",
    "    ax[1].set_xlabel(\"Entropy\")\n",
    "    ax[1].legend()\n",
    "    title = \"Histograms of smoothness of %s\" % imp_type\n",
    "    title += \"\\n%s binary models\" % condition_name\n",
    "    title += \"\\nComputed on %d randomly drawn test peaks\" % num_samples\n",
    "    fig.suptitle(title)\n",
    "    plt.subplots_adjust(top=0.80)\n",
    "    plt.show()\n",
    "    \n",
    "    def draw_xy_line(ax):\n",
    "        limits = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "        ]\n",
    "        ax.plot(limits, limits, \"--\", alpha=0.5, color=\"black\")\n",
    "        ax.set_aspect(\"equal\")\n",
    "        ax.set_xlim(limits)\n",
    "        ax.set_ylim(limits)\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 6))\n",
    "    ax[0].scatter(noprior_imp_fourier_scores, prior_imp_fourier_scores, color=\"mediumorchid\", alpha=0.4)\n",
    "    ax[0].set_xlabel(\"High frequency sum without prior\")\n",
    "    ax[0].set_ylabel(\"High frequency sum with Fourier prior\")\n",
    "    ax[1].scatter(noprior_imp_entropy_scores, prior_imp_entropy_scores, color=\"mediumorchid\", alpha=0.4)\n",
    "    ax[1].set_xlabel(\"Entropy without prior\")\n",
    "    ax[1].set_ylabel(\"Entropy with Fourier prior\")\n",
    "    draw_xy_line(ax[0])\n",
    "    draw_xy_line(ax[1])\n",
    "    title = \"Pairwise comparison of %s smoothness\" % imp_type\n",
    "    title += \"\\n%s binary models\" % condition_name\n",
    "    title += \"\\nComputed on %d randomly drawn test peaks\" % num_samples\n",
    "    fig.suptitle(title)\n",
    "    plt.subplots_adjust(top=0.80)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"High-frequency Fourier sum:\")\n",
    "    print(\"Average without priors: %f\" % np.nanmean(noprior_imp_fourier_scores))\n",
    "    print(\"Average with priors: %f\" % np.nanmean(prior_imp_fourier_scores))\n",
    "    print(\"Standard error without priors: %f\" % scipy.stats.sem(noprior_imp_fourier_scores, nan_policy=\"omit\"))\n",
    "    print(\"Standard error with priors: %f\" % scipy.stats.sem(prior_imp_fourier_scores, nan_policy=\"omit\"))\n",
    "    w, p = scipy.stats.wilcoxon(noprior_imp_fourier_scores, prior_imp_fourier_scores, alternative=\"greater\")\n",
    "    print(\"One-sided Wilcoxon test: w = %f, p = %f\" % (w, p))\n",
    "    print(\"Entropy:\")\n",
    "    print(\"Average without priors: %f\" % np.nanmean(noprior_imp_entropy_scores))\n",
    "    print(\"Average with priors: %f\" % np.nanmean(prior_imp_entropy_scores))\n",
    "    print(\"Standard error without priors: %f\" % scipy.stats.sem(noprior_imp_entropy_scores, nan_policy=\"omit\"))\n",
    "    print(\"Standard error with priors: %f\" % scipy.stats.sem(prior_imp_entropy_scores, nan_policy=\"omit\"))\n",
    "    w, p = scipy.stats.wilcoxon(noprior_imp_entropy_scores, prior_imp_entropy_scores, alternative=\"greater\")\n",
    "    print(\"One-sided Wilcoxon test: w = %f, p = %f\" % (w, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_global_smoothness(\n",
    "    noprior_grad_fourier_scores, prior_grad_fourier_scores, noprior_grad_entropy_scores,\n",
    "    prior_grad_entropy_scores, \"input gradients\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_global_smoothness(\n",
    "    noprior_shap_fourier_scores, prior_shap_fourier_scores, noprior_shap_entropy_scores,\n",
    "    prior_shap_entropy_scores, \"DeepSHAP scores\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scipy.stats.wilcoxon(noprior_shap_fourier_scores, prior_shap_fourier_scores, alternative=\"less\"))\n",
    "for i in np.random.choice(num_samples, size=5, replace=False):\n",
    "    plt.figure(figsize=(20, 1))\n",
    "    plt.plot(np.sum(noprior_shap[i] * one_hot_seqs[i], axis=1), color=\"coral\")\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(20, 1))\n",
    "    plt.plot(np.sum(prior_shap[i] * one_hot_seqs[i], axis=1), color=\"slateblue\")\n",
    "    plt.show()\n",
    "    print(noprior_shap_fourier_scores[i], prior_shap_fourier_scores[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fft(signal, include_dc=False, pos_limit=None, title=None):\n",
    "    abs_signal = np.abs(signal)\n",
    "    \n",
    "    freqs, mags = dft(abs_signal)\n",
    "    if not include_dc:\n",
    "        freqs, mags = freqs[1:], mags[1:]\n",
    "        \n",
    "    plt.figure(figsize=(20, 2))\n",
    "    plt.plot(freqs, mags, color=\"red\")\n",
    "    plt.xlabel(\"Frequency (radians)\")\n",
    "    plt.ylabel(\"|Frequency component|\")\n",
    "    if pos_limit is not None:\n",
    "        pos_limit_radians = pos_limit * 2 * np.pi / len(signal)\n",
    "        plt.axvline(x=pos_limit_radians, color=\"black\")\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_signal(signal, title=None, color=None):\n",
    "    plt.figure(figsize=(20, 2))\n",
    "    plt.plot(signal, color=color)\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_plot(\n",
    "    model, shap_explainer, bin_index, with_priors, show_sequences=True, seq_slices=[slice(650, 750)], ylim=None\n",
    "):\n",
    "    if type(seq_slices) is not list:\n",
    "        seq_slices = [seq_slices]\n",
    "    results = compute_predictions.get_binary_model_predictions(                                              \n",
    "        model, np.array([bin_index]), input_func,                      \n",
    "        return_losses=False, return_gradients=True, show_progress=False                                         \n",
    "    )\n",
    "    coords = results[\"coords\"]\n",
    "    input_seqs = results[\"input_seqs\"]\n",
    "    input_grads = results[\"input_grads\"]\n",
    "\n",
    "    chrom, start, end = coords[0]\n",
    "    print(bin_index)\n",
    "    print(\"%s:%d-%d\" % (chrom, start, end))\n",
    "    \n",
    "    color = \"slateblue\" if with_priors else \"coral\"\n",
    "#     print(\"Input gradients and Fourier transform\")\n",
    "#     plot_signal(np.sum(input_grads[0] * input_seqs[0], axis=1), title=\"Input gradients\", color=color)\n",
    "#     plot_fft(np.sum(input_grads[0] * input_seqs[0], axis=1), pos_limit=200, title=\"Fourier transform of input gradients\")\n",
    "#     if show_sequences:\n",
    "#         for seq_slice in seq_slices:\n",
    "#             viz_sequence.plot_weights(input_grads[0][seq_slice], subticks_frequency=1000)\n",
    "#             viz_sequence.plot_weights((input_grads[0] * input_seqs[0])[seq_slice], subticks_frequency=1000)\n",
    "    \n",
    "    print(\"DeepSHAP scores\")\n",
    "    hyp_shap_scores = shap_explainer(input_seqs, hide_shap_output=True)\n",
    "    plot_signal(np.sum(hyp_shap_scores[0] * input_seqs[0], axis=1), title=\"DeepSHAP scores\", color=color)\n",
    "    if show_sequences:\n",
    "        for seq_slice in seq_slices:\n",
    "            viz_sequence.plot_weights(hyp_shap_scores[0][seq_slice], subticks_frequency=1000, ylim=ylim)\n",
    "            viz_sequence.plot_weights((hyp_shap_scores[0] * input_seqs[0])[seq_slice], subticks_frequency=1000, ylim=ylim)\n",
    "    \n",
    "#     print(\"ISM scores\")\n",
    "#     hyp_ism_scores = compute_ism.get_binary_model_ism(model, input_seqs, task_index=task_index)\n",
    "#     plot_signal(np.sum(hyp_ism_scores[0] * input_seqs[0], axis=1), title=\"ISM scores\", color=color)\n",
    "#     if show_sequences:\n",
    "#         for seq_slice in seq_slices:\n",
    "#             viz_sequence.plot_weights(hyp_ism_scores[0][seq_slice], subticks_frequency=1000)\n",
    "#             viz_sequence.plot_weights((hyp_ism_scores[0] * input_seqs[0])[seq_slice], subticks_frequency=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample some random peaks\n",
    "pos_bins[np.random.choice(len(pos_bins), size=10, replace=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The bins that show the most improvement in prior loss\n",
    "sample_bins[np.flip(np.argsort(noprior_preds[\"att_losses\"] - prior_preds[\"att_losses\"]))][:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# SPI1 vs L2\n",
    "bin_index = 3079662\n",
    "seq_slices = [slice(520, 620)]\n",
    "show_sequences = True\n",
    "predict_and_plot(noprior_model, noprior_shap_explainer, bin_index, False, show_sequences, seq_slices)\n",
    "predict_and_plot(prior_model, prior_shap_explainer, bin_index, True, show_sequences, seq_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SPI1 vs L2\n",
    "bin_index = 4612843\n",
    "seq_slices = [slice(400, 600), slice(325, 375), slice(710, 810)]\n",
    "show_sequences = True\n",
    "predict_and_plot(noprior_model, noprior_shap_explainer, bin_index, False, show_sequences, seq_slices)\n",
    "predict_and_plot(prior_model, prior_shap_explainer, bin_index, True, show_sequences, seq_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# SPI1\n",
    "bin_index = 577670\n",
    "seq_slices = [slice(400, 600)]\n",
    "show_sequences = True\n",
    "predict_and_plot(noprior_model, noprior_shap_explainer, bin_index, False, show_sequences, seq_slices)\n",
    "predict_and_plot(prior_model, prior_shap_explainer, bin_index, True, show_sequences, seq_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# GATA2\n",
    "bin_index = 4484095\n",
    "seq_slices = [slice(225, 275), slice(300, 500)]\n",
    "show_sequences = True\n",
    "predict_and_plot(noprior_model, noprior_shap_explainer, bin_index, False, show_sequences, seq_slices)\n",
    "predict_and_plot(prior_model, prior_shap_explainer, bin_index, True, show_sequences, seq_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# K562\n",
    "bin_index = 2254287\n",
    "seq_slices = [slice(425, 475), slice(600, 650)]\n",
    "show_sequences = True\n",
    "predict_and_plot(noprior_model, noprior_shap_explainer, bin_index, False, show_sequences, seq_slices)\n",
    "predict_and_plot(prior_model, prior_shap_explainer, bin_index, True, show_sequences, seq_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# BPNet\n",
    "bin_index = 1444378  # Nanog\n",
    "seq_slices = [slice(475, 575)]\n",
    "show_sequences = True\n",
    "predict_and_plot(noprior_model, noprior_shap_explainer, bin_index, False, show_sequences, seq_slices)\n",
    "predict_and_plot(prior_model, prior_shap_explainer, bin_index, True, show_sequences, seq_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# BPNet\n",
    "bin_index = 2998255  # Nanog\n",
    "seq_slices = [slice(450, 550)]\n",
    "show_sequences = True\n",
    "predict_and_plot(noprior_model, noprior_shap_explainer, bin_index, False, show_sequences, seq_slices)\n",
    "predict_and_plot(prior_model, prior_shap_explainer, bin_index, True, show_sequences, seq_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# BPNet\n",
    "bin_index = 2546769  # Nanog\n",
    "seq_slices = [slice(600, 700)]\n",
    "show_sequences = True\n",
    "predict_and_plot(noprior_model, noprior_shap_explainer, bin_index, False, show_sequences, seq_slices)\n",
    "predict_and_plot(prior_model, prior_shap_explainer, bin_index, True, show_sequences, seq_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# BPNet\n",
    "bin_index = 1790322  # Nanog\n",
    "seq_slices = [slice(600, 700)]\n",
    "show_sequences = True\n",
    "predict_and_plot(noprior_model, noprior_shap_explainer, bin_index, False, show_sequences, seq_slices)\n",
    "predict_and_plot(prior_model, prior_shap_explainer, bin_index, True, show_sequences, seq_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# BPNet outside peaks\n",
    "bin_index = 96866  # Agg\n",
    "seq_slices = [slice(900, 950)]\n",
    "show_sequences = True\n",
    "predict_and_plot(noprior_model, noprior_shap_explainer, bin_index, False, show_sequences, seq_slices)\n",
    "predict_and_plot(prior_model, prior_shap_explainer, bin_index, True, show_sequences, seq_slices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
