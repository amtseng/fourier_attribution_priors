{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_metrics_json(models_path, run_num):\n",
    "    \"\"\"\n",
    "    Looks in {models_path}/{run_num}/metrics.json and returns the contents as a\n",
    "    Python dictionary. Returns None if the path does not exist.\n",
    "    \"\"\"\n",
    "    path = os.path.join(models_path, str(run_num), \"metrics.json\")\n",
    "    if not os.path.exists(path):\n",
    "        return None\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_metric(models_path, metric_name, reduce_func, compare_func):\n",
    "    \"\"\"\n",
    "    Given the path to a set of runs, determines the run with the best metric value,\n",
    "    for the given `metric_name`. For each run, the function `reduce_func` must take\n",
    "    the array of all values for that metric and return a (scalar) value to use for\n",
    "    comparison. The best metric value is determined by `metric_compare_func`, which\n",
    "    must take in two arguments, and return whether or not the _first_ one is better.\n",
    "    Returns the number of the run, the value associated with that run, and a dict of\n",
    "    all the values used for comparison.\n",
    "    \"\"\"\n",
    "    # Get the metrics, ignoring empty or nonexistent metrics.json files\n",
    "    metrics = {run_num : import_metrics_json(models_path, run_num) for run_num in os.listdir(models_path)}\n",
    "    metrics = {key : val for key, val in metrics.items() if val}  # Remove empties\n",
    "    \n",
    "    # Get the best value\n",
    "    best_run, best_val, all_vals = None, None, {}\n",
    "    for run_num in metrics.keys():\n",
    "        try:\n",
    "            val = reduce_func(metrics[run_num][metric_name][\"values\"])\n",
    "            all_vals[run_num] = val\n",
    "            if best_val is None or compare_func(val, best_val):\n",
    "                best_val, best_run = val, run_num\n",
    "        except Exception:\n",
    "            print(\"Warning: Was not able to compute values for run %s\" % run_num)\n",
    "            continue\n",
    "    return best_run, best_val, all_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_metric_at_best_epoch(models_path, metric_name, reduce_func, compare_func):\n",
    "    \"\"\"\n",
    "    Given the path to a set of runs, determines the run with the best metric value,\n",
    "    for the given `metric_name`. For each run, the function `reduce_func` must take\n",
    "    the array of all values for that metric and return a (scalar) value FOR EACH\n",
    "    SUBARRAY/VALUE in the value array to use for comparison. The best metric value\n",
    "    is determined by `metric_compare_func`, which must take in two arguments, and\n",
    "    return whether or not the _first_ one is better.\n",
    "    Returns the number of the run, the (one-indexed) number of the epch, the value\n",
    "    associated with that run and epoch, and a dict of all the values used for\n",
    "    comparison (mapping pair of run number and epoch number to value).\n",
    "    \"\"\"\n",
    "    # Get the metrics, ignoring empty or nonexistent metrics.json files\n",
    "    metrics = {run_num : import_metrics_json(models_path, run_num) for run_num in os.listdir(models_path)}\n",
    "    metrics = {key : val for key, val in metrics.items() if val}  # Remove empties\n",
    "    \n",
    "    # Get the best value\n",
    "    best_run, best_epoch, best_val, all_vals = None, None, None, {}\n",
    "    for run_num in metrics.keys():\n",
    "        try:\n",
    "            # Find the best epoch within that run\n",
    "            best_epoch_in_run, best_val_in_run = None, None\n",
    "            for i, subarr in enumerate(metrics[run_num][metric_name][\"values\"]):\n",
    "                val = reduce_func(subarr)\n",
    "                if best_val_in_run is None or compare_func(val, best_val_in_run):\n",
    "                    best_epoch_in_run, best_val_in_run = i + 1, val\n",
    "            all_vals[(run_num, best_epoch_in_run)] = best_val_in_run\n",
    "            \n",
    "            # If the best value in the best epoch of the run is best so far, update\n",
    "            if best_val is None or compare_func(best_val_in_run, best_val):\n",
    "                best_run, best_epoch, best_val = run_num, best_epoch_in_run, best_val_in_run\n",
    "        except Exception:\n",
    "            print(\"Warning: Was not able to compute values for run %s\" % run_num)\n",
    "            continue\n",
    "    return best_run, best_epoch, best_val, all_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def print_validation_profile_and_prior_losses(condition):\n",
    "    models_path = \"/users/amtseng/att_priors/models/trained_models/profile_models/%s/\" % condition\n",
    "    \n",
    "    print(\"Best profile loss overall:\")\n",
    "    best_run, best_epoch, best_val, all_vals = get_best_metric_at_best_epoch(\n",
    "        models_path,\n",
    "        \"val_prof_corr_losses\",\n",
    "        lambda values: np.mean(values),\n",
    "        lambda x, y: x < y\n",
    "    )\n",
    "    print(\"\\tBest run: %s\" % best_run)\n",
    "    print(\"\\tBest epoch in run: %d\" % best_epoch)\n",
    "    print(\"\\tAssociated value: %s\" % best_val)\n",
    "    \n",
    "    print(\"Best epoch in each run:\")\n",
    "    for key in sorted(all_vals.keys(), key=lambda p: int(p[0])):\n",
    "        print(\"\\tRun %s, epoch %d: %6.2f\" % (key[0], key[1], all_vals[key]))\n",
    "        \n",
    "    print(\"All validation profile and prior losses:\")\n",
    "    for key in sorted(all_vals.keys(), key=lambda p: int(p[0])):\n",
    "        print(key[0])\n",
    "        metrics = import_metrics_json(models_path, key[0])\n",
    "        print(\"\\t\" + \" \".join([\"%6.2f\" % i for i in np.mean(metrics[\"train_prof_corr_losses\"][\"values\"], axis=1)]))\n",
    "        print(\"\\t\" + \" \".join([\"%6.2f\" % i for i in np.mean(metrics[\"val_prof_corr_losses\"][\"values\"], axis=1)]))\n",
    "        print(\"\\t\" + \" \".join([\"%6.4f\" % i for i in np.mean(metrics[\"val_att_losses\"][\"values\"], axis=1)]))\n",
    "    return all_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best profile loss overall:\n",
      "\tBest run: 2\n",
      "\tBest epoch in run: 8\n",
      "\tAssociated value: 180.72518995920817\n",
      "Best epoch in each run:\n",
      "\tRun 1, epoch 10: 180.97\n",
      "\tRun 2, epoch 8: 180.73\n",
      "\tRun 3, epoch 2: 181.95\n",
      "All validation profile and prior losses:\n",
      "1\n",
      "\t200.36 194.65 193.33 192.59 192.15 191.83 191.66 191.52 191.40 191.25\n",
      "\t184.69 182.63 181.86 181.45 181.32 181.37 181.15 181.13 181.09 180.97\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "2\n",
      "\t199.41 194.43 193.20 192.45 192.04 191.73 191.50 191.35 191.22 191.14\n",
      "\t184.60 182.48 181.70 181.30 180.91 180.93 180.88 180.73 180.80 180.90\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "3\n",
      "\t198.70 193.95\n",
      "\t183.93 181.95\n",
      "\t0.0000 0.0000\n"
     ]
    }
   ],
   "source": [
    "noprior_vals = print_validation_profile_and_prior_losses(\"HepG2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best profile loss overall:\n",
      "\tBest run: 1\n",
      "\tBest epoch in run: 9\n",
      "\tAssociated value: 181.77251742045084\n",
      "Best epoch in each run:\n",
      "\tRun 1, epoch 9: 181.77\n",
      "\tRun 2, epoch 2: 183.09\n",
      "All validation profile and prior losses:\n",
      "1\n",
      "\t199.37 194.95 194.05 193.47 193.14 192.86 192.67 192.56 192.45 192.38\n",
      "\t184.64 183.46 182.80 182.50 182.20 182.05 182.10 182.17 181.77 182.11\n",
      "\t0.1124 0.0946 0.0776 0.0777 0.0766 0.0789 0.0812 0.0818 0.0797 0.0826\n",
      "2\n",
      "\t199.63 195.21\n",
      "\t184.50 183.09\n",
      "\t0.1013 0.0823\n"
     ]
    }
   ],
   "source": [
    "prior_vals = print_validation_profile_and_prior_losses(\"HepG2_prior\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_validation_and_prior_losses(condition):\n",
    "    models_path = \"/users/amtseng/att_priors/models/trained_models/binary_models/%s/\" % condition\n",
    "    \n",
    "    print(\"Best validation loss overall:\")\n",
    "    best_run, best_epoch, best_val, all_vals = get_best_metric_at_best_epoch(\n",
    "        models_path,\n",
    "        \"val_corr_losses\",\n",
    "        lambda values: np.mean(values),\n",
    "        lambda x, y: x < y\n",
    "    )\n",
    "    print(\"\\tBest run: %s\" % best_run)\n",
    "    print(\"\\tBest epoch in run: %d\" % best_epoch)\n",
    "    print(\"\\tAssociated value: %s\" % best_val)\n",
    "    \n",
    "    print(\"Best epoch in each run:\")\n",
    "    for key in sorted(all_vals.keys(), key=lambda p: int(p[0])):\n",
    "        print(\"\\tRun %s, epoch %d: %6.3f\" % (key[0], key[1], all_vals[key]))\n",
    "        \n",
    "    print(\"All validation profile and prior losses:\")\n",
    "    for key in sorted(all_vals.keys(), key=lambda p: int(p[0])):\n",
    "        print(key[0])\n",
    "        metrics = import_metrics_json(models_path, key[0])\n",
    "        print(\"\\t\" + \" \".join([\"%6.3f\" % i for i in np.mean(metrics[\"train_corr_losses\"][\"values\"], axis=1)]))\n",
    "        print(\"\\t\" + \" \".join([\"%6.3f\" % i for i in np.mean(metrics[\"val_corr_losses\"][\"values\"], axis=1)]))\n",
    "        print(\"\\t\" + \" \".join([\"%6.3f\" % i for i in np.mean(metrics[\"val_att_losses\"][\"values\"], axis=1)]))\n",
    "    return all_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss overall:\n",
      "\tBest run: 3\n",
      "\tBest epoch in run: 1\n",
      "\tAssociated value: 0.24186948145690718\n",
      "Best epoch in each run:\n",
      "\tRun 1, epoch 1:  0.260\n",
      "\tRun 2, epoch 1:  0.261\n",
      "\tRun 3, epoch 1:  0.242\n",
      "All validation profile and prior losses:\n",
      "1\n",
      "\t 0.249  0.194  0.166  0.146  0.129  0.115  0.105  0.098  0.092  0.088\n",
      "\t 0.260  0.274  0.300  0.341  0.356  0.375  0.403  0.432  0.435  0.464\n",
      "\t 0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000\n",
      "2\n",
      "\t 0.250  0.195  0.167  0.148  0.134  0.123  0.115  0.107  0.099  0.091\n",
      "\t 0.261  0.269  0.293  0.332  0.348  0.378  0.389  0.436  0.434  0.458\n",
      "\t 0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000\n",
      "3\n",
      "\t 0.239  0.180\n",
      "\t 0.242  0.259\n",
      "\t 0.000  0.000\n"
     ]
    }
   ],
   "source": [
    "noprior_vals = print_validation_and_prior_losses(\"HepG2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss overall:\n",
      "\tBest run: 1\n",
      "\tBest epoch in run: 5\n",
      "\tAssociated value: 0.24833823553564255\n",
      "Best epoch in each run:\n",
      "\tRun 1, epoch 5:  0.248\n",
      "All validation profile and prior losses:\n",
      "1\n",
      "\t 0.329  0.288  0.272  0.247  0.219  0.201  0.188\n",
      "\t 0.322  0.293  0.302  0.262  0.248  0.254  0.261\n",
      "\t 0.079  0.068  0.081  0.041  0.035  0.035  0.032\n"
     ]
    }
   ],
   "source": [
    "prior_vals = print_validation_and_prior_losses(\"HepG2_prior\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f99bb67f7d0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bin_num = 20\n",
    "plt.figure()\n",
    "plt.hist(\n",
    "    [np.array(list(noprior_vals.values())), np.array(list(prior_vals.values()))],\n",
    "    bin_num, histtype=\"bar\",\n",
    "    label=[\"No prior\", \"With prior\"], color=[\"red\", \"blue\"])\n",
    "title = \"Histogram of validation loss\"\n",
    "title += \"\\nTraining on only 1% of positive bins\"\n",
    "plt.title(title)\n",
    "plt.xlabel(\"Validation profile loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.2640587687389155\n",
      "5.566017270666034e-05\n"
     ]
    }
   ],
   "source": [
    "np_vals, p_vals = np.array(list(noprior_vals.values())), np.array(list(prior_vals.values()))\n",
    "t, p = scipy.stats.ttest_ind(np_vals, p_vals)\n",
    "print(t)\n",
    "print(p / 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
