{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_metrics_json(models_path, run_num):\n",
    "    \"\"\"\n",
    "    Looks in {models_path}/{run_num}/metrics.json and returns the contents as a\n",
    "    Python dictionary. Returns None if the path does not exist.\n",
    "    \"\"\"\n",
    "    path = os.path.join(models_path, str(run_num), \"metrics.json\")\n",
    "    if not os.path.exists(path):\n",
    "        return None\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_metric(models_path, metric_name, reduce_func, compare_func):\n",
    "    \"\"\"\n",
    "    Given the path to a set of runs, determines the run with the best metric value,\n",
    "    for the given `metric_name`. For each run, the function `reduce_func` must take\n",
    "    the array of all values for that metric and return a (scalar) value to use for\n",
    "    comparison. The best metric value is determined by `metric_compare_func`, which\n",
    "    must take in two arguments, and return whether or not the _first_ one is better.\n",
    "    Returns the number of the run, the value associated with that run, and a dict of\n",
    "    all the values used for comparison.\n",
    "    \"\"\"\n",
    "    # Get the metrics, ignoring empty or nonexistent metrics.json files\n",
    "    metrics = {run_num : import_metrics_json(models_path, run_num) for run_num in os.listdir(models_path)}\n",
    "    metrics = {key : val for key, val in metrics.items() if val}  # Remove empties\n",
    "    \n",
    "    # Get the best value\n",
    "    best_run, best_val, all_vals = None, None, {}\n",
    "    for run_num in metrics.keys():\n",
    "        try:\n",
    "            val = reduce_func(metrics[run_num][metric_name][\"values\"])\n",
    "            all_vals[run_num] = val\n",
    "            if best_val is None or compare_func(val, best_val):\n",
    "                best_val, best_run = val, run_num\n",
    "        except Exception:\n",
    "            print(\"Warning: Was not able to compute values for run %s\" % run_num)\n",
    "            continue\n",
    "    return best_run, best_val, all_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_metric_at_best_epoch(models_path, metric_name, reduce_func, compare_func):\n",
    "    \"\"\"\n",
    "    Given the path to a set of runs, determines the run with the best metric value,\n",
    "    for the given `metric_name`. For each run, the function `reduce_func` must take\n",
    "    the array of all values for that metric and return a (scalar) value FOR EACH\n",
    "    SUBARRAY/VALUE in the value array to use for comparison. The best metric value\n",
    "    is determined by `metric_compare_func`, which must take in two arguments, and\n",
    "    return whether or not the _first_ one is better.\n",
    "    Returns the number of the run, the (one-indexed) number of the epch, the value\n",
    "    associated with that run and epoch, and a dict of all the values used for\n",
    "    comparison (mapping pair of run number and epoch number to value).\n",
    "    \"\"\"\n",
    "    # Get the metrics, ignoring empty or nonexistent metrics.json files\n",
    "    metrics = {run_num : import_metrics_json(models_path, run_num) for run_num in os.listdir(models_path)}\n",
    "    metrics = {key : val for key, val in metrics.items() if val}  # Remove empties\n",
    "    \n",
    "    # Get the best value\n",
    "    best_run, best_epoch, best_val, all_vals = None, None, None, {}\n",
    "    for run_num in metrics.keys():\n",
    "        try:\n",
    "            # Find the best epoch within that run\n",
    "            best_epoch_in_run, best_val_in_run = None, None\n",
    "            for i, subarr in enumerate(metrics[run_num][metric_name][\"values\"]):\n",
    "                val = reduce_func(subarr)\n",
    "                if best_val_in_run is None or compare_func(val, best_val_in_run):\n",
    "                    best_epoch_in_run, best_val_in_run = i + 1, val\n",
    "            all_vals[(run_num, best_epoch_in_run)] = best_val_in_run\n",
    "            \n",
    "            # If the best value in the best epoch of the run is best so far, update\n",
    "            if best_val is None or compare_func(best_val_in_run, best_val):\n",
    "                best_run, best_epoch, best_val = run_num, best_epoch_in_run, best_val_in_run\n",
    "        except Exception:\n",
    "            print(\"Warning: Was not able to compute values for run %s\" % run_num)\n",
    "            continue\n",
    "    return best_run, best_epoch, best_val, all_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best run: 7\n",
      "Best epoch in run: 1\n",
      "Associated value: 89.94859203334525\n",
      "('1', 5) 92.87491922347809\n",
      "('2', 2) 91.81298261861669\n",
      "('3', 3) 90.98503513520565\n",
      "('4', 4) 91.65070682283887\n",
      "('5', 7) 92.79284542587723\n",
      "('6', 1) 90.31572375108041\n",
      "('7', 1) 89.94859203334525\n",
      "('8', 1) 90.88748335300532\n",
      "('9', 3) 94.3520067339937\n",
      "('10', 1) 90.28025521627686\n",
      "('11', 10) 93.6835513662959\n",
      "('12', 2) 91.68056812552709\n",
      "('13', 1) 90.3932429886274\n",
      "('14', 1) 90.75675676716642\n",
      "('15', 6) 92.59214978571481\n"
     ]
    }
   ],
   "source": [
    "models_path = \"/users/amtseng/att_priors/models/trained_models/profile_models/SPI1_prior/\"\n",
    "best_run, best_epoch, best_val, all_vals = get_best_metric_at_best_epoch(\n",
    "    models_path,\n",
    "    \"val_prof_corr_losses\",\n",
    "    lambda values: np.mean(values),\n",
    "    lambda x, y: x < y\n",
    ")\n",
    "print(\"Best run: %s\" % best_run)\n",
    "print(\"Best epoch in run: %d\" % best_epoch)\n",
    "print(\"Associated value: %s\" % best_val)\n",
    "for key in sorted(all_vals.keys(), key=lambda p: int(p[0])):\n",
    "    print(key, all_vals[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[94.37510603 93.54147481 93.86899592 92.90773183 92.87491922 93.15681116\n",
      " 93.34095781 93.13254945 94.30564022 93.53211262]\n",
      "[0.23614891 0.07265516 0.05968027 0.04774254 0.04080145 0.03647423\n",
      " 0.03300492 0.03081511 0.02749416 0.027668  ]\n",
      "2\n",
      "[ 92.35735941  91.81298262  93.71755831  93.8992644   94.86775387\n",
      "  96.28630551  98.04736373 102.45802585 106.65216831 125.23091452]\n",
      "[0.14959264 0.06180098 0.04442908 0.02954582 0.03102257 0.02951256\n",
      " 0.02865808 0.02427959 0.02407855 0.24149895]\n",
      "3\n",
      "[91.73066505 91.22965849 90.98503514 91.08862228 91.74752596 91.78483883\n",
      " 92.40955055 92.27776492 94.53128618 93.94874115]\n",
      "[0.16432875 0.06235689 0.04442935 0.03651058 0.0315486  0.03033786\n",
      " 0.02869359 0.02991026 0.02721583 0.02920703]\n",
      "4\n",
      "[92.18479015 92.03698236 91.6579977  91.65070682 91.80126954 92.78554964\n",
      " 91.71918688 92.11625637 92.87797818 93.136613  ]\n",
      "[0.1871363  0.06845363 0.04990551 0.0386693  0.03243457 0.0281125\n",
      " 0.02836284 0.0293305  0.02916564 0.02901448]\n",
      "5\n",
      "[93.57477461 93.27071851 92.95506118 92.79894633 92.86720174 93.21799576\n",
      " 92.79284543 93.65637232 93.67623011 93.65379486]\n",
      "[0.16365955 0.07433702 0.05618095 0.0428856  0.03840313 0.03277555\n",
      " 0.0323126  0.02802484 0.02665406 0.0266461 ]\n",
      "6\n",
      "[ 90.31572375  91.02309557  92.18227772  92.53126248  93.14462928\n",
      "  94.07749175  95.53463859 100.38485118 101.53409802 102.21473901]\n",
      "[0.15564999 0.05899242 0.04134651 0.03634255 0.02928536 0.02882974\n",
      " 0.0289113  0.02238322 0.02617793 0.02212006]\n",
      "7\n",
      "[ 89.94859203  90.51733346  91.49991205  92.27029895  92.61809144\n",
      "  93.60389927  94.86693113  97.18416601  99.53872962 102.39954433]\n",
      "[0.16466253 0.05605814 0.04605331 0.03619196 0.03258386 0.02984588\n",
      " 0.02810004 0.02520516 0.02483904 0.02810174]\n",
      "8\n",
      "[90.88748335 90.91703688 91.99032866 92.7011716  92.59084333 93.17990923\n",
      " 95.00269014 95.24830816 97.41348871 97.23017089]\n",
      "[0.14602916 0.0594681  0.0451276  0.03559071 0.03520644 0.0263633\n",
      " 0.0263377  0.02598185 0.02450598 0.02778236]\n",
      "9\n",
      "[94.61969358 95.00672708 94.35200673 94.55715231 94.93861981 94.80140391\n",
      " 94.56905871 95.00441258 95.23800276 97.01170435]\n",
      "[0.25093863 0.07014286 0.05863281 0.04878229 0.03832215 0.03244559\n",
      " 0.02905928 0.02537723 0.02658247 0.0228112 ]\n",
      "10\n",
      "[ 90.28025522  90.97937181  92.09127857  93.25905043  94.67636562\n",
      "  95.69000929  96.08936407  97.41818272 101.12775962 103.69793901]\n",
      "[0.15420799 0.05748974 0.04679252 0.04332937 0.03217648 0.03263907\n",
      " 0.03514686 0.02413138 0.02532452 0.03115819]\n",
      "11\n",
      "[100.46248263  95.02860244  94.17152662  93.99510454  93.82584536\n",
      "  93.72228502  93.71211441  93.77107719  93.75599663  93.68355137]\n",
      "[0.28933845 0.08863713 0.06430207 0.05141747 0.04390012 0.04026324\n",
      " 0.03547067 0.03443865 0.03187618 0.03242475]\n",
      "12\n",
      "[92.26470644 91.68056813 92.35246493 92.92370792 93.28738085 93.04431627\n",
      " 93.75835061 96.20940966 95.07231014 95.67765766]\n",
      "[0.1514452  0.06809635 0.04857733 0.04025432 0.03313311 0.02888065\n",
      " 0.02551235 0.02687096 0.02519497 0.0247308 ]\n",
      "13\n",
      "[90.39324299 90.63327989 91.43817565 92.120006   92.58003568 92.87229738\n",
      " 94.7474936  94.10337528 95.05159465 97.2392058 ]\n",
      "[0.15147401 0.05965398 0.04719907 0.03447462 0.03195435 0.0330707\n",
      " 0.02854613 0.02388633 0.02329505 0.02362801]\n",
      "14\n",
      "[90.75675677 90.78152009 92.1112038  92.55340401 92.81119223 93.22701847\n",
      " 94.50887334 94.2853697  96.49738531 99.79278724]\n",
      "[0.16981758 0.06093135 0.04432217 0.03651569 0.03009209 0.02967894\n",
      " 0.02917989 0.02690344 0.02663245 0.02312912]\n",
      "15\n",
      "[93.40645214 93.01962552 92.80672509 93.16473152 92.71934749 92.59214979\n",
      " 92.74537106 92.92211185 93.20245676 93.14051961]\n",
      "[0.20007468 0.0795914  0.05984298 0.04307026 0.03874408 0.03356465\n",
      " 0.03021865 0.02953428 0.0311627  0.02920394]\n"
     ]
    }
   ],
   "source": [
    "for key in sorted(all_vals.keys(), key=lambda p: int(p[0])):\n",
    "    print(key[0])\n",
    "    metrics = import_metrics_json(models_path, key[0])\n",
    "    print(np.mean(metrics[\"val_prof_corr_losses\"][\"values\"], axis=1))\n",
    "    print(np.mean(metrics[\"val_pos_att_losses\"][\"values\"], axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
