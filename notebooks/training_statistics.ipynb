{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_metrics_json(models_path, run_num):\n",
    "    \"\"\"\n",
    "    Looks in {models_path}/{run_num}/metrics.json and returns the contents as a\n",
    "    Python dictionary. Returns None if the path does not exist.\n",
    "    \"\"\"\n",
    "    path = os.path.join(models_path, str(run_num), \"metrics.json\")\n",
    "    if not os.path.exists(path):\n",
    "        return None\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_metric(models_path, metric_name, reduce_func, compare_func):\n",
    "    \"\"\"\n",
    "    Given the path to a set of runs, determines the run with the best metric value,\n",
    "    for the given `metric_name`. For each run, the function `reduce_func` must take\n",
    "    the array of all values for that metric and return a (scalar) value to use for\n",
    "    comparison. The best metric value is determined by `metric_compare_func`, which\n",
    "    must take in two arguments, and return whether or not the _first_ one is better.\n",
    "    Returns the number of the run, the value associated with that run, and a dict of\n",
    "    all the values used for comparison.\n",
    "    \"\"\"\n",
    "    # Get the metrics, ignoring empty or nonexistent metrics.json files\n",
    "    metrics = {run_num : import_metrics_json(models_path, run_num) for run_num in os.listdir(models_path)}\n",
    "    metrics = {key : val for key, val in metrics.items() if val}  # Remove empties\n",
    "    \n",
    "    # Get the best value\n",
    "    best_run, best_val, all_vals = None, None, {}\n",
    "    for run_num in metrics.keys():\n",
    "        try:\n",
    "            val = reduce_func(metrics[run_num][metric_name][\"values\"])\n",
    "            all_vals[run_num] = val\n",
    "            if best_val is None or compare_func(val, best_val):\n",
    "                best_val, best_run = val, run_num\n",
    "        except Exception:\n",
    "            print(\"Warning: Was not able to compute values for run %s\" % run_num)\n",
    "            continue\n",
    "    return best_run, best_val, all_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_metric_at_best_epoch(models_path, metric_name, reduce_func, compare_func):\n",
    "    \"\"\"\n",
    "    Given the path to a set of runs, determines the run with the best metric value,\n",
    "    for the given `metric_name`. For each run, the function `reduce_func` must take\n",
    "    the array of all values for that metric and return a (scalar) value FOR EACH\n",
    "    SUBARRAY/VALUE in the value array to use for comparison. The best metric value\n",
    "    is determined by `metric_compare_func`, which must take in two arguments, and\n",
    "    return whether or not the _first_ one is better.\n",
    "    Returns the number of the run, the (one-indexed) number of the epch, the value\n",
    "    associated with that run and epoch, and a dict of all the values used for\n",
    "    comparison (mapping pair of run number and epoch number to value).\n",
    "    \"\"\"\n",
    "    # Get the metrics, ignoring empty or nonexistent metrics.json files\n",
    "    metrics = {run_num : import_metrics_json(models_path, run_num) for run_num in os.listdir(models_path)}\n",
    "    metrics = {key : val for key, val in metrics.items() if val}  # Remove empties\n",
    "    \n",
    "    # Get the best value\n",
    "    best_run, best_epoch, best_val, all_vals = None, None, None, {}\n",
    "    for run_num in metrics.keys():\n",
    "        try:\n",
    "            # Find the best epoch within that run\n",
    "            best_epoch_in_run, best_val_in_run = None, None\n",
    "            for i, subarr in enumerate(metrics[run_num][metric_name][\"values\"]):\n",
    "                val = reduce_func(subarr)\n",
    "                if best_val_in_run is None or compare_func(val, best_val_in_run):\n",
    "                    best_epoch_in_run, best_val_in_run = i + 1, val\n",
    "            all_vals[(run_num, best_epoch_in_run)] = best_val_in_run\n",
    "            \n",
    "            # If the best value in the best epoch of the run is best so far, update\n",
    "            if best_val is None or compare_func(best_val_in_run, best_val):\n",
    "                best_run, best_epoch, best_val = run_num, best_epoch_in_run, best_val_in_run\n",
    "        except Exception:\n",
    "            print(\"Warning: Was not able to compute values for run %s\" % run_num)\n",
    "            continue\n",
    "    return best_run, best_epoch, best_val, all_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def print_validation_profile_and_prior_losses(condition):\n",
    "    models_path = \"/users/amtseng/att_priors/models/trained_models/profile_models/%s/\" % condition\n",
    "    \n",
    "    print(\"Best profile loss overall:\")\n",
    "    best_run, best_epoch, best_val, all_vals = get_best_metric_at_best_epoch(\n",
    "        models_path,\n",
    "        \"val_prof_corr_losses\",\n",
    "        lambda values: np.mean(values),\n",
    "        lambda x, y: x < y\n",
    "    )\n",
    "    print(\"\\tBest run: %s\" % best_run)\n",
    "    print(\"\\tBest epoch in run: %d\" % best_epoch)\n",
    "    print(\"\\tAssociated value: %s\" % best_val)\n",
    "    \n",
    "    print(\"Best epoch in each run:\")\n",
    "    for key in sorted(all_vals.keys(), key=lambda p: int(p[0])):\n",
    "        print(\"\\tRun %s, epoch %d: %6.2f\" % (key[0], key[1], all_vals[key]))\n",
    "        \n",
    "    print(\"All validation profile and prior losses:\")\n",
    "    for key in sorted(all_vals.keys(), key=lambda p: int(p[0])):\n",
    "        print(key[0])\n",
    "        metrics = import_metrics_json(models_path, key[0])\n",
    "        print(\"\\t\" + \" \".join([\"%6.2f\" % i for i in np.mean(metrics[\"val_prof_corr_losses\"][\"values\"], axis=1)]))\n",
    "        print(\"\\t\" + \" \".join([\"%6.4f\" % i for i in np.mean(metrics[\"val_pos_att_losses\"][\"values\"], axis=1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best profile loss overall:\n",
      "\tBest run: 33\n",
      "\tBest epoch in run: 10\n",
      "\tAssociated value: 88.52770374925001\n",
      "Best epoch in each run:\n",
      "\tRun 1, epoch 9:  90.26\n",
      "\tRun 2, epoch 9:  89.05\n",
      "\tRun 3, epoch 10:  89.23\n",
      "\tRun 4, epoch 7:  89.27\n",
      "\tRun 5, epoch 10:  88.99\n",
      "\tRun 6, epoch 10:  89.62\n",
      "\tRun 7, epoch 10:  89.21\n",
      "\tRun 8, epoch 10:  89.20\n",
      "\tRun 9, epoch 9:  89.67\n",
      "\tRun 10, epoch 10:  88.76\n",
      "\tRun 11, epoch 10:  89.58\n",
      "\tRun 12, epoch 10:  89.80\n",
      "\tRun 13, epoch 8:  88.60\n",
      "\tRun 14, epoch 10:  88.99\n",
      "\tRun 15, epoch 2:  90.67\n",
      "\tRun 16, epoch 5:  89.56\n",
      "\tRun 17, epoch 10:  89.77\n",
      "\tRun 18, epoch 10:  89.92\n",
      "\tRun 19, epoch 10:  89.03\n",
      "\tRun 20, epoch 10:  89.54\n",
      "\tRun 21, epoch 4:  89.97\n",
      "\tRun 22, epoch 10:  89.68\n",
      "\tRun 23, epoch 10:  89.58\n",
      "\tRun 24, epoch 10:  88.78\n",
      "\tRun 25, epoch 10:  90.40\n",
      "\tRun 26, epoch 10:  88.83\n",
      "\tRun 27, epoch 10:  89.36\n",
      "\tRun 28, epoch 8:  90.63\n",
      "\tRun 29, epoch 10:  89.49\n",
      "\tRun 30, epoch 10:  89.11\n",
      "\tRun 31, epoch 10:  89.05\n",
      "\tRun 32, epoch 8:  89.25\n",
      "\tRun 33, epoch 10:  88.53\n",
      "\tRun 34, epoch 10:  89.71\n",
      "\tRun 35, epoch 9:  88.58\n",
      "\tRun 36, epoch 9:  89.06\n",
      "\tRun 37, epoch 9:  88.97\n",
      "\tRun 38, epoch 10:  89.31\n",
      "\tRun 39, epoch 10:  89.78\n",
      "\tRun 40, epoch 10:  90.09\n",
      "\tRun 41, epoch 5:  90.26\n",
      "\tRun 42, epoch 10:  89.82\n",
      "\tRun 43, epoch 10:  89.20\n",
      "\tRun 44, epoch 10:  89.46\n",
      "\tRun 45, epoch 10:  89.40\n",
      "\tRun 46, epoch 10:  89.50\n",
      "\tRun 47, epoch 10:  89.53\n",
      "\tRun 48, epoch 7:  90.04\n",
      "\tRun 49, epoch 9:  89.14\n",
      "\tRun 50, epoch 10:  88.77\n",
      "All validation profile and prior losses:\n",
      "1\n",
      "\t 90.88  90.69  90.64  90.41  90.57  90.51  90.41  90.42  90.26  90.49\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "2\n",
      "\t 90.88  89.84  89.51  89.26  89.17  89.15  89.15  89.17  89.05  89.06\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "3\n",
      "\t 92.80  91.46  90.69  90.07  89.62  89.47  89.45  89.33  89.31  89.23\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "4\n",
      "\t 90.35  89.74  89.46  89.39  89.30  89.32  89.27  89.41  89.37  89.34\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "5\n",
      "\t 91.41  90.44  89.81  89.54  89.45  89.22  89.11  89.12  89.05  88.99\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "6\n",
      "\t 94.57  92.28  91.50  90.94  90.57  90.26  90.08  90.02  89.82  89.62\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "7\n",
      "\t 92.40  90.60  89.91  89.64  89.53  89.33  89.37  89.24  89.22  89.21\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "8\n",
      "\t 91.12  90.07  89.81  89.59  89.61  89.35  89.35  89.36  89.27  89.20\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "9\n",
      "\t 90.37  90.04  89.85  89.81  89.78  89.86  89.91  89.86  89.67  89.80\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "10\n",
      "\t 93.23  90.92  90.30  89.82  89.52  89.26  89.09  88.99  88.85  88.76\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "11\n",
      "\t 93.48  92.20  91.33  90.98  90.57  90.22  90.01  89.81  89.74  89.58\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "12\n",
      "\t 93.89  92.49  91.54  91.18  90.79  90.48  90.28  90.12  90.20  89.80\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "13\n",
      "\t 90.32  89.35  89.01  88.73  88.85  88.74  88.62  88.60  88.67  88.62\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "14\n",
      "\t 92.21  90.52  89.93  89.60  89.37  89.27  89.20  89.15  89.09  88.99\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "15\n",
      "\t 91.27  90.67  91.03  90.89  90.75  91.02  90.80  90.78  90.83  90.71\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "16\n",
      "\t 90.71  90.01  89.77  89.64  89.56  89.63  89.57  89.69  89.64  89.72\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "17\n",
      "\t 93.81  92.27  91.58  91.09  90.77  90.40  90.05  89.92  89.87  89.77\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "18\n",
      "\t 94.27  92.64  91.83  91.37  91.00  90.69  90.38  90.14  90.04  89.92\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "19\n",
      "\t 91.57  89.98  89.51  89.32  89.27  89.21  89.06  89.05  89.19  89.03\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "20\n",
      "\t 92.13  90.77  90.44  90.16  89.92  90.00  89.74  89.77  89.65  89.54\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "21\n",
      "\t 90.58  90.27  90.21  89.97  90.03  90.16  90.42  90.25  90.03  90.43\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "22\n",
      "\t 95.14  92.87  92.13  91.57  90.93  90.57  90.32  90.07  89.82  89.68\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "23\n",
      "\t 92.99  91.79  90.76  90.44  90.06  89.92  89.82  89.80  89.68  89.58\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "24\n",
      "\t 92.18  90.96  90.01  89.68  89.28  89.17  89.08  89.03  88.86  88.78\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "25\n",
      "\t106.98  94.40  93.02  92.69  91.77  91.28  91.16  90.83  90.54  90.40\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "26\n",
      "\t 91.28  90.31  89.65  89.30  89.18  89.08  88.92  88.91  88.94  88.83\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "27\n",
      "\t 90.47  90.58  89.50  89.49  89.48  89.37  89.74  89.71  89.47  89.36\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "28\n",
      "\t 91.86  91.08  90.94  90.82  90.79  90.75  90.85  90.63  90.70  91.02\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "29\n",
      "\t 93.47  92.04  91.33  90.75  90.29  90.03  89.85  89.74  89.53  89.49\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "30\n",
      "\t 91.36  90.30  89.76  89.63  89.57  89.42  89.30  89.14  89.16  89.11\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "31\n",
      "\t 91.68  90.64  89.85  89.57  89.58  89.31  89.25  89.24  89.11  89.05\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "32\n",
      "\t 90.61  89.80  89.58  89.46  89.52  89.31  89.27  89.25  89.34  89.35\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "33\n",
      "\t 91.35  89.71  89.29  89.15  88.84  88.73  88.69  88.67  88.58  88.53\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "34\n",
      "\t 94.51  91.71  91.06  90.64  90.37  90.19  90.03  89.81  89.74  89.71\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "35\n",
      "\t 91.07  89.72  89.23  88.96  88.95  88.85  88.71  88.62  88.58  88.59\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "36\n",
      "\t 89.96  89.54  89.32  89.20  89.11  89.14  89.13  89.10  89.06  89.19\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "37\n",
      "\t 90.47  89.65  89.31  89.22  89.12  89.17  89.15  89.03  88.97  89.01\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "38\n",
      "\t 92.70  91.40  90.39  90.15  89.90  89.64  89.60  89.51  89.43  89.31\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "39\n",
      "\t 94.16  92.76  91.77  91.24  90.89  90.61  90.27  90.12  89.92  89.78\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "40\n",
      "\t 94.69  93.08  92.18  91.63  91.29  91.10  90.54  90.30  90.16  90.09\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "41\n",
      "\t 91.09  90.55  90.60  90.47  90.26  90.28  90.34  90.34  90.45  90.38\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "42\n",
      "\t 93.77  91.91  91.14  90.77  90.60  90.41  90.22  90.08  89.98  89.82\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "43\n",
      "\t 92.22  90.56  89.93  89.64  89.57  89.37  89.22  89.28  89.23  89.20\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "44\n",
      "\t 93.35  91.67  90.89  90.50  90.05  89.76  89.69  89.57  89.51  89.46\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "45\n",
      "\t 93.09  91.86  90.91  90.27  90.01  89.82  89.65  89.58  89.51  89.40\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "46\n",
      "\t 94.30  92.38  91.69  91.16  90.53  90.12  89.96  89.68  89.57  89.50\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "47\n",
      "\t 90.39  90.00  89.94  89.59  89.59  89.67  89.62  89.83  89.74  89.53\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 91.47  90.94  90.76  90.13  90.36  90.19  90.04  90.16  90.26  90.13\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "49\n",
      "\t 91.32  90.25  89.87  89.66  89.45  89.43  89.19  89.27  89.14  89.26\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "50\n",
      "\t 92.23  90.84  90.05  89.70  89.29  89.16  89.05  88.86  89.00  88.77\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n"
     ]
    }
   ],
   "source": [
    "print_validation_profile_and_prior_losses(\"SPI1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best profile loss overall:\n",
      "\tBest run: 2\n",
      "\tBest epoch in run: 5\n",
      "\tAssociated value: 89.53327648109575\n",
      "Best epoch in each run:\n",
      "\tRun 1, epoch 6:  90.34\n",
      "\tRun 2, epoch 5:  89.53\n",
      "\tRun 3, epoch 8:  90.92\n",
      "\tRun 4, epoch 3:  91.03\n",
      "\tRun 5, epoch 7:  90.34\n",
      "\tRun 6, epoch 10:  89.66\n",
      "\tRun 7, epoch 10:  89.81\n",
      "\tRun 8, epoch 9:  90.43\n",
      "\tRun 9, epoch 2:  90.53\n",
      "All validation profile and prior losses:\n",
      "1\n",
      "\t 90.92  90.49  90.44  90.47  90.40  90.34  90.46  90.36  90.36  90.51\n",
      "\t0.1634 0.0804 0.0671 0.0627 0.0591 0.0580 0.0552 0.0542 0.0580 0.0562\n",
      "2\n",
      "\t 90.20  89.73  89.67  89.56  89.53  89.56  89.57  89.54  89.63  89.69\n",
      "\t0.1458 0.0787 0.0676 0.0619 0.0607 0.0562 0.0573 0.0561 0.0552 0.0522\n",
      "3\n",
      "\t 91.77  91.07  91.21  91.00  91.02  91.37  91.29  90.92  91.10  91.09\n",
      "\t0.1540 0.0751 0.0644 0.0631 0.0614 0.0570 0.0549 0.0553 0.0562 0.0544\n",
      "4\n",
      "\t 92.09  91.32  91.03\n",
      "\t0.1504 0.0886 0.0705\n",
      "5\n",
      "\t 90.67  90.69  90.50  90.53  90.77  90.75  90.34  90.46  90.78  90.50\n",
      "\t0.1587 0.0773 0.0666 0.0616 0.0597 0.0562 0.0574 0.0535 0.0552 0.0521\n",
      "6\n",
      "\t 91.07  90.23  90.15  89.91  89.92  89.86  89.74  89.69  89.69  89.66\n",
      "\t0.1571 0.0796 0.0669 0.0615 0.0574 0.0558 0.0552 0.0533 0.0525 0.0517\n",
      "7\n",
      "\t 90.99  90.38  90.12  90.05  90.05  89.92  89.87  89.91  89.83  89.81\n",
      "\t0.1507 0.0766 0.0675 0.0630 0.0583 0.0583 0.0551 0.0504 0.0501 0.0496\n",
      "8\n",
      "\t 93.81  92.35  91.77  91.40  91.09  90.84  90.69  90.57  90.43  90.44\n",
      "\t0.1985 0.1085 0.0845 0.0755 0.0675 0.0617 0.0581 0.0553 0.0522 0.0497\n",
      "9\n",
      "\t 90.79  90.53  90.56  90.58  90.59  90.68\n",
      "\t0.1487 0.0769 0.0687 0.0600 0.0535 0.0547\n"
     ]
    }
   ],
   "source": [
    "print_validation_profile_and_prior_losses(\"SPI1_prior_attinflate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best profile loss overall:\n",
      "\tBest run: 6\n",
      "\tBest epoch in run: 10\n",
      "\tAssociated value: 89.43545644086106\n",
      "Best epoch in each run:\n",
      "\tRun 1, epoch 10:  89.87\n",
      "\tRun 2, epoch 10:  90.15\n",
      "\tRun 3, epoch 10:  89.92\n",
      "\tRun 4, epoch 10:  90.16\n",
      "\tRun 5, epoch 10:  90.54\n",
      "\tRun 6, epoch 10:  89.44\n",
      "\tRun 7, epoch 10:  90.00\n",
      "\tRun 8, epoch 9:  90.21\n",
      "\tRun 9, epoch 6:  90.08\n",
      "All validation profile and prior losses:\n",
      "1\n",
      "\t 92.41  91.31  91.02  90.55  90.37  90.21  90.06  90.01  90.04  89.87\n",
      "\t0.0694 0.0594 0.0527 0.0496 0.0498 0.0459 0.0461 0.0446 0.0436 0.0445\n",
      "2\n",
      "\t 91.27  90.99  90.68  90.31  90.44  90.26  90.31  90.32  90.32  90.15\n",
      "\t0.0650 0.0602 0.0578 0.0557 0.0539 0.0541 0.0530 0.0538 0.0546 0.0544\n",
      "3\n",
      "\t 93.55  92.03  91.23  90.96  90.70  90.29  90.24  90.08  89.95  89.92\n",
      "\t0.0779 0.0658 0.0582 0.0539 0.0537 0.0497 0.0475 0.0474 0.0451 0.0451\n",
      "4\n",
      "\t 99.18  96.59  95.51  94.56  91.49  90.82  91.77  90.56  90.97  90.16\n",
      "\t0.0551 0.0460 0.0451 0.0358 0.0548 0.0486 0.0530 0.0459 0.0471 0.0443\n",
      "5\n",
      "\t 95.47  93.22  92.59  91.76  91.52  91.05  91.05  90.77  90.63  90.54\n",
      "\t0.1455 0.1031 0.0889 0.0758 0.0677 0.0637 0.0604 0.0601 0.0556 0.0522\n",
      "6\n",
      "\t 91.73  90.80  90.28  90.03  89.68  89.67  89.64  89.53  89.47  89.44\n",
      "\t0.0790 0.0662 0.0588 0.0554 0.0517 0.0509 0.0487 0.0476 0.0476 0.0464\n",
      "7\n",
      "\t 97.78  91.81  91.15  90.59  90.34  90.18  90.19  90.12  90.12  90.00\n",
      "\t0.0897 0.0720 0.0610 0.0577 0.0525 0.0508 0.0498 0.0478 0.0489 0.0475\n",
      "8\n",
      "\t 91.25  90.55  90.79  90.64  90.62  90.66  90.36  90.33  90.21  90.35\n",
      "\t0.0689 0.0595 0.0565 0.0574 0.0562 0.0540 0.0552 0.0531 0.0525 0.0517\n",
      "9\n",
      "\t 90.99  90.38  90.35  90.26  90.29  90.08\n",
      "\t0.0657 0.0608 0.0596 0.0567 0.0560 0.0583\n"
     ]
    }
   ],
   "source": [
    "print_validation_profile_and_prior_losses(\"SPI1_prior_attconstant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best profile loss overall:\n",
      "\tBest run: 17\n",
      "\tBest epoch in run: 9\n",
      "\tAssociated value: 203.30705208353476\n",
      "Best epoch in each run:\n",
      "\tRun 1, epoch 9: 204.14\n",
      "\tRun 2, epoch 10: 206.80\n",
      "\tRun 3, epoch 10: 208.88\n",
      "\tRun 4, epoch 10: 207.57\n",
      "\tRun 5, epoch 9: 204.24\n",
      "\tRun 6, epoch 10: 204.69\n",
      "\tRun 7, epoch 9: 208.48\n",
      "\tRun 8, epoch 9: 208.00\n",
      "\tRun 9, epoch 10: 213.23\n",
      "\tRun 10, epoch 10: 232.69\n",
      "\tRun 11, epoch 10: 204.16\n",
      "\tRun 12, epoch 10: 207.08\n",
      "\tRun 13, epoch 10: 204.09\n",
      "\tRun 14, epoch 10: 206.05\n",
      "\tRun 15, epoch 10: 209.06\n",
      "\tRun 16, epoch 10: 208.27\n",
      "\tRun 17, epoch 9: 203.31\n",
      "\tRun 18, epoch 10: 221.71\n",
      "\tRun 19, epoch 10: 208.10\n",
      "\tRun 20, epoch 10: 228.12\n",
      "\tRun 21, epoch 10: 204.62\n",
      "\tRun 22, epoch 10: 204.42\n",
      "\tRun 23, epoch 10: 225.76\n",
      "\tRun 24, epoch 10: 214.60\n",
      "\tRun 25, epoch 10: 228.51\n",
      "\tRun 26, epoch 10: 207.09\n",
      "\tRun 27, epoch 10: 210.44\n",
      "\tRun 28, epoch 10: 214.78\n",
      "\tRun 29, epoch 10: 212.19\n",
      "\tRun 30, epoch 10: 206.44\n",
      "\tRun 31, epoch 10: 219.68\n",
      "\tRun 32, epoch 10: 205.44\n",
      "\tRun 33, epoch 10: 211.25\n",
      "\tRun 34, epoch 10: 208.67\n",
      "\tRun 35, epoch 10: 219.89\n",
      "\tRun 36, epoch 10: 209.28\n",
      "\tRun 37, epoch 10: 208.09\n",
      "\tRun 38, epoch 10: 204.35\n",
      "\tRun 39, epoch 10: 211.58\n",
      "\tRun 40, epoch 10: 208.40\n",
      "\tRun 41, epoch 10: 205.74\n",
      "\tRun 42, epoch 10: 209.31\n",
      "\tRun 43, epoch 10: 205.44\n",
      "\tRun 44, epoch 10: 205.89\n",
      "\tRun 45, epoch 2: 227.45\n",
      "\tRun 46, epoch 9: 204.20\n",
      "\tRun 47, epoch 10: 205.50\n",
      "\tRun 48, epoch 10: 207.55\n",
      "\tRun 49, epoch 10: 209.44\n",
      "\tRun 50, epoch 9: 205.48\n",
      "All validation profile and prior losses:\n",
      "1\n",
      "\t212.22 209.84 209.08 207.88 206.71 205.71 205.01 204.24 204.14 204.40\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "2\n",
      "\t238.59 226.81 215.92 211.01 210.48 209.48 208.50 207.46 206.89 206.80\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "3\n",
      "\t227.70 225.18 222.83 220.10 214.52 212.44 211.17 209.90 209.92 208.88\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "4\n",
      "\t232.80 218.81 213.87 213.32 212.12 210.45 209.65 209.02 208.12 207.57\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "5\n",
      "\t218.69 211.96 209.98 208.40 207.62 206.34 205.15 205.18 204.24 204.35\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "6\n",
      "\t231.56 220.11 211.02 210.40 209.33 209.07 207.09 206.66 205.22 204.69\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "7\n",
      "\t239.47 227.85 216.02 212.72 210.69 209.17 209.13 208.74 208.48 209.11\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "8\n",
      "\t235.91 225.08 214.56 212.29 212.19 211.82 209.26 208.83 208.00 208.08\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "9\n",
      "\t248.03 235.44 219.80 217.57 217.03 216.40 215.82 214.30 213.36 213.23\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "10\n",
      "\t253.72 248.31 247.88 248.40 247.90 247.09 246.39 241.70 238.33 232.69\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "11\n",
      "\t226.68 213.32 211.17 210.08 207.68 207.62 206.96 204.81 204.40 204.16\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "12\n",
      "\t240.31 226.01 219.64 212.44 211.48 209.66 209.22 210.43 207.71 207.08\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "13\n",
      "\t228.04 218.99 211.01 210.02 208.92 207.34 206.66 206.55 204.89 204.09\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "14\n",
      "\t244.98 226.44 213.60 211.41 210.85 209.15 208.91 207.80 206.71 206.05\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "15\n",
      "\t227.63 217.81 213.60 212.56 211.31 211.33 210.26 209.58 209.35 209.06\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "16\n",
      "\t226.34 223.69 219.06 215.90 211.98 210.58 209.88 209.02 208.79 208.27\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "17\n",
      "\t213.83 210.64 208.27 206.66 204.99 204.78 204.06 203.51 203.31 203.45\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "18\n",
      "\t247.90 245.30 244.17 239.75 237.37 229.80 227.45 225.89 224.87 221.71\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "19\n",
      "\t246.18 228.51 219.96 215.48 215.18 211.57 211.00 210.51 209.75 208.10\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "20\n",
      "\t246.63 245.53 242.09 241.87 240.45 238.97 234.86 231.32 229.34 228.12\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "21\n",
      "\t235.86 224.35 217.86 212.37 209.07 207.50 206.74 206.15 205.16 204.62\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "22\n",
      "\t229.77 213.11 210.50 209.92 211.24 209.00 206.69 205.95 207.65 204.42\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "23\n",
      "\t245.85 244.93 244.03 238.91 237.04 235.26 233.15 227.56 225.99 225.76\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "24\n",
      "\t248.63 243.67 240.01 237.42 231.25 227.99 222.48 219.13 215.86 214.60\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "25\n",
      "\t250.38 250.83 244.61 243.16 240.05 235.48 231.48 230.35 229.16 228.51\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "26\n",
      "\t239.39 230.60 225.04 218.29 212.75 211.37 209.99 208.44 207.75 207.09\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "27\n",
      "\t241.05 230.71 226.94 223.25 218.86 214.45 212.52 211.49 210.75 210.44\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "28\n",
      "\t246.78 241.44 238.33 229.00 228.69 226.09 223.22 221.99 218.52 214.78\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "29\n",
      "\t243.24 237.91 229.04 227.99 225.29 221.94 218.16 214.81 213.77 212.19\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "30\n",
      "\t235.15 223.54 214.94 214.05 211.39 210.07 209.02 207.79 207.30 206.44\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "31\n",
      "\t244.97 239.91 237.77 235.65 233.37 226.97 224.88 223.95 222.06 219.68\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "32\n",
      "\t216.37 214.11 212.23 211.28 208.64 208.21 206.89 206.29 205.93 205.44\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "33\n",
      "\t244.33 239.41 237.97 228.21 226.20 223.00 218.10 214.42 212.01 211.25\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "34\n",
      "\t240.64 231.37 229.53 221.21 213.65 211.49 211.24 210.01 208.90 208.67\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "35\n",
      "\t246.39 245.26 241.33 239.22 235.28 228.63 226.88 225.41 222.71 219.89\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "36\n",
      "\t231.94 223.75 216.64 213.62 214.82 212.29 211.17 212.01 209.84 209.28\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "37\n",
      "\t246.84 231.77 223.27 214.02 212.09 210.82 210.11 209.94 209.20 208.09\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "38\n",
      "\t233.88 214.26 212.51 209.83 209.73 207.36 206.45 206.43 205.06 204.35\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "39\n",
      "\t245.32 237.74 229.43 227.65 223.56 220.84 217.69 214.96 213.49 211.58\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "40\n",
      "\t234.68 224.87 217.09 214.83 213.16 213.71 210.43 210.11 208.74 208.40\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "41\n",
      "\t237.82 227.17 219.25 211.35 209.00 208.06 207.20 206.69 206.56 205.74\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "42\n",
      "\t243.41 232.47 229.70 220.13 214.02 212.75 213.72 211.22 210.66 209.31\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "43\n",
      "\t226.04 213.32 210.81 209.67 209.86 207.97 207.19 206.80 206.97 205.44\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "44\n",
      "\t214.67 211.92 211.70 212.28 208.82 212.43 207.61 208.13 207.71 205.89\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "45\n",
      "\t236.57 227.45\n",
      "\t0.0000 0.0000\n",
      "46\n",
      "\t231.16 213.59 211.93 208.60 208.08 206.38 205.54 204.74 204.20 204.31\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "47\n",
      "\t246.15 230.50 216.62 213.41 211.43 209.38 208.67 207.93 206.18 205.50\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "48\n",
      "\t238.98 227.88 222.85 213.15 211.51 209.85 208.84 208.84 208.38 207.55\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t221.32 216.00 214.35 213.25 211.89 211.00 210.84 211.62 209.84 209.44\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "50\n",
      "\t219.97 212.38 211.45 209.73 208.26 209.54 207.59 206.62 205.48 208.19\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n"
     ]
    }
   ],
   "source": [
    "print_validation_profile_and_prior_losses(\"TEAD4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best profile loss overall:\n",
      "\tBest run: 49\n",
      "\tBest epoch in run: 9\n",
      "\tAssociated value: 204.70488308443882\n",
      "Best epoch in each run:\n",
      "\tRun 1, epoch 10: 210.72\n",
      "\tRun 2, epoch 10: 210.21\n",
      "\tRun 3, epoch 10: 205.92\n",
      "\tRun 4, epoch 10: 233.96\n",
      "\tRun 5, epoch 10: 205.85\n",
      "\tRun 6, epoch 10: 216.86\n",
      "\tRun 7, epoch 10: 205.73\n",
      "\tRun 8, epoch 9: 207.97\n",
      "\tRun 9, epoch 10: 207.70\n",
      "\tRun 10, epoch 9: 204.71\n",
      "\tRun 11, epoch 10: 207.35\n",
      "\tRun 12, epoch 10: 220.66\n",
      "\tRun 13, epoch 8: 204.85\n",
      "\tRun 14, epoch 10: 206.26\n",
      "\tRun 15, epoch 10: 207.71\n",
      "\tRun 16, epoch 10: 207.51\n",
      "\tRun 17, epoch 10: 208.24\n",
      "\tRun 18, epoch 10: 208.90\n",
      "\tRun 19, epoch 10: 217.27\n",
      "\tRun 20, epoch 10: 216.59\n",
      "\tRun 21, epoch 8: 207.04\n",
      "\tRun 22, epoch 10: 210.90\n",
      "\tRun 23, epoch 10: 208.92\n",
      "\tRun 24, epoch 10: 211.28\n",
      "\tRun 25, epoch 10: 209.74\n",
      "\tRun 26, epoch 10: 206.93\n",
      "\tRun 27, epoch 8: 209.89\n",
      "\tRun 28, epoch 10: 209.87\n",
      "\tRun 29, epoch 10: 234.06\n",
      "\tRun 30, epoch 10: 232.68\n",
      "\tRun 31, epoch 10: 211.56\n",
      "\tRun 32, epoch 10: 223.92\n",
      "\tRun 33, epoch 9: 208.02\n",
      "\tRun 34, epoch 10: 209.27\n",
      "\tRun 35, epoch 10: 224.43\n",
      "\tRun 36, epoch 10: 207.77\n",
      "\tRun 37, epoch 10: 213.10\n",
      "\tRun 38, epoch 10: 205.97\n",
      "\tRun 39, epoch 10: 212.62\n",
      "\tRun 40, epoch 10: 208.03\n",
      "\tRun 41, epoch 9: 205.45\n",
      "\tRun 42, epoch 10: 207.51\n",
      "\tRun 43, epoch 10: 208.70\n",
      "\tRun 44, epoch 10: 206.59\n",
      "\tRun 45, epoch 9: 209.14\n",
      "\tRun 46, epoch 10: 211.42\n",
      "\tRun 47, epoch 10: 209.33\n",
      "\tRun 48, epoch 10: 205.81\n",
      "\tRun 49, epoch 9: 204.70\n",
      "\tRun 50, epoch 10: 219.90\n",
      "All validation profile and prior losses:\n",
      "1\n",
      "\t240.39 238.09 233.61 230.66 227.39 222.37 218.99 215.28 213.90 210.72\n",
      "\t0.2934 0.2314 0.1776 0.1522 0.1742 0.1907 0.2020 0.1868 0.1863 0.1715\n",
      "2\n",
      "\t236.52 228.13 217.07 215.64 214.68 213.99 212.86 211.83 210.24 210.21\n",
      "\t0.3649 0.3070 0.1424 0.1109 0.0899 0.0947 0.0847 0.0791 0.0766 0.0757\n",
      "3\n",
      "\t230.31 211.62 210.40 210.00 209.72 207.78 207.77 207.02 206.52 205.92\n",
      "\t0.4158 0.1592 0.1242 0.1026 0.0950 0.0934 0.0857 0.0859 0.0856 0.0809\n",
      "4\n",
      "\t248.67 248.64 248.02 246.95 245.27 244.16 240.83 238.97 237.12 233.96\n",
      "\t0.3034 0.2176 0.2314 0.1527 0.1389 0.1214 0.1095 0.0992 0.0918 0.0863\n",
      "5\n",
      "\t225.66 211.41 211.09 210.67 210.72 208.93 208.49 207.42 206.66 205.85\n",
      "\t0.3577 0.1471 0.1198 0.1021 0.0964 0.0854 0.0758 0.0820 0.0808 0.0838\n",
      "6\n",
      "\t247.46 242.58 238.58 235.71 231.10 227.91 226.38 223.62 218.76 216.86\n",
      "\t0.3140 0.2729 0.1704 0.1392 0.1618 0.1748 0.1638 0.1451 0.1609 0.1643\n",
      "7\n",
      "\t236.67 226.10 222.32 211.07 208.78 208.02 207.08 207.66 206.04 205.73\n",
      "\t0.3573 0.3065 0.2326 0.2042 0.1677 0.1427 0.1326 0.1137 0.1064 0.1050\n",
      "8\n",
      "\t239.00 227.94 224.15 217.47 212.81 211.07 209.12 208.59 207.97 208.03\n",
      "\t0.3085 0.3056 0.2515 0.2377 0.2187 0.1931 0.1686 0.1540 0.1527 0.1370\n",
      "9\n",
      "\t237.29 226.31 219.08 212.82 210.98 210.34 208.74 208.40 208.26 207.70\n",
      "\t0.3721 0.2599 0.1905 0.1604 0.1553 0.1363 0.1238 0.1018 0.1003 0.0945\n",
      "10\n",
      "\t210.77 208.70 207.59 206.18 208.44 206.13 205.51 204.79 204.71 205.25\n",
      "\t0.2064 0.1358 0.1102 0.1056 0.1024 0.0914 0.0907 0.0870 0.0835 0.0908\n",
      "11\n",
      "\t222.92 211.73 210.53 209.71 209.50 209.17 208.24 207.76 207.46 207.35\n",
      "\t0.3498 0.1600 0.1401 0.1209 0.1079 0.0973 0.1005 0.0966 0.0949 0.0875\n",
      "12\n",
      "\t240.57 236.87 231.03 230.33 227.82 226.53 224.96 224.15 222.31 220.66\n",
      "\t0.3019 0.2298 0.2265 0.1916 0.1925 0.1944 0.2037 0.1973 0.1985 0.2067\n",
      "13\n",
      "\t215.38 210.46 211.07 207.77 206.93 206.48 205.14 204.85 205.15 204.93\n",
      "\t0.2158 0.1451 0.0930 0.0994 0.0892 0.0872 0.0841 0.0828 0.0850 0.0953\n",
      "14\n",
      "\t236.16 224.41 213.61 211.18 210.19 209.47 208.33 207.85 206.59 206.26\n",
      "\t0.3223 0.2459 0.1868 0.1675 0.1528 0.1305 0.1076 0.1100 0.1027 0.1021\n",
      "15\n",
      "\t242.81 235.98 229.96 216.35 212.18 211.31 210.14 212.14 209.79 207.71\n",
      "\t0.3315 0.1700 0.2010 0.1498 0.1280 0.1226 0.1233 0.1168 0.1001 0.0942\n",
      "16\n",
      "\t225.73 219.40 211.32 210.69 209.76 208.83 208.64 208.52 207.91 207.51\n",
      "\t0.4439 0.2789 0.1846 0.1573 0.1392 0.1351 0.1220 0.1212 0.1120 0.1095\n",
      "17\n",
      "\t245.88 234.38 228.83 225.63 215.43 211.85 210.58 209.78 210.55 208.24\n",
      "\t0.2910 0.3336 0.2991 0.1903 0.1961 0.1460 0.1359 0.1101 0.1042 0.0929\n",
      "18\n",
      "\t233.81 218.87 215.75 214.38 213.06 212.13 210.68 210.54 209.58 208.90\n",
      "\t0.3637 0.1728 0.1237 0.1092 0.0960 0.1060 0.0938 0.0881 0.0847 0.0857\n",
      "19\n",
      "\t248.49 233.08 230.80 229.79 228.19 226.06 223.94 222.21 221.39 217.27\n",
      "\t0.3851 0.3296 0.3192 0.3016 0.2894 0.2743 0.2587 0.2422 0.2276 0.2066\n",
      "20\n",
      "\t246.84 243.62 239.29 233.10 230.68 231.29 227.86 226.43 221.14 216.59\n",
      "\t0.2829 0.2644 0.2682 0.2455 0.1909 0.1351 0.1658 0.1709 0.1795 0.2037\n",
      "21\n",
      "\t225.80 212.12 211.02 210.45 210.95 208.59 208.06 207.04 207.56 207.47\n",
      "\t0.3076 0.1370 0.1029 0.0801 0.0799 0.0752 0.0768 0.0757 0.0753 0.0793\n",
      "22\n",
      "\t247.31 241.17 236.53 230.85 229.47 223.06 215.05 212.52 211.16 210.90\n",
      "\t0.3649 0.2179 0.1531 0.1651 0.1524 0.1674 0.1788 0.1644 0.1564 0.1213\n",
      "23\n",
      "\t231.00 219.48 213.60 212.95 211.60 212.13 210.70 209.50 209.38 208.92\n",
      "\t0.3761 0.1815 0.1480 0.1391 0.1228 0.1056 0.1022 0.0978 0.0943 0.0917\n",
      "24\n",
      "\t242.23 235.88 230.33 229.13 232.07 222.22 216.41 213.88 214.32 211.28\n",
      "\t0.3177 0.2359 0.2095 0.1909 0.1867 0.1808 0.1713 0.1741 0.1580 0.1549\n",
      "25\n",
      "\t241.56 237.66 234.40 230.70 225.77 221.01 214.84 211.92 210.58 209.74\n",
      "\t0.3243 0.2107 0.2033 0.1663 0.1821 0.1929 0.1752 0.1530 0.1372 0.1327\n",
      "26\n",
      "\t238.27 218.25 212.86 211.33 210.84 209.50 209.24 208.79 208.32 206.93\n",
      "\t0.3631 0.1843 0.1255 0.1025 0.1002 0.0915 0.0870 0.0867 0.0849 0.0815\n",
      "27\n",
      "\t227.74 218.43 216.90 214.54 213.69 213.52 211.89 209.89 210.30 211.17\n",
      "\t0.3041 0.1547 0.1122 0.1074 0.0950 0.0873 0.0870 0.0859 0.0769 0.0721\n",
      "28\n",
      "\t246.97 240.79 230.70 222.32 217.35 214.22 212.30 211.11 210.05 209.87\n",
      "\t0.2928 0.1713 0.2173 0.1780 0.1484 0.1354 0.1254 0.1163 0.1132 0.1004\n",
      "29\n",
      "\t248.47 247.88 247.70 246.99 246.26 242.07 241.60 239.77 237.16 234.06\n",
      "\t0.3529 0.2547 0.2487 0.2447 0.2517 0.2585 0.1956 0.1679 0.1468 0.1511\n",
      "30\n",
      "\t246.71 245.20 242.83 241.12 240.20 239.10 238.10 237.55 235.46 232.68\n",
      "\t0.2655 0.2612 0.2629 0.2350 0.2057 0.1937 0.1721 0.1513 0.1550 0.1562\n",
      "31\n",
      "\t236.16 230.19 227.24 223.31 219.15 216.80 215.84 212.65 213.48 211.56\n",
      "\t0.3903 0.3232 0.2429 0.2077 0.1986 0.1958 0.1771 0.1706 0.1727 0.1688\n",
      "32\n",
      "\t247.17 241.63 239.78 237.41 235.37 232.52 231.14 227.80 225.92 223.92\n",
      "\t0.3230 0.2773 0.2335 0.1627 0.1530 0.1520 0.1455 0.1573 0.1669 0.1614\n",
      "33\n",
      "\t227.05 214.05 212.78 211.95 211.30 209.80 209.03 210.71 208.02 208.50\n",
      "\t0.2906 0.1336 0.1079 0.0996 0.1000 0.0869 0.0921 0.0903 0.0854 0.0828\n",
      "34\n",
      "\t241.60 238.80 234.03 232.22 227.33 218.60 213.10 211.13 210.19 209.27\n",
      "\t0.2765 0.1972 0.1640 0.1772 0.1927 0.1949 0.1882 0.1648 0.1488 0.1243\n",
      "35\n",
      "\t246.74 242.10 239.95 236.65 233.89 231.34 230.43 227.58 225.96 224.43\n",
      "\t0.3069 0.2297 0.1821 0.1793 0.2024 0.1779 0.2116 0.2036 0.2026 0.2201\n",
      "36\n",
      "\t238.22 226.56 213.25 212.78 211.53 210.55 209.45 208.59 208.29 207.77\n",
      "\t0.4100 0.2597 0.1434 0.1132 0.0949 0.0932 0.0870 0.0837 0.0801 0.0834\n",
      "37\n",
      "\t240.50 237.86 232.99 231.01 228.41 223.53 220.04 216.06 213.33 213.10\n",
      "\t0.3135 0.2225 0.1811 0.1761 0.1731 0.1808 0.1830 0.1805 0.1571 0.1554\n",
      "38\n",
      "\t234.81 224.98 212.10 211.11 208.92 208.03 207.44 207.53 206.32 205.97\n",
      "\t0.3896 0.2505 0.1907 0.1509 0.1249 0.1121 0.0998 0.0935 0.0910 0.0890\n",
      "39\n",
      "\t250.11 242.54 239.52 234.31 228.37 224.13 220.26 214.95 213.74 212.62\n",
      "\t0.2722 0.2641 0.1944 0.2448 0.2206 0.2198 0.2160 0.2029 0.1904 0.1732\n",
      "40\n",
      "\t240.99 236.30 230.45 219.72 211.96 212.55 210.49 209.37 208.99 208.03\n",
      "\t0.2901 0.1854 0.1485 0.1592 0.1299 0.1106 0.1047 0.0954 0.0946 0.0985\n",
      "41\n",
      "\t215.08 211.40 210.28 208.64 208.90 207.27 206.43 205.77 205.45 205.69\n",
      "\t0.2751 0.1507 0.1151 0.0907 0.0773 0.0768 0.0827 0.0783 0.0781 0.0756\n",
      "42\n",
      "\t216.66 213.80 211.43 210.22 209.97 209.42 208.53 208.20 208.47 207.51\n",
      "\t0.2466 0.1443 0.1088 0.0963 0.0959 0.0874 0.0811 0.0790 0.0793 0.0805\n",
      "43\n",
      "\t232.91 224.39 216.25 214.03 213.40 211.56 210.01 209.55 209.97 208.70\n",
      "\t0.4031 0.3175 0.2136 0.1613 0.1398 0.1223 0.1129 0.1047 0.0945 0.0945\n",
      "44\n",
      "\t234.41 225.05 213.59 211.31 210.62 209.68 208.96 207.53 207.23 206.59\n",
      "\t0.3388 0.2652 0.1344 0.1086 0.0912 0.0851 0.0848 0.0859 0.0863 0.0826\n",
      "45\n",
      "\t236.37 229.81 216.53 213.59 213.04 211.95 210.25 209.48 209.14 209.53\n",
      "\t0.3999 0.3186 0.2031 0.1405 0.1027 0.1089 0.0948 0.0905 0.0893 0.0850\n",
      "46\n",
      "\t249.83 240.39 231.51 227.96 221.54 216.69 215.87 212.41 212.44 211.42\n",
      "\t0.3417 0.3063 0.2224 0.1956 0.1833 0.1637 0.1491 0.1437 0.1238 0.1580\n",
      "47\n",
      "\t246.74 242.98 236.31 232.10 222.82 217.38 212.33 210.33 210.05 209.33\n",
      "\t0.2850 0.2894 0.1673 0.1573 0.1788 0.1734 0.1447 0.1463 0.1445 0.1269\n",
      "48\n",
      "\t227.80 212.95 210.92 210.67 208.59 208.23 207.54 207.00 206.32 205.81\n",
      "\t0.4043 0.1476 0.1233 0.1126 0.0986 0.0930 0.0901 0.0877 0.0855 0.0873\n",
      "49\n",
      "\t220.31 210.21 209.16 217.10 206.71 205.82 205.11 205.87 204.70 205.03\n",
      "\t0.3148 0.1331 0.1003 0.1034 0.0863 0.0902 0.0885 0.0833 0.0912 0.0938\n",
      "50\n",
      "\t239.48 237.44 230.53 229.44 228.27 226.10 223.78 222.16 221.16 219.90\n",
      "\t0.3121 0.2311 0.2175 0.1796 0.1908 0.1812 0.1855 0.1846 0.1794 0.1777\n"
     ]
    }
   ],
   "source": [
    "print_validation_profile_and_prior_losses(\"TEAD4_prior_attinflate\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
