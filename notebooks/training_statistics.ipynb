{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_metrics_json(models_path, run_num):\n",
    "    \"\"\"\n",
    "    Looks in {models_path}/{run_num}/metrics.json and returns the contents as a\n",
    "    Python dictionary. Returns None if the path does not exist.\n",
    "    \"\"\"\n",
    "    path = os.path.join(models_path, str(run_num), \"metrics.json\")\n",
    "    if not os.path.exists(path):\n",
    "        return None\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_metric(models_path, metric_name, reduce_func, compare_func):\n",
    "    \"\"\"\n",
    "    Given the path to a set of runs, determines the run with the best metric value,\n",
    "    for the given `metric_name`. For each run, the function `reduce_func` must take\n",
    "    the array of all values for that metric and return a (scalar) value to use for\n",
    "    comparison. The best metric value is determined by `metric_compare_func`, which\n",
    "    must take in two arguments, and return whether or not the _first_ one is better.\n",
    "    Returns the number of the run, the value associated with that run, and a dict of\n",
    "    all the values used for comparison.\n",
    "    \"\"\"\n",
    "    # Get the metrics, ignoring empty or nonexistent metrics.json files\n",
    "    metrics = {run_num : import_metrics_json(models_path, run_num) for run_num in os.listdir(models_path)}\n",
    "    metrics = {key : val for key, val in metrics.items() if val}  # Remove empties\n",
    "    \n",
    "    # Get the best value\n",
    "    best_run, best_val, all_vals = None, None, {}\n",
    "    for run_num in metrics.keys():\n",
    "        try:\n",
    "            val = reduce_func(metrics[run_num][metric_name][\"values\"])\n",
    "            all_vals[run_num] = val\n",
    "            if best_val is None or compare_func(val, best_val):\n",
    "                best_val, best_run = val, run_num\n",
    "        except Exception:\n",
    "            print(\"Warning: Was not able to compute values for run %s\" % run_num)\n",
    "            continue\n",
    "    return best_run, best_val, all_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_metric_at_best_epoch(models_path, metric_name, reduce_func, compare_func):\n",
    "    \"\"\"\n",
    "    Given the path to a set of runs, determines the run with the best metric value,\n",
    "    for the given `metric_name`. For each run, the function `reduce_func` must take\n",
    "    the array of all values for that metric and return a (scalar) value FOR EACH\n",
    "    SUBARRAY/VALUE in the value array to use for comparison. The best metric value\n",
    "    is determined by `metric_compare_func`, which must take in two arguments, and\n",
    "    return whether or not the _first_ one is better.\n",
    "    Returns the number of the run, the (one-indexed) number of the epch, the value\n",
    "    associated with that run and epoch, and a dict of all the values used for\n",
    "    comparison (mapping pair of run number and epoch number to value).\n",
    "    \"\"\"\n",
    "    # Get the metrics, ignoring empty or nonexistent metrics.json files\n",
    "    metrics = {run_num : import_metrics_json(models_path, run_num) for run_num in os.listdir(models_path)}\n",
    "    metrics = {key : val for key, val in metrics.items() if val}  # Remove empties\n",
    "    \n",
    "    # Get the best value\n",
    "    best_run, best_epoch, best_val, all_vals = None, None, None, {}\n",
    "    for run_num in metrics.keys():\n",
    "        try:\n",
    "            # Find the best epoch within that run\n",
    "            best_epoch_in_run, best_val_in_run = None, None\n",
    "            for i, subarr in enumerate(metrics[run_num][metric_name][\"values\"]):\n",
    "                val = reduce_func(subarr)\n",
    "                if best_val_in_run is None or compare_func(val, best_val_in_run):\n",
    "                    best_epoch_in_run, best_val_in_run = i + 1, val\n",
    "            all_vals[(run_num, best_epoch_in_run)] = best_val_in_run\n",
    "            \n",
    "            # If the best value in the best epoch of the run is best so far, update\n",
    "            if best_val is None or compare_func(best_val_in_run, best_val):\n",
    "                best_run, best_epoch, best_val = run_num, best_epoch_in_run, best_val_in_run\n",
    "        except Exception:\n",
    "            print(\"Warning: Was not able to compute values for run %s\" % run_num)\n",
    "            continue\n",
    "    return best_run, best_epoch, best_val, all_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def print_validation_profile_and_prior_losses(condition):\n",
    "    models_path = \"/users/amtseng/att_priors/models/trained_models/profile_models/%s/\" % condition\n",
    "    \n",
    "    print(\"Best profile loss overall:\")\n",
    "    best_run, best_epoch, best_val, all_vals = get_best_metric_at_best_epoch(\n",
    "        models_path,\n",
    "        \"val_prof_corr_losses\",\n",
    "        lambda values: np.mean(values),\n",
    "        lambda x, y: x < y\n",
    "    )\n",
    "    print(\"\\tBest run: %s\" % best_run)\n",
    "    print(\"\\tBest epoch in run: %d\" % best_epoch)\n",
    "    print(\"\\tAssociated value: %s\" % best_val)\n",
    "    \n",
    "    print(\"Best epoch in each run:\")\n",
    "    for key in sorted(all_vals.keys(), key=lambda p: int(p[0])):\n",
    "        print(\"\\tRun %s, epoch %d: %6.2f\" % (key[0], key[1], all_vals[key]))\n",
    "        \n",
    "    print(\"All validation profile and prior losses:\")\n",
    "    for key in sorted(all_vals.keys(), key=lambda p: int(p[0])):\n",
    "        print(key[0])\n",
    "        metrics = import_metrics_json(models_path, key[0])\n",
    "        print(\"\\t\" + \" \".join([\"%6.2f\" % i for i in np.mean(metrics[\"train_prof_corr_losses\"][\"values\"], axis=1)]))\n",
    "        print(\"\\t\" + \" \".join([\"%6.2f\" % i for i in np.mean(metrics[\"val_prof_corr_losses\"][\"values\"], axis=1)]))\n",
    "        print(\"\\t\" + \" \".join([\"%6.4f\" % i for i in np.mean(metrics[\"val_att_losses\"][\"values\"], axis=1)]))\n",
    "    return all_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best profile loss overall:\n",
      "\tBest run: 29\n",
      "\tBest epoch in run: 9\n",
      "\tAssociated value: 149.85964560130284\n",
      "Best epoch in each run:\n",
      "\tRun 1, epoch 10: 151.35\n",
      "\tRun 2, epoch 8: 150.94\n",
      "\tRun 3, epoch 10: 150.32\n",
      "\tRun 4, epoch 10: 150.36\n",
      "\tRun 5, epoch 6: 150.94\n",
      "\tRun 6, epoch 9: 150.07\n",
      "\tRun 7, epoch 7: 149.92\n",
      "\tRun 8, epoch 9: 150.41\n",
      "\tRun 9, epoch 10: 151.67\n",
      "\tRun 10, epoch 9: 150.27\n",
      "\tRun 11, epoch 7: 150.20\n",
      "\tRun 12, epoch 10: 150.22\n",
      "\tRun 13, epoch 10: 150.59\n",
      "\tRun 14, epoch 10: 150.48\n",
      "\tRun 15, epoch 9: 150.67\n",
      "\tRun 16, epoch 8: 150.92\n",
      "\tRun 17, epoch 10: 150.85\n",
      "\tRun 18, epoch 10: 150.90\n",
      "\tRun 19, epoch 8: 149.96\n",
      "\tRun 20, epoch 8: 150.74\n",
      "\tRun 21, epoch 10: 150.52\n",
      "\tRun 22, epoch 9: 150.92\n",
      "\tRun 23, epoch 8: 151.08\n",
      "\tRun 24, epoch 10: 151.33\n",
      "\tRun 25, epoch 10: 150.37\n",
      "\tRun 26, epoch 10: 150.69\n",
      "\tRun 27, epoch 8: 151.86\n",
      "\tRun 28, epoch 10: 152.33\n",
      "\tRun 29, epoch 9: 149.86\n",
      "\tRun 30, epoch 9: 152.01\n",
      "\tRun 31, epoch 10: 150.59\n",
      "\tRun 32, epoch 4: 153.79\n",
      "All validation profile and prior losses:\n",
      "1\n",
      "\t173.45 166.75 161.79 159.03 157.66 156.84 156.16 155.47 154.90 154.49\n",
      "\t160.05 155.66 154.55 152.48 151.98 151.51 151.50 151.61 151.35 151.35\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "2\n",
      "\t170.52 165.78 162.15 159.46 157.68 156.63 156.04 155.33 154.75 154.27\n",
      "\t158.25 156.21 154.28 152.48 152.38 151.74 151.52 150.94 151.66 151.32\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "3\n",
      "\t171.24 162.67 159.27 157.86 156.85 155.97 155.48 154.75 154.29 154.14\n",
      "\t157.43 153.21 152.32 152.00 151.88 150.97 150.55 150.51 150.58 150.32\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "4\n",
      "\t172.17 166.27 160.81 158.53 157.45 156.45 155.75 155.11 154.52 153.98\n",
      "\t159.19 155.97 152.42 151.66 151.64 150.97 151.20 150.66 150.78 150.36\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "5\n",
      "\t173.44 165.81 160.49 158.65 157.67 156.90 156.12 155.47 154.94 154.46\n",
      "\t164.32 157.30 152.84 152.46 152.39 150.94 151.51 151.38 152.15 151.19\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "6\n",
      "\t173.63 167.58 161.87 159.16 157.91 156.86 156.11 155.56 154.92 154.41\n",
      "\t159.18 156.08 152.21 151.50 150.86 150.66 150.24 150.37 150.07 150.14\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "7\n",
      "\t173.33 167.27 162.67 159.48 158.25 157.08 156.17 155.49 154.91 154.40\n",
      "\t159.20 155.33 153.42 151.47 151.02 150.11 149.92 150.25 150.74 149.99\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "8\n",
      "\t170.96 164.59 159.60 157.88 156.93 156.06 155.40 154.83 154.26 153.86\n",
      "\t158.57 154.50 152.49 151.64 151.46 151.21 151.24 151.64 150.41 151.32\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "9\n",
      "\t171.24 166.92 164.02 160.95 158.54 157.54 156.63 155.82 155.25 154.65\n",
      "\t160.15 159.34 157.28 154.02 153.49 152.44 152.31 152.55 151.84 151.67\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "10\n",
      "\t173.33 167.63 162.39 159.64 158.36 157.36 156.60 155.79 155.37 154.72\n",
      "\t160.28 157.10 152.43 152.08 151.79 152.11 150.88 150.80 150.27 150.53\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "11\n",
      "\t172.81 166.04 160.43 158.57 157.37 156.53 155.82 155.19 154.58 154.08\n",
      "\t159.24 154.60 151.79 151.12 151.19 150.85 150.20 150.21 150.48 150.53\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "12\n",
      "\t173.06 164.42 160.18 158.72 157.66 156.96 156.12 155.47 154.97 154.41\n",
      "\t158.96 154.55 152.21 150.68 150.48 150.44 151.60 150.81 151.17 150.22\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "13\n",
      "\t173.09 165.26 160.45 158.69 157.56 156.81 156.13 155.29 154.68 154.17\n",
      "\t159.82 155.02 153.53 151.91 152.20 150.98 150.86 151.54 150.64 150.59\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "14\n",
      "\t170.38 165.73 162.78 159.63 157.85 156.77 156.07 155.45 154.94 154.40\n",
      "\t159.51 156.66 154.61 152.56 152.04 151.37 150.70 151.14 151.11 150.48\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "15\n",
      "\t173.14 166.44 160.88 158.53 157.16 156.43 155.62 154.83 154.24 153.84\n",
      "\t158.88 155.69 153.75 151.93 151.21 151.17 151.15 151.01 150.67 151.11\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "16\n",
      "\t172.27 167.27 162.68 159.59 157.93 157.14 156.26 155.61 155.18 154.79\n",
      "\t160.06 157.57 153.44 153.41 151.18 151.30 151.27 150.92 151.06 150.97\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "17\n",
      "\t173.02 167.29 164.93 162.62 160.55 158.80 157.66 156.83 156.26 155.59\n",
      "\t158.93 157.21 155.52 154.32 154.12 152.33 151.90 151.34 151.32 150.85\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "18\n",
      "\t172.58 166.73 161.01 158.61 157.42 156.66 155.77 155.10 154.48 154.00\n",
      "\t160.85 156.15 153.75 152.59 152.15 152.55 152.17 151.75 151.26 150.90\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "19\n",
      "\t172.29 167.22 164.22 160.85 158.80 157.50 156.50 155.84 155.25 154.63\n",
      "\t161.53 156.60 154.36 152.73 151.56 150.77 150.22 149.96 150.03 150.09\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "20\n",
      "\t171.35 166.99 164.40 161.44 159.13 157.37 156.49 155.71 155.21 154.73\n",
      "\t158.14 156.88 155.03 152.78 152.05 151.20 150.76 150.74 150.80 150.95\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "21\n",
      "\t173.27 166.41 160.61 158.64 157.37 156.43 155.83 155.03 154.47 154.10\n",
      "\t159.84 154.25 151.83 151.98 151.12 151.38 150.75 151.10 150.89 150.52\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "22\n",
      "\t172.95 165.35 160.12 158.29 157.21 156.32 155.58 155.09 154.55 154.12\n",
      "\t160.06 155.28 153.26 152.20 151.90 151.39 151.70 151.13 150.92 151.50\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "23\n",
      "\t173.39 168.35 164.78 160.53 158.83 157.73 157.08 156.22 155.71 155.03\n",
      "\t160.53 157.80 154.47 153.09 152.12 152.29 152.16 151.08 151.73 151.78\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "24\n",
      "\t171.88 167.17 164.82 162.26 160.03 158.33 157.22 156.37 155.59 154.99\n",
      "\t162.27 158.69 156.95 154.76 153.93 152.85 152.40 152.33 151.54 151.33\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "25\n",
      "\t173.84 167.59 163.41 159.37 157.80 156.78 155.98 155.31 154.70 154.19\n",
      "\t161.40 158.43 153.20 152.23 151.59 151.55 151.06 150.64 150.70 150.37\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "26\n",
      "\t173.10 166.82 161.22 158.53 157.41 156.36 155.52 154.92 154.39 153.86\n",
      "\t160.22 156.37 153.02 152.69 151.45 150.93 151.31 151.23 151.14 150.69\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "27\n",
      "\t173.95 166.33 160.65 158.77 157.74 156.83 156.14 155.62 155.07 154.57\n",
      "\t161.37 155.71 154.26 153.19 152.60 152.56 152.38 151.86 152.63 152.03\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "28\n",
      "\t172.10 167.46 165.38 163.28 161.83 160.19 158.80 157.89 156.70 156.23\n",
      "\t160.68 159.86 156.78 155.74 155.52 154.21 153.45 154.35 152.37 152.33\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "29\n",
      "\t175.17 168.41 165.70 163.13 160.25 158.43 157.43 156.62 155.98 155.49\n",
      "\t159.37 158.04 155.63 153.49 151.69 151.28 150.50 150.06 149.86 150.19\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "30\n",
      "\t172.35 167.09 164.26 161.70 159.70 158.11 157.23 156.40 155.78 155.36\n",
      "\t160.22 159.85 156.88 155.18 153.56 153.05 152.65 152.61 152.01 152.60\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "31\n",
      "\t172.73 165.71 160.32 158.35 157.19 156.34 155.59 155.04 154.59 154.20\n",
      "\t159.32 155.62 153.00 152.27 151.89 152.45 151.54 151.30 150.97 150.59\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "32\n",
      "\t174.68 168.18 164.23 159.91\n",
      "\t161.39 159.34 155.31 153.79\n",
      "\t0.0000 0.0000 0.0000 0.0000\n"
     ]
    }
   ],
   "source": [
    "noprior_vals = print_validation_profile_and_prior_losses(\"E2F6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best profile loss overall:\n",
      "\tBest run: 15\n",
      "\tBest epoch in run: 9\n",
      "\tAssociated value: 150.18527179294162\n",
      "Best epoch in each run:\n",
      "\tRun 1, epoch 10: 152.39\n",
      "\tRun 2, epoch 8: 150.89\n",
      "\tRun 3, epoch 8: 150.37\n",
      "\tRun 4, epoch 10: 150.64\n",
      "\tRun 5, epoch 10: 151.76\n",
      "\tRun 6, epoch 10: 151.12\n",
      "\tRun 7, epoch 9: 151.45\n",
      "\tRun 8, epoch 9: 150.52\n",
      "\tRun 9, epoch 10: 151.97\n",
      "\tRun 10, epoch 8: 151.02\n",
      "\tRun 11, epoch 9: 150.84\n",
      "\tRun 12, epoch 10: 150.88\n",
      "\tRun 13, epoch 10: 151.95\n",
      "\tRun 14, epoch 9: 152.70\n",
      "\tRun 15, epoch 9: 150.19\n",
      "\tRun 16, epoch 4: 152.37\n",
      "All validation profile and prior losses:\n",
      "1\n",
      "\t173.87 168.51 166.20 164.45 162.57 161.08 159.90 158.99 158.39 157.79\n",
      "\t160.89 163.33 157.83 156.33 154.88 156.65 155.39 153.36 152.88 152.39\n",
      "\t0.1939 0.1605 0.1419 0.1217 0.1283 0.1578 0.1366 0.1368 0.1342 0.1315\n",
      "2\n",
      "\t174.25 167.19 161.78 159.57 158.67 157.92 157.17 156.74 156.43 155.96\n",
      "\t159.79 155.19 152.83 152.35 151.61 151.42 151.53 150.89 151.52 151.34\n",
      "\t0.1624 0.1097 0.0950 0.0886 0.0875 0.0845 0.0830 0.0808 0.0849 0.0770\n",
      "3\n",
      "\t174.82 168.42 164.01 160.46 159.02 158.11 157.40 156.71 156.15 155.79\n",
      "\t160.18 156.84 153.39 152.58 151.46 151.05 151.47 150.37 150.51 150.40\n",
      "\t0.1767 0.1118 0.0791 0.0753 0.0785 0.0788 0.0968 0.0710 0.0704 0.0647\n",
      "4\n",
      "\t173.77 168.59 166.22 162.28 159.81 158.89 158.11 157.48 156.94 156.54\n",
      "\t160.35 158.47 155.25 153.21 152.56 152.19 151.57 151.56 151.31 150.64\n",
      "\t0.1274 0.1170 0.1209 0.1079 0.0913 0.0864 0.0863 0.0792 0.0826 0.0802\n",
      "5\n",
      "\t175.28 169.62 165.67 162.13 159.90 158.80 158.15 157.52 156.95 156.57\n",
      "\t161.67 158.33 156.12 153.93 153.00 153.29 152.89 152.85 152.35 151.76\n",
      "\t0.1842 0.1523 0.1062 0.0886 0.0857 0.0821 0.0753 0.0743 0.0715 0.0708\n",
      "6\n",
      "\t174.59 167.80 162.10 159.93 158.79 158.10 157.54 156.91 156.54 156.26\n",
      "\t160.86 155.09 152.83 152.28 152.06 151.83 151.81 151.97 151.36 151.12\n",
      "\t0.1574 0.1121 0.0949 0.0873 0.0854 0.0862 0.0827 0.0832 0.0796 0.0814\n",
      "7\n",
      "\t174.83 168.42 163.21 160.24 159.29 158.15 157.66 157.01 156.50 156.14\n",
      "\t160.45 158.67 154.00 155.80 151.81 151.70 151.80 151.59 151.45 151.74\n",
      "\t0.1551 0.1245 0.0969 0.0826 0.0831 0.0776 0.0761 0.0720 0.0691 0.0682\n",
      "8\n",
      "\t172.62 164.94 160.63 159.45 158.62 158.13 157.46 156.88 156.52 156.13\n",
      "\t159.21 153.31 152.88 151.72 151.21 150.99 150.91 150.55 150.52 150.65\n",
      "\t0.1378 0.1066 0.0903 0.0865 0.0843 0.0841 0.0816 0.0798 0.0787 0.0774\n",
      "9\n",
      "\t174.06 168.21 164.83 161.78 160.12 159.00 158.53 157.85 157.51 156.83\n",
      "\t161.18 159.04 157.28 154.40 153.11 153.22 152.28 152.41 152.30 151.97\n",
      "\t0.1372 0.1237 0.1100 0.1011 0.0955 0.0804 0.0791 0.0767 0.0696 0.0698\n",
      "10\n",
      "\t173.53 168.47 163.71 160.54 159.13 158.30 157.80 157.21 156.63 156.34\n",
      "\t160.40 156.88 153.97 152.64 151.97 151.96 151.21 151.02 151.30 151.05\n",
      "\t0.1688 0.1365 0.1077 0.0925 0.0845 0.0846 0.0835 0.0776 0.0792 0.0747\n",
      "11\n",
      "\t172.65 168.93 166.72 162.66 159.64 158.61 157.84 157.17 156.58 156.11\n",
      "\t161.52 158.03 156.69 153.95 151.62 151.82 151.42 150.98 150.84 151.01\n",
      "\t0.1804 0.1423 0.1336 0.1037 0.0967 0.0909 0.0847 0.0822 0.0807 0.0770\n",
      "12\n",
      "\t174.44 168.24 163.32 160.40 159.04 158.18 157.50 157.09 156.62 156.07\n",
      "\t160.15 157.13 153.70 152.35 152.32 151.69 151.63 152.44 151.73 150.88\n",
      "\t0.1636 0.1206 0.0930 0.0898 0.0852 0.0838 0.0838 0.0814 0.0787 0.0771\n",
      "13\n",
      "\t173.34 167.74 162.18 159.85 158.73 158.00 157.35 156.89 156.42 156.01\n",
      "\t161.65 156.89 153.90 153.56 152.72 152.88 152.42 152.44 152.09 151.95\n",
      "\t0.1458 0.1156 0.0884 0.0850 0.0834 0.0829 0.0796 0.0781 0.0756 0.0773\n",
      "14\n",
      "\t174.99 168.70 163.53 160.49 159.25 158.31 157.65 156.94 156.42 155.93\n",
      "\t162.06 158.83 155.89 155.06 154.39 153.75 153.36 153.68 152.70 152.71\n",
      "\t0.1545 0.1373 0.1078 0.0993 0.0966 0.0850 0.0768 0.0632 0.0611 0.0601\n",
      "15\n",
      "\t173.75 167.91 162.31 159.64 158.50 157.59 157.10 156.54 156.01 155.70\n",
      "\t160.10 156.35 152.23 151.50 151.38 151.33 150.66 150.79 150.19 150.21\n",
      "\t0.1598 0.1226 0.1012 0.0916 0.0893 0.0832 0.0843 0.0803 0.0773 0.0789\n",
      "16\n",
      "\t174.29 167.44 161.45 159.62 158.69 157.74\n",
      "\t161.41 155.08 153.60 152.37 152.70\n",
      "\t0.1607 0.1096 0.0973 0.0889 0.0844\n"
     ]
    }
   ],
   "source": [
    "prior_vals = print_validation_profile_and_prior_losses(\"E2F6_prior\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1/model_ckpt_epoch_10.pt',\n",
       " '2/model_ckpt_epoch_10.pt',\n",
       " '3/model_ckpt_epoch_10.pt',\n",
       " '4/model_ckpt_epoch_10.pt',\n",
       " '5/model_ckpt_epoch_10.pt',\n",
       " '6/model_ckpt_epoch_10.pt',\n",
       " '7/model_ckpt_epoch_10.pt',\n",
       " '8/model_ckpt_epoch_10.pt',\n",
       " '9/model_ckpt_epoch_10.pt',\n",
       " '10/model_ckpt_epoch_10.pt',\n",
       " '11/model_ckpt_epoch_10.pt',\n",
       " '12/model_ckpt_epoch_10.pt',\n",
       " '13/model_ckpt_epoch_10.pt',\n",
       " '14/model_ckpt_epoch_10.pt',\n",
       " '15/model_ckpt_epoch_10.pt',\n",
       " '16/model_ckpt_epoch_10.pt']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\"%s/model_ckpt_epoch_%d.pt\" % (a, 10) for a, b in sorted(prior_vals.keys(), key=lambda p: int(p[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fce66b5c890>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bin_num = 20\n",
    "plt.figure()\n",
    "plt.hist(\n",
    "    [np.array(list(noprior_vals.values())), np.array(list(prior_vals.values()))],\n",
    "    bin_num, histtype=\"bar\",\n",
    "    label=[\"No prior\", \"With prior\"], color=[\"red\", \"blue\"])\n",
    "title = \"Histogram of validation profile loss\"\n",
    "title += \"\\nTraining on only top 1% of peaks\"\n",
    "plt.title(title)\n",
    "plt.xlabel(\"Validation profile loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25600345785323875\n",
      "0.39924238231685866\n"
     ]
    }
   ],
   "source": [
    "np_vals, p_vals = np.array(list(noprior_vals.values())), np.array(list(prior_vals.values()))\n",
    "t, p = scipy.stats.ttest_ind(np_vals, p_vals)\n",
    "print(t)\n",
    "print(p / 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
