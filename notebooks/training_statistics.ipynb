{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing saved metrics JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_metrics_json(models_path, run_num):\n",
    "    \"\"\"\n",
    "    Looks in {models_path}/{run_num}/metrics.json and returns the contents as a\n",
    "    Python dictionary. Returns None if the path does not exist, or the JSON is\n",
    "    not well-formed.\n",
    "    \"\"\"\n",
    "    path = os.path.join(models_path, str(run_num), \"metrics.json\")\n",
    "    if not os.path.exists(path):\n",
    "        return None\n",
    "    try:\n",
    "        with open(path, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Metrics JSON at %s is not well-formed\" % path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_metric_at_best_epoch(models_path, metric_name, reduce_func, compare_func, max_epoch=None):\n",
    "    \"\"\"\n",
    "    Given the path to a set of runs, determines the run with the best metric value,\n",
    "    for the given `metric_name`. For each run, the function `reduce_func` must take\n",
    "    the array of all values for that metric and return a (scalar) value FOR EACH\n",
    "    SUBARRAY/VALUE in the value array to use for comparison. The best metric value\n",
    "    is determined by `metric_compare_func`, which must take in two arguments, and\n",
    "    return True if the _first_ one is better. If `max_epoch` is provided, will only\n",
    "    report everything up to this epoch (1-indexed).\n",
    "    Returns the number of the run, the (one-indexed) number of the epoch, the value\n",
    "    associated with that run and epoch, and a dict of all the values used for\n",
    "    comparison (mapping pair of run number and epoch number to value).\n",
    "    \"\"\"\n",
    "    # Get the metrics, ignoring empty or nonexistent metrics.json files\n",
    "    metrics = {run_num : import_metrics_json(models_path, run_num) for run_num in os.listdir(models_path)}\n",
    "    metrics = {key : val for key, val in metrics.items() if val}  # Remove empties\n",
    "    \n",
    "    # Get the best value\n",
    "    best_run, best_epoch, best_val, all_vals = None, None, None, {}\n",
    "    for run_num in metrics.keys():\n",
    "        try:\n",
    "            # Find the best epoch within that run\n",
    "            best_epoch_in_run, best_val_in_run = None, None\n",
    "            for i, subarr in enumerate(metrics[run_num][metric_name][\"values\"]):\n",
    "                if i == max_epoch:\n",
    "                    break\n",
    "                val = reduce_func(subarr)\n",
    "                if best_val_in_run is None or compare_func(val, best_val_in_run):\n",
    "                    best_epoch_in_run, best_val_in_run = i + 1, val\n",
    "            all_vals[(run_num, best_epoch_in_run)] = best_val_in_run\n",
    "            \n",
    "            # If the best value in the best epoch of the run is best so far, update\n",
    "            if best_val is None or compare_func(best_val_in_run, best_val):\n",
    "                best_run, best_epoch, best_val = run_num, best_epoch_in_run, best_val_in_run\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"Warning: Was not able to compute values for run %s\" % run_num)\n",
    "            continue\n",
    "    return best_run, best_epoch, best_val, all_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profile models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def print_profile_losses(models_path, max_epoch=None):\n",
    "    \"\"\"\n",
    "    Given the path to a condition containing many runs, prints out the best validation\n",
    "    profile NLL losses for each run, and the set of profile NLL losses for training\n",
    "    and validation over all epochs, as well as the validation prior loss. If given,\n",
    "    only consider up to `max_epoch` epochs total; anything afterward would be ignored.\n",
    "    \"\"\"\n",
    "    print(\"Best profile loss overall:\")\n",
    "    best_run, best_epoch, best_val, all_vals = get_best_metric_at_best_epoch(\n",
    "        models_path,\n",
    "        \"val_prof_corr_losses\",\n",
    "        lambda values: np.mean(values),\n",
    "        lambda x, y: x < y,\n",
    "        max_epoch\n",
    "    )\n",
    "    print(\"\\tBest run: %s\" % best_run)\n",
    "    print(\"\\tBest epoch in run: %d\" % best_epoch)\n",
    "    print(\"\\tAssociated value: %s\" % best_val)\n",
    "    \n",
    "    print(\"Best epoch in each run:\")\n",
    "    for key in sorted(all_vals.keys(), key=lambda p: int(p[0])):\n",
    "        print(\"\\tRun %s, epoch %d: %6.2f\" % (key[0], key[1], all_vals[key]))\n",
    "        \n",
    "    print(\"All validation profile and prior losses:\")\n",
    "    for key in sorted(all_vals.keys(), key=lambda p: int(p[0])):\n",
    "        print(key[0])\n",
    "        metrics = import_metrics_json(models_path, key[0])\n",
    "        print(\"\\t\" + \" \".join([\"%6.2f\" % i for i in np.mean(metrics[\"train_prof_corr_losses\"][\"values\"], axis=1)[:max_epoch]]))\n",
    "        print(\"\\t\" + \" \".join([\"%6.2f\" % i for i in np.mean(metrics[\"val_prof_corr_losses\"][\"values\"], axis=1)[:max_epoch]]))\n",
    "        print(\"\\t\" + \" \".join([\"%6.4f\" % i for i in np.mean(metrics[\"val_att_losses\"][\"values\"], axis=1)[:max_epoch]]))\n",
    "    return all_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_models_path = \"/users/amtseng/att_priors/models/trained_models/profile/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best profile loss overall:\n",
      "\tBest run: 28\n",
      "\tBest epoch in run: 19\n",
      "\tAssociated value: 144.52477201077306\n",
      "Best epoch in each run:\n",
      "\tRun 1, epoch 19: 145.83\n",
      "\tRun 2, epoch 20: 146.27\n",
      "\tRun 3, epoch 17: 144.68\n",
      "\tRun 4, epoch 19: 145.49\n",
      "\tRun 5, epoch 20: 146.26\n",
      "\tRun 6, epoch 19: 145.06\n",
      "\tRun 7, epoch 20: 145.01\n",
      "\tRun 8, epoch 19: 146.45\n",
      "\tRun 9, epoch 18: 145.48\n",
      "\tRun 10, epoch 20: 144.68\n",
      "\tRun 11, epoch 18: 145.05\n",
      "\tRun 12, epoch 18: 146.87\n",
      "\tRun 13, epoch 20: 144.56\n",
      "\tRun 14, epoch 19: 145.95\n",
      "\tRun 15, epoch 19: 145.37\n",
      "\tRun 16, epoch 19: 147.13\n",
      "\tRun 17, epoch 15: 145.35\n",
      "\tRun 18, epoch 20: 146.32\n",
      "\tRun 19, epoch 15: 146.19\n",
      "\tRun 20, epoch 18: 145.67\n",
      "\tRun 21, epoch 14: 146.33\n",
      "\tRun 22, epoch 19: 145.77\n",
      "\tRun 23, epoch 13: 145.91\n",
      "\tRun 24, epoch 17: 146.59\n",
      "\tRun 25, epoch 20: 145.58\n",
      "\tRun 26, epoch 17: 146.31\n",
      "\tRun 27, epoch 19: 145.24\n",
      "\tRun 28, epoch 19: 144.52\n",
      "\tRun 29, epoch 19: 145.53\n",
      "\tRun 30, epoch 18: 145.61\n",
      "All validation profile and prior losses:\n",
      "1\n",
      "\t212.42 206.65 198.52 195.00 192.19 190.42 189.72 189.01 188.25 187.81 186.98 186.26 185.89 185.46 185.15 184.85 184.52 184.17 184.03 183.78\n",
      "\t154.59 151.94 150.48 149.17 148.67 148.12 148.13 147.50 147.85 146.89 146.86 147.06 146.81 146.63 146.12 146.11 146.07 146.20 145.83 145.93\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "2\n",
      "\t213.63 209.11 200.84 196.10 192.91 190.36 188.89 188.46 187.96 189.31 188.40 187.04 186.89 186.12 185.75 185.44 185.15 184.93 184.72 184.52\n",
      "\t156.02 153.61 151.63 150.59 149.64 148.45 148.08 147.94 148.35 148.54 147.87 147.60 147.14 147.07 146.78 146.93 146.61 146.39 146.33 146.27\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "3\n",
      "\t213.44 210.67 208.27 199.40 196.20 193.67 191.16 189.85 189.04 188.19 187.59 186.82 186.38 185.88 185.56 185.17 184.83 184.54 184.18 183.92\n",
      "\t154.44 153.41 151.31 150.19 148.77 148.22 147.43 147.36 147.54 146.00 145.65 145.66 145.18 145.32 145.40 145.24 144.68 144.72 145.04 144.74\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "4\n",
      "\t212.70 211.07 208.42 199.98 196.60 194.02 191.52 189.59 189.01 188.81 187.98 187.17 186.70 186.15 185.89 185.54 185.29 184.81 184.63 184.34\n",
      "\t153.95 153.75 151.55 150.17 148.91 148.71 147.83 147.97 148.16 146.72 146.38 145.91 146.28 145.95 146.07 145.95 145.64 145.50 145.49 145.90\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "5\n",
      "\t211.47 206.59 198.13 194.67 191.99 190.13 189.16 188.44 187.40 186.80 186.38 185.97 185.53 185.20 185.03 184.72 184.41 184.25 183.94 183.58\n",
      "\t155.68 152.66 150.75 149.93 149.00 148.50 148.03 147.90 147.35 147.27 147.30 147.03 146.79 146.82 147.25 146.65 146.62 146.42 146.39 146.26\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "6\n",
      "\t212.10 209.99 200.85 195.48 191.67 189.77 189.01 189.00 188.38 187.61 187.08 186.60 186.15 185.87 185.48 185.18 184.81 184.52 184.39 184.07\n",
      "\t154.37 152.37 150.21 148.50 147.72 147.68 147.47 148.78 146.46 146.24 146.26 145.90 145.98 145.56 145.51 145.79 145.69 145.64 145.06 145.77\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "7\n",
      "\t211.55 210.73 210.31 207.55 199.09 195.24 191.49 189.41 188.26 188.08 187.55 187.04 186.62 186.30 186.02 185.66 185.41 185.02 184.85 184.59\n",
      "\t154.07 153.79 153.53 151.47 149.64 148.31 147.64 146.69 146.26 146.36 146.07 145.60 145.62 145.38 145.70 145.70 145.38 145.07 145.30 145.01\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "8\n",
      "\t212.36 211.44 210.97 204.88 198.66 195.90 193.01 190.81 189.47 188.75 188.84 188.37 187.95 187.42 188.05 186.82 186.60 186.14 185.81 185.70\n",
      "\t155.39 155.42 154.86 152.26 151.56 150.36 149.46 148.13 147.93 148.73 147.79 147.38 147.46 147.44 147.27 147.24 146.66 146.72 146.45 146.73\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "9\n",
      "\t212.38 211.23 210.29 205.40 199.60 196.22 193.37 191.08 189.66 188.78 188.69 188.13 187.42 187.01 186.61 186.26 186.05 185.64 185.49 185.16\n",
      "\t154.65 154.06 153.43 151.03 150.79 149.18 148.08 147.17 146.99 146.75 146.52 146.35 146.27 146.22 145.90 146.01 145.81 145.48 145.49 145.79\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "10\n",
      "\t211.66 210.26 204.20 195.93 191.60 189.14 187.79 187.39 187.35 186.41 186.05 185.70 185.28 184.91 184.75 184.37 184.27 184.09 183.87 183.70\n",
      "\t153.81 153.22 150.88 149.00 148.28 147.96 146.10 146.66 146.02 145.82 145.65 145.45 145.19 145.15 145.21 145.01 145.01 144.91 144.83 144.68\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "11\n",
      "\t211.23 208.09 199.99 195.88 193.22 190.95 188.66 187.38 186.98 186.83 186.23 185.55 185.16 184.83 184.60 184.35 184.13 183.85 183.72 183.44\n",
      "\t153.74 152.24 149.75 148.47 148.60 147.51 146.91 146.60 147.27 146.23 145.78 145.31 145.86 145.61 145.41 145.22 145.32 145.05 145.19 145.28\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "12\n",
      "\t212.42 209.64 208.36 201.15 195.81 192.32 189.82 188.44 187.96 187.37 186.65 186.06 185.77 185.29 185.00 184.70 184.37 184.07 183.72 183.58\n",
      "\t155.95 155.32 154.09 152.55 150.54 150.20 148.92 148.29 148.40 147.83 147.79 147.87 147.50 147.22 147.27 147.33 147.12 146.87 146.92 146.97\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "13\n",
      "\t211.88 210.60 209.22 200.33 195.13 191.50 189.30 188.10 187.31 187.03 187.01 186.70 186.21 185.48 185.15 184.95 184.78 184.45 184.26 184.01\n",
      "\t153.72 153.53 152.05 149.23 148.82 146.87 148.28 146.22 145.83 145.79 145.40 145.23 145.47 145.18 144.94 145.00 144.75 144.61 144.81 144.56\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "14\n",
      "\t214.35 211.59 210.38 208.35 202.37 198.92 196.63 194.56 193.31 191.97 191.10 190.45 190.18 189.54 189.07 188.65 188.06 187.82 187.54 187.25\n",
      "\t154.01 153.83 153.11 152.62 150.83 149.76 149.43 148.51 148.33 148.45 148.52 147.57 147.33 147.59 147.42 147.24 146.80 146.55 145.95 146.20\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "15\n",
      "\t213.32 210.74 205.91 200.03 196.16 193.07 190.97 189.55 188.72 188.01 187.36 186.97 186.46 186.14 185.68 185.38 185.04 184.73 184.36 184.09\n",
      "\t154.70 153.39 151.02 150.05 149.28 148.39 147.34 147.23 146.84 146.53 146.34 146.28 146.19 145.88 145.67 145.68 145.84 145.41 145.37 145.84\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "16\n",
      "\t213.82 212.20 211.79 210.74 205.50 199.78 197.21 194.87 192.94 191.66 190.80 189.99 189.44 189.02 188.55 188.13 187.69 187.41 187.08 186.98\n",
      "\t155.55 155.52 155.26 154.08 152.20 150.83 150.44 149.35 150.02 148.60 148.47 148.19 148.24 148.06 148.48 147.56 147.54 147.86 147.13 147.89\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "17\n",
      "\t211.46 200.28 193.85 190.40 188.93 188.29 187.57 186.85 186.50 186.06 185.61 185.44 185.10 184.77 184.45 184.25 183.91 183.80\n",
      "\t153.10 149.85 148.08 147.52 147.46 147.09 146.73 146.77 146.14 146.12 145.73 146.36 145.77 145.92 145.35 145.50 146.22 145.75\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "18\n",
      "\t212.39 210.28 207.50 202.17 197.97 195.18 192.39 190.63 189.29 188.04 187.09 186.41 186.05 185.82 185.70 185.36 185.11 184.80 184.54 184.30\n",
      "\t155.54 154.34 153.28 151.71 150.63 149.63 148.94 148.18 147.70 148.03 147.38 147.13 147.01 147.06 147.32 146.66 146.66 146.37 146.59 146.32\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "19\n",
      "\t213.46 211.30 210.34 200.81 195.29 192.45 190.98 190.28 189.59 188.70 188.17 187.69 187.28 186.99 186.61\n",
      "\t154.52 154.41 153.05 149.78 148.87 148.53 147.81 147.43 147.61 146.81 146.88 146.57 146.46 146.28 146.19\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "20\n",
      "\t214.63 211.11 210.12 208.70 205.68 197.13 193.13 191.02 189.85 188.85 188.30 187.64 187.19 186.77 186.42 186.02 185.76 185.52 185.20 184.96\n",
      "\t154.59 154.51 153.95 153.63 151.48 150.87 148.30 147.87 147.72 147.42 146.87 147.18 147.02 146.28 146.77 146.48 146.21 145.67 146.22 145.95\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "21\n",
      "\t211.25 208.85 201.99 194.76 190.80 188.90 187.91 186.98 186.39 185.77 185.22 184.85 184.41 184.16\n",
      "\t155.13 153.50 150.61 149.82 148.62 147.82 147.16 146.94 146.66 146.74 146.43 146.48 146.75 146.33\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "22\n",
      "\t211.42 208.63 201.44 195.34 190.57 188.45 188.30 187.50 186.78 186.28 185.86 185.55 185.14 184.80 184.44 184.15 183.92 183.76 183.57 183.23\n",
      "\t155.05 153.32 150.75 149.57 148.02 147.90 147.30 149.00 146.76 147.18 146.57 146.66 146.53 146.26 146.33 146.01 145.91 147.22 145.77 146.04\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t210.00 198.34 192.84 189.51 188.48 187.89 186.71 185.95 185.56 185.13 184.91 184.52 184.20 183.88 183.76 183.49 183.32 182.98 182.92 182.74\n",
      "\t152.47 150.81 149.08 148.79 148.86 147.40 147.00 147.09 146.66 146.56 146.61 146.38 145.91 146.22 146.10 146.35 146.34 145.92 145.95 146.16\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "24\n",
      "\t212.73 210.20 207.73 206.93 204.83 198.65 195.66 193.28 191.29 190.26 189.60 189.14 188.65 188.08 187.62 187.16 186.74 186.41 186.14\n",
      "\t154.61 154.13 153.55 153.24 151.71 151.02 149.63 149.14 148.32 147.82 148.14 147.71 147.56 147.12 147.37 147.11 146.59 146.66 147.14\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "25\n",
      "\t213.36 211.55 209.32 200.60 197.11 195.07 193.37 192.29 191.28 190.44 189.89 189.09 188.28 187.66 187.16 186.74 186.31 186.10 185.70 185.39\n",
      "\t154.27 153.98 152.01 150.25 149.25 148.94 148.47 148.66 148.08 147.88 146.86 147.22 146.43 146.33 146.36 145.97 146.48 145.71 145.70 145.58\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "26\n",
      "\t211.57 208.22 198.21 193.63 190.74 189.32 188.71 188.08 187.59 186.97 186.38 185.92 185.59 185.34 184.71 184.51 184.20 183.83 183.64 183.34\n",
      "\t155.78 152.84 150.57 149.17 148.76 148.02 147.88 147.65 147.48 147.36 147.12 147.26 147.11 146.57 146.66 147.00 146.31 146.49 146.66 146.39\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "27\n",
      "\t212.05 208.99 198.02 193.07 189.94 188.82 189.33 188.02 187.10 186.61 186.13 185.82 185.57 185.24 184.79 184.59 184.30 184.10 183.84 183.59\n",
      "\t154.53 151.48 149.32 147.81 147.39 147.50 150.95 146.58 146.36 146.34 146.17 146.14 146.31 145.80 145.53 145.45 145.81 145.41 145.24 145.45\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "28\n",
      "\t214.98 211.12 210.25 205.11 198.30 195.18 192.37 190.60 189.49 188.73 188.09 187.45 187.09 186.59 186.18 185.79 185.44 185.06 184.80\n",
      "\t153.44 152.95 152.44 150.42 148.98 147.94 146.85 146.96 146.36 145.62 145.51 145.56 144.91 145.11 144.69 144.56 144.60 144.57 144.52\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "29\n",
      "\t212.75 209.68 206.17 199.77 196.21 193.16 191.44 190.01 189.24 188.32 187.76 186.94 186.48 186.13 185.85 185.46 184.97 184.81 184.50 184.24\n",
      "\t155.04 153.21 151.77 150.03 148.98 148.59 147.99 148.80 147.61 147.75 146.83 147.28 146.41 146.76 146.42 146.45 145.81 145.74 145.53 145.61\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n",
      "30\n",
      "\t212.64 211.75 207.53 200.23 197.71 195.89 194.09 192.49 191.49 190.41 189.57 188.97 188.18 187.69 187.25 186.97 186.40 186.14 185.84 185.54\n",
      "\t154.47 154.01 151.11 150.33 149.98 149.15 148.67 148.94 148.09 147.75 147.85 146.99 146.58 146.53 146.04 146.02 146.54 145.61 145.68 145.67\n",
      "\t0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000 0.0000\n"
     ]
    }
   ],
   "source": [
    "noprior_prof_val_losses = print_profile_losses(os.path.join(profile_models_path, \"BPNet_keep20\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best profile loss overall:\n",
      "\tBest run: 14\n",
      "\tBest epoch in run: 18\n",
      "\tAssociated value: 144.64615034020466\n",
      "Best epoch in each run:\n",
      "\tRun 1, epoch 19: 145.03\n",
      "\tRun 2, epoch 20: 147.88\n",
      "\tRun 3, epoch 18: 146.19\n",
      "\tRun 4, epoch 20: 145.04\n",
      "\tRun 5, epoch 20: 146.33\n",
      "\tRun 6, epoch 19: 147.86\n",
      "\tRun 7, epoch 20: 146.34\n",
      "\tRun 8, epoch 19: 146.04\n",
      "\tRun 9, epoch 20: 147.35\n",
      "\tRun 10, epoch 20: 146.82\n",
      "\tRun 11, epoch 20: 146.96\n",
      "\tRun 12, epoch 20: 147.10\n",
      "\tRun 13, epoch 20: 146.58\n",
      "\tRun 14, epoch 18: 144.65\n",
      "\tRun 15, epoch 20: 145.57\n",
      "\tRun 16, epoch 19: 145.97\n",
      "\tRun 17, epoch 18: 145.71\n",
      "\tRun 18, epoch 18: 145.68\n",
      "\tRun 19, epoch 16: 145.65\n",
      "\tRun 20, epoch 18: 147.14\n",
      "\tRun 21, epoch 19: 144.80\n",
      "\tRun 22, epoch 20: 145.16\n",
      "\tRun 23, epoch 20: 146.01\n",
      "\tRun 24, epoch 20: 147.31\n",
      "\tRun 25, epoch 20: 146.17\n",
      "\tRun 26, epoch 16: 147.27\n",
      "\tRun 27, epoch 19: 145.94\n",
      "\tRun 28, epoch 19: 146.36\n",
      "\tRun 29, epoch 17: 145.89\n",
      "\tRun 30, epoch 20: 146.91\n",
      "\tRun 31, epoch 9: 151.57\n",
      "\tRun 32, epoch 11: 147.07\n",
      "\tRun 33, epoch 20: 145.56\n",
      "\tRun 34, epoch 7: 150.82\n",
      "\tRun 35, epoch 20: 146.74\n",
      "\tRun 36, epoch 9: 150.89\n",
      "\tRun 37, epoch 15: 148.45\n",
      "\tRun 38, epoch 20: 147.39\n",
      "\tRun 39, epoch 15: 146.56\n",
      "All validation profile and prior losses:\n",
      "1\n",
      "\t210.50 210.14 210.16 210.04 210.03 207.94 197.40 191.31 187.73 186.53 185.42 184.85 184.29 183.98 183.62 183.43 183.10 182.88 182.79 182.46\n",
      "\t154.59 154.59 154.60 154.58 154.66 151.91 149.31 147.42 146.69 146.20 146.09 145.74 145.39 145.82 145.23 145.07 145.03 145.11 145.03 145.21\n",
      "\t0.0712 0.0391 0.0315 0.0287 0.0320 0.1741 0.1604 0.1646 0.1196 0.1148 0.1043 0.0940 0.1098 0.1020 0.1003 0.0919 0.0917 0.0908 0.0851 0.0890\n",
      "2\n",
      "\t213.83 211.94 211.54 211.42 211.28 210.89 208.58 201.78 199.16 195.94 193.04 191.50 190.43 189.80 189.13 188.69 188.25 187.64 187.21 186.89\n",
      "\t156.68 155.75 155.71 155.60 155.63 155.28 153.33 152.79 151.81 150.86 149.51 150.48 148.74 148.55 150.20 148.29 149.26 149.28 148.23 147.88\n",
      "\t0.1866 0.1302 0.0738 0.0533 0.0655 0.0704 0.1616 0.1762 0.1425 0.1356 0.1264 0.1139 0.1224 0.1211 0.1341 0.1364 0.1271 0.1407 0.1314 0.1294\n",
      "3\n",
      "\t212.39 211.24 211.01 211.00 210.87 210.78 208.38 199.90 196.15 192.55 190.19 188.75 187.93 187.14 186.69 186.26 185.92 185.79 185.53 185.41\n",
      "\t155.04 154.87 154.84 154.86 154.67 154.60 152.06 150.64 150.33 148.63 147.44 147.60 147.36 147.00 146.66 146.72 146.28 146.19 146.40 146.37\n",
      "\t0.1564 0.1352 0.0643 0.0463 0.0406 0.0501 0.1730 0.1781 0.1779 0.1541 0.1443 0.1428 0.1375 0.1330 0.1277 0.1237 0.1165 0.1086 0.1030 0.1042\n",
      "4\n",
      "\t211.40 210.57 210.27 202.01 194.38 190.33 188.75 187.47 186.51 186.02 185.76 185.72 185.23 184.81 184.46 184.10 184.37 184.33 183.55 183.66\n",
      "\t154.53 154.52 153.92 150.20 148.91 147.32 147.39 146.77 146.46 146.49 145.82 145.70 145.58 145.74 145.51 145.31 145.27 145.30 145.09 145.04\n",
      "\t0.1269 0.0653 0.0623 0.1675 0.1678 0.1154 0.0890 0.0857 0.0921 0.0723 0.0773 0.0877 0.0801 0.0692 0.0798 0.0766 0.0774 0.0728 0.0775 0.0791\n",
      "5\n",
      "\t212.75 211.47 211.24 210.66 202.03 196.82 192.73 190.25 188.86 188.34 187.68 187.09 186.76 186.45 186.06 185.91 185.73 185.51 185.20 185.08\n",
      "\t155.75 155.54 155.50 154.54 151.50 150.41 148.89 148.09 147.78 147.40 147.33 146.97 147.02 146.97 146.61 146.56 146.78 146.45 146.65 146.33\n",
      "\t0.1670 0.0560 0.0399 0.0821 0.1951 0.1744 0.1539 0.1270 0.1226 0.1110 0.1095 0.0981 0.0967 0.0911 0.0966 0.0942 0.0921 0.0906 0.0905 0.0914\n",
      "6\n",
      "\t217.37 211.77 211.24 211.09 211.04 211.08 211.08 210.97 210.15 200.93 196.44 193.58 191.68 190.29 189.43 188.55 188.02 187.50 187.31 186.81\n",
      "\t156.30 155.78 155.76 155.68 155.67 155.60 155.62 155.57 154.08 151.56 150.22 151.58 148.72 148.80 148.43 148.35 148.80 147.87 147.86 147.89\n",
      "\t0.1727 0.1324 0.1483 0.0532 0.0447 0.0387 0.0348 0.0386 0.1343 0.1673 0.1388 0.1484 0.1349 0.1418 0.1337 0.1238 0.1362 0.1289 0.1250 0.1323\n",
      "7\n",
      "\t212.34 211.00 210.98 210.95 210.89 210.77 210.39 206.94 199.50 197.68 194.91 192.56 190.94 189.60 188.47 187.77 187.07 186.48 186.02 185.99\n",
      "\t154.91 154.74 155.88 154.72 154.73 154.62 154.26 152.80 150.45 151.39 148.76 149.34 147.99 147.77 147.85 147.01 146.91 146.56 147.03 146.34\n",
      "\t0.1784 0.1691 0.2511 0.0995 0.0834 0.0729 0.0736 0.2189 0.1812 0.1718 0.1542 0.1565 0.1492 0.1483 0.1419 0.1363 0.1310 0.1306 0.1205 0.1186\n",
      "8\n",
      "\t213.88 212.08 211.87 211.82 211.81 211.76 211.72 211.52 209.86 201.37 196.01 192.64 191.45 189.33 188.22 187.44 186.91 186.37 186.08 185.67\n",
      "\t156.04 154.77 154.72 154.66 154.75 154.68 154.60 154.53 152.38 150.62 149.29 149.22 148.16 147.12 147.27 146.41 146.86 146.42 146.04 146.21\n",
      "\t0.2080 0.1575 0.1453 0.1018 0.0808 0.0749 0.0692 0.0586 0.1937 0.1758 0.1655 0.1954 0.1502 0.1321 0.1213 0.1177 0.1054 0.0960 0.1045 0.0909\n",
      "9\n",
      "\t211.63 210.82 210.79 210.67 210.60 210.46 210.13 207.28 200.29 196.32 193.60 191.48 190.03 189.07 188.29 187.54 187.13 186.75 186.51 186.22\n",
      "\t155.90 155.70 155.62 155.58 155.50 155.47 155.20 153.61 151.63 150.95 149.53 149.32 148.87 148.34 148.14 148.03 147.85 147.51 147.78 147.35\n",
      "\t0.1718 0.1674 0.0980 0.0801 0.0739 0.0650 0.0676 0.1512 0.1860 0.1656 0.1588 0.1447 0.1455 0.1408 0.1445 0.1249 0.1230 0.1168 0.1103 0.1048\n",
      "10\n",
      "\t212.97 211.76 211.59 211.49 209.94 200.15 195.51 192.09 190.12 188.80 187.98 187.42 186.96 186.74 186.85 186.39 186.13 185.85 185.62 185.49\n",
      "\t156.06 155.96 155.89 155.81 154.53 151.64 150.99 149.19 149.42 149.32 148.83 147.93 147.52 147.36 147.39 147.96 147.14 147.35 146.89 146.82\n",
      "\t0.1681 0.1356 0.0834 0.0549 0.1830 0.1694 0.1609 0.1650 0.1566 0.1416 0.1356 0.1182 0.1139 0.1008 0.1026 0.0979 0.0941 0.0904 0.0865 0.0885\n",
      "11\n",
      "\t211.92 211.19 211.19 211.06 210.65 204.03 197.76 193.98 191.86 190.57 189.59 188.88 188.10 187.74 187.17 186.63 186.36 185.93 185.72 185.20\n",
      "\t155.36 155.15 155.14 155.08 154.37 151.31 149.97 149.25 148.88 148.24 148.08 147.86 148.08 147.53 147.67 147.15 147.89 147.02 147.28 146.96\n",
      "\t0.1597 0.0938 0.0784 0.0582 0.0839 0.1898 0.1618 0.1416 0.1360 0.1285 0.1246 0.1275 0.1210 0.1211 0.1217 0.1181 0.1223 0.1182 0.1190 0.1210\n",
      "12\n",
      "\t215.71 211.66 210.28 205.24 199.72 196.66 194.24 192.31 191.07 190.41 189.77 189.26 188.82 188.24 188.00 187.54 187.07 186.82 186.59 186.40\n",
      "\t155.62 155.30 154.08 152.55 151.95 150.41 150.28 149.92 148.86 148.34 148.20 147.98 148.23 147.71 147.75 147.57 147.22 147.44 147.38 147.10\n",
      "\t0.2003 0.1332 0.0986 0.1974 0.1382 0.1154 0.1053 0.1365 0.1296 0.1548 0.1401 0.1488 0.1314 0.1285 0.1219 0.1238 0.1300 0.1239 0.1339 0.1174\n",
      "13\n",
      "\t212.75 211.62 211.37 209.74 199.78 195.04 191.80 189.96 188.88 187.88 187.25 186.73 186.55 186.16 185.71 185.46 185.34 185.23 184.97 184.82\n",
      "\t156.03 155.66 155.50 153.08 151.60 149.71 148.91 149.96 149.00 147.67 149.32 147.34 147.15 147.83 147.05 146.90 147.09 147.19 147.03 146.58\n",
      "\t0.1501 0.0711 0.0508 0.1967 0.1440 0.1384 0.1371 0.1405 0.1312 0.1236 0.1249 0.1158 0.1304 0.1269 0.1238 0.1198 0.1087 0.1174 0.1207 0.1166\n",
      "14\n",
      "\t211.77 211.32 211.20 210.18 200.44 194.55 191.46 189.68 188.26 187.40 186.75 186.33 185.90 185.51 185.10 184.61 184.37 184.16 183.99 183.79\n",
      "\t153.61 153.58 153.51 151.49 149.54 147.56 147.84 146.51 146.08 146.02 145.66 145.35 145.46 145.78 144.91 145.09 145.12 144.65 144.87 144.83\n",
      "\t0.1052 0.0528 0.0415 0.1725 0.1324 0.1394 0.1457 0.1344 0.1280 0.1292 0.1288 0.1202 0.1154 0.1261 0.1170 0.1180 0.1124 0.1127 0.1132 0.1097\n",
      "15\n",
      "\t214.19 212.71 212.58 212.59 212.53 209.99 200.12 195.84 192.66 190.80 189.55 188.81 188.19 187.72 187.30 186.90 187.08 186.62 186.63 186.19\n",
      "\t154.92 154.49 154.50 154.58 154.45 151.71 150.47 149.13 147.83 147.43 146.87 146.56 146.81 146.36 146.56 146.43 146.68 146.01 145.96 145.57\n",
      "\t0.1680 0.1501 0.0997 0.0763 0.0556 0.1911 0.1607 0.1414 0.1403 0.1470 0.1240 0.1359 0.1369 0.1308 0.1252 0.1237 0.1222 0.1201 0.1147 0.1183\n",
      "16\n",
      "\t212.09 210.62 210.50 210.46 210.34 210.20 207.58 199.47 196.04 191.99 189.56 188.30 187.37 186.44 185.95 185.13 184.71 184.39 184.15 184.34\n",
      "\t154.98 154.92 154.85 154.93 154.72 154.58 152.00 150.56 150.14 148.39 147.54 147.44 147.47 146.90 146.97 146.54 146.79 146.77 145.97 146.04\n",
      "\t0.1818 0.1587 0.0734 0.0607 0.0610 0.0620 0.1991 0.1557 0.1403 0.1225 0.0982 0.1258 0.0986 0.0907 0.0858 0.0813 0.0699 0.0695 0.0750 0.0678\n",
      "17\n",
      "\t214.69 211.79 211.62 211.46 211.52 211.52 211.25 207.99 201.10 197.59 193.63 190.84 189.18 188.30 187.30 186.76 186.23 185.73 185.31 185.05\n",
      "\t155.18 154.49 154.43 154.41 154.44 154.36 154.18 151.87 150.82 149.47 147.89 147.55 146.85 146.78 146.61 146.17 145.84 145.71 146.21 146.27\n",
      "\t0.2020 0.1488 0.1423 0.1026 0.0542 0.0479 0.0652 0.1696 0.1435 0.1565 0.1315 0.1108 0.1004 0.0997 0.1097 0.1098 0.1202 0.0913 0.0997 0.0818\n",
      "18\n",
      "\t214.10 211.39 211.28 211.19 211.20 211.05 211.07 210.79 206.08 198.99 195.34 192.54 190.27 188.89 187.93 187.35 187.52 187.10 186.55 186.24\n",
      "\t154.20 154.15 154.17 154.13 154.11 154.04 154.05 153.69 150.72 149.35 148.03 147.28 146.70 146.36 146.15 145.76 145.90 145.68 146.38 145.77\n",
      "\t0.1692 0.1276 0.1139 0.0736 0.0587 0.0455 0.0390 0.0624 0.1930 0.1517 0.1445 0.1414 0.1388 0.1354 0.1279 0.1241 0.1239 0.1220 0.1219 0.1188\n",
      "19\n",
      "\t212.75 212.23 212.15 212.12 212.01 211.60 209.02 200.69 195.26 192.21 190.44 189.18 188.43 187.97 187.42 186.94\n",
      "\t154.30 154.09 154.12 154.11 154.04 153.79 152.01 149.19 148.03 147.10 147.44 146.28 145.83 145.91 146.02 145.65\n",
      "\t0.1005 0.0495 0.0326 0.0422 0.0400 0.0581 0.1967 0.1548 0.1469 0.1351 0.1353 0.1360 0.1278 0.1283 0.1235 0.1310\n",
      "20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t213.07 211.78 211.68 211.68 211.58 211.27 207.04 200.38 195.88 192.94 190.92 189.96 189.21 188.66 188.26 187.73 187.46 187.36 186.95 186.71\n",
      "\t155.96 155.62 155.61 155.56 155.52 155.27 152.70 150.87 150.05 149.10 148.86 149.19 148.77 147.62 147.93 147.76 147.42 147.14 147.37 147.69\n",
      "\t0.1644 0.1452 0.0518 0.0397 0.0341 0.0669 0.1453 0.1369 0.1370 0.1273 0.1435 0.1287 0.1366 0.1315 0.1233 0.1289 0.1221 0.0994 0.0945 0.0984\n",
      "21\n",
      "\t211.86 210.59 210.44 210.23 209.54 200.69 193.07 189.64 187.93 186.98 186.00 185.20 185.20 185.27 184.45 184.26 184.11 183.61 183.51 183.24\n",
      "\t154.51 154.49 154.45 154.38 152.89 150.08 147.76 147.59 146.23 145.99 146.59 145.61 145.68 145.89 145.53 144.83 145.18 144.99 144.80 144.92\n",
      "\t0.1061 0.0644 0.0431 0.0452 0.1121 0.1723 0.1309 0.1073 0.0989 0.0939 0.0876 0.0802 0.0742 0.0808 0.0845 0.0898 0.0851 0.0868 0.0865 0.0820\n",
      "22\n",
      "\t215.25 211.53 211.30 211.29 211.29 211.17 211.08 207.43 197.39 193.44 190.91 189.23 188.28 187.35 186.61 186.28 185.85 185.43 185.16 184.79\n",
      "\t154.47 154.48 154.44 154.42 154.47 154.37 154.43 151.20 149.07 148.33 147.48 146.70 146.74 146.24 145.83 145.46 145.47 145.31 145.31 145.16\n",
      "\t0.2091 0.0765 0.0441 0.0339 0.0323 0.0332 0.0360 0.1704 0.1562 0.1334 0.1569 0.1539 0.1598 0.1321 0.1266 0.1170 0.1182 0.1082 0.1022 0.0928\n",
      "23\n",
      "\t210.50 210.01 209.91 209.81 207.65 198.51 194.81 192.05 190.46 188.81 187.75 186.85 185.97 185.42 184.92 184.60 184.11 184.06 183.80 183.81\n",
      "\t155.00 154.92 154.93 154.76 152.71 151.25 149.81 148.64 148.69 148.30 148.47 147.35 147.57 147.68 146.83 148.37 146.57 147.48 146.33 146.01\n",
      "\t0.1568 0.0791 0.0579 0.0497 0.1931 0.1775 0.1529 0.1394 0.1553 0.1473 0.1374 0.1315 0.1215 0.1124 0.1083 0.1063 0.0983 0.1068 0.0967 0.0907\n",
      "24\n",
      "\t214.82 211.99 211.62 211.49 211.44 211.38 211.13 208.90 200.18 196.01 193.18 191.42 189.97 189.07 188.36 187.91 187.20 186.53 186.05 185.89\n",
      "\t156.16 155.67 155.62 155.70 155.65 155.69 155.42 153.33 151.44 152.06 149.79 148.75 148.70 148.33 148.11 147.85 147.83 147.75 147.58 147.31\n",
      "\t0.1950 0.1386 0.0599 0.0416 0.0337 0.0393 0.0473 0.2121 0.1955 0.1567 0.1741 0.1642 0.1498 0.1465 0.1358 0.1272 0.1307 0.1329 0.1314 0.1234\n",
      "25\n",
      "\t212.65 211.19 211.07 211.04 211.10 210.93 210.61 207.96 200.33 197.32 194.00 191.57 190.21 189.07 188.13 187.38 186.96 186.33 185.93 185.47\n",
      "\t154.96 154.84 154.79 154.88 154.89 154.76 154.46 152.22 151.14 150.16 149.31 148.03 148.19 147.52 147.64 147.08 146.83 146.79 146.40 146.17\n",
      "\t0.1708 0.1577 0.1073 0.0799 0.0665 0.0557 0.0607 0.1908 0.1455 0.1424 0.1405 0.1329 0.1345 0.1310 0.1175 0.1330 0.1424 0.1290 0.1236 0.1179\n",
      "26\n",
      "\t212.01 211.14 211.05 210.99 211.06 211.00 210.92 210.03 202.37 196.79 192.62 189.92 188.59 187.53 186.96 186.30 185.81 185.46 185.07\n",
      "\t155.83 155.61 155.62 155.65 155.60 155.58 155.51 154.45 151.33 149.78 148.81 148.86 148.29 147.85 147.64 147.27 147.66 147.33 147.46\n",
      "\t0.1383 0.0625 0.0468 0.0360 0.0334 0.0309 0.0329 0.1069 0.1416 0.1395 0.1367 0.1405 0.1386 0.1313 0.1286 0.1232 0.1222 0.1200 0.1171\n",
      "27\n",
      "\t214.32 212.72 212.62 212.61 212.70 212.65 212.58 212.53 207.24 199.45 195.31 192.74 191.45 190.33 189.34 188.79 188.33 188.06 187.52 187.38\n",
      "\t154.68 154.40 154.31 154.27 154.27 154.32 154.35 154.12 150.94 150.26 148.36 148.04 147.33 147.22 146.79 146.88 146.84 146.31 145.94 145.96\n",
      "\t0.1585 0.1602 0.1217 0.0679 0.0515 0.0457 0.0372 0.0434 0.1280 0.1375 0.1436 0.1352 0.1235 0.1240 0.1288 0.1185 0.1090 0.1202 0.1278 0.1266\n",
      "28\n",
      "\t213.27 211.30 211.17 211.15 210.96 210.56 203.64 197.99 193.33 190.63 189.06 188.23 187.31 186.57 186.42 186.07 186.04 186.17 185.59 185.22\n",
      "\t155.04 154.91 154.96 155.00 154.94 154.50 151.78 150.00 148.83 148.06 148.27 147.35 147.06 147.47 147.17 147.84 147.14 146.74 146.36 146.44\n",
      "\t0.1612 0.1445 0.0657 0.0513 0.0397 0.0993 0.1731 0.1489 0.1519 0.1363 0.1340 0.1314 0.1150 0.1255 0.1242 0.1379 0.1357 0.1253 0.1241 0.1208\n",
      "29\n",
      "\t212.24 211.02 211.01 211.02 211.04 210.76 206.50 198.40 193.98 191.34 189.67 188.53 187.85 186.80 186.67 185.86 185.57 185.17 184.77 184.58\n",
      "\t154.48 154.33 154.33 154.40 154.22 154.18 150.99 149.38 148.72 147.69 147.32 147.18 146.63 146.65 146.67 146.35 145.89 146.04 146.36 146.15\n",
      "\t0.1491 0.1028 0.0740 0.0574 0.0480 0.0390 0.1897 0.1429 0.1392 0.1256 0.1142 0.1217 0.1203 0.1184 0.1115 0.1100 0.1221 0.1187 0.1171 0.1135\n",
      "30\n",
      "\t212.88 211.54 211.19 211.05 210.83 207.00 199.71 195.28 192.11 190.19 188.90 188.05 187.53 186.97 186.52 186.07 186.00 185.79 185.48 185.17\n",
      "\t156.25 155.51 155.65 155.52 155.23 152.66 151.07 150.69 148.74 148.19 148.39 147.63 148.30 147.92 147.97 147.46 147.27 147.34 146.91 146.91\n",
      "\t0.1975 0.1494 0.0887 0.0558 0.0634 0.1742 0.1472 0.1563 0.1319 0.1382 0.1429 0.1277 0.1181 0.1148 0.1152 0.1099 0.1102 0.1095 0.1047 0.1163\n",
      "31\n",
      "\t211.76 210.82 210.83 210.77 210.72 210.55 210.33 209.63 204.81\n",
      "\t155.17 154.72 154.65 154.67 154.60 154.54 154.44 153.92 151.57\n",
      "\t0.1636 0.1040 0.0601 0.0593 0.0539 0.0492 0.0516 0.0959 0.1727\n",
      "32\n",
      "\t211.87 211.39 211.40 211.42 211.35 211.13 205.51 199.04 194.52 191.33 189.34 188.36 187.80\n",
      "\t154.30 154.08 154.11 154.07 154.03 153.67 150.96 149.56 148.45 147.41 147.07 147.15 147.21\n",
      "\t0.1290 0.1608 0.0459 0.0383 0.0363 0.0451 0.1260 0.1478 0.1543 0.1438 0.1339 0.1500 0.1756\n",
      "33\n",
      "\t213.64 211.86 211.78 211.74 211.61 210.12 200.51 196.04 191.40 189.22 187.79 186.81 186.28 186.17 186.04 185.93 185.20 184.82 184.51 184.48\n",
      "\t155.21 155.06 155.02 155.01 154.99 152.77 151.00 149.08 148.98 147.88 147.15 146.49 146.10 146.22 145.96 145.87 146.08 145.89 145.79 145.56\n",
      "\t0.1447 0.0623 0.0383 0.0399 0.0347 0.2115 0.1443 0.1291 0.1505 0.1116 0.1115 0.1004 0.0879 0.0802 0.0804 0.0779 0.0793 0.0734 0.0745 0.0746\n",
      "34\n",
      "\t213.37 211.90 211.71 211.66 211.56 211.08 203.64 198.98\n",
      "\t155.07 154.74 154.82 154.78 154.79 153.97 150.82 151.23\n",
      "\t0.1825 0.1375 0.1041 0.0669 0.0433 0.0825 0.1423 0.1228\n",
      "35\n",
      "\t212.26 211.22 211.15 211.14 211.10 211.04 210.38 204.83 198.82 194.69 191.40 189.31 187.82 187.06 186.36 186.00 185.73 185.42 185.39 185.08\n",
      "\t155.98 155.84 155.79 155.85 155.75 155.68 155.11 152.42 151.45 151.19 149.32 149.32 147.98 147.77 147.42 147.31 146.97 147.81 147.09 146.74\n",
      "\t0.1669 0.1332 0.0679 0.0463 0.0481 0.0477 0.0716 0.1561 0.1602 0.1422 0.1449 0.1347 0.1241 0.1179 0.1165 0.1051 0.0983 0.0994 0.0941 0.0866\n",
      "36\n",
      "\t212.55 211.32 211.16 211.07 210.98 210.43 206.61 200.36 197.30\n",
      "\t154.96 155.02 154.86 154.87 154.72 154.22 152.36 151.82 150.89\n",
      "\t0.1443 0.0935 0.0622 0.0493 0.0638 0.0935 0.1439 0.1542 0.1716\n",
      "37\n",
      "\t212.74 211.28 211.15 211.10 210.91 210.38 203.54 198.67 195.95 193.57 191.46 190.91 189.58 189.13 188.87 188.19\n",
      "\t155.18 154.83 155.07 154.93 154.94 153.87 151.47 150.91 149.35 148.91 148.59 148.60 149.19 149.31 148.45\n",
      "\t0.1571 0.1633 0.1001 0.0570 0.0464 0.1139 0.1848 0.1382 0.1335 0.1352 0.1418 0.1416 0.1359 0.1308 0.1323\n",
      "38\n",
      "\t213.77 211.47 211.28 211.22 211.09 207.32 199.56 196.04 193.36 191.48 190.18 189.51 188.95 188.20 187.79 187.20 186.61 186.20 185.89 185.63\n",
      "\t155.89 155.65 155.63 155.55 155.35 152.67 151.36 150.14 149.70 149.26 149.41 149.98 148.37 148.55 149.57 147.95 147.83 147.78 148.02 147.39\n",
      "\t0.1887 0.1646 0.1032 0.0615 0.0464 0.1785 0.1746 0.1679 0.1358 0.1234 0.1073 0.1491 0.1421 0.1342 0.1319 0.1242 0.1262 0.1200 0.1202 0.1156\n",
      "39\n",
      "\t211.40 210.80 210.75 210.53 209.67 200.34 195.34 191.89 189.80 188.59 187.61 186.90 186.23 185.80 185.44 184.90\n",
      "\t155.16 155.03 155.02 154.90 153.24 150.41 149.81 148.52 148.05 148.08 147.75 148.57 147.47 148.05 146.56 146.69\n",
      "\t0.1481 0.0580 0.0434 0.0416 0.1294 0.1577 0.1375 0.1360 0.1339 0.1266 0.1185 0.1285 0.1221 0.1236 0.1162 0.1199\n"
     ]
    }
   ],
   "source": [
    "prior_prof_val_losses = print_profile_losses(os.path.join(profile_models_path, \"BPNet_prior_keep20\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean without priors: 145.702885\n",
      "Mean with priors: 146.737467\n",
      "One-sided t-test p: 0.000560\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bin_num = 20\n",
    "plt.figure()\n",
    "plt.hist(\n",
    "    [np.array(list(noprior_prof_val_losses.values())), np.array(list(prior_prof_val_losses.values()))],\n",
    "    bin_num, histtype=\"bar\",\n",
    "    label=[\"No prior\", \"With Fourier prior\"], color=[\"red\", \"blue\"])\n",
    "title = \"Histogram of validation profile loss without/with Fourier priors\"\n",
    "title += \"\\nSPI1, %d/%d profile models without/with Fourier priors\" % (len(noprior_prof_val_losses), len(prior_prof_val_losses))\n",
    "title += \"\\nTraining on top 20% of peaks\"\n",
    "plt.title(title)\n",
    "plt.xlabel(\"Validation profile loss\")\n",
    "plt.legend()\n",
    "\n",
    "np_vals, p_vals = np.array(list(noprior_prof_val_losses.values())), np.array(list(prior_prof_val_losses.values()))\n",
    "t, p = scipy.stats.ttest_ind(np_vals, p_vals)\n",
    "print(\"Mean without priors: %f\" % np.mean(np_vals))\n",
    "print(\"Mean with priors: %f\" % np.mean(p_vals))\n",
    "print(\"One-sided t-test p: %f\" % (p / 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_binary_losses(models_path, max_epoch=None):\n",
    "    \"\"\"\n",
    "    Given the path to a condition containing many runs, prints out the best validation\n",
    "    losses for each run, and the set of losses for training and validation over all\n",
    "    epochs, as well as the validation prior loss. If given, only consider up to\n",
    "    `max_epoch` epochs total; anything afterward would be ignored.\n",
    "    \"\"\"\n",
    "    print(\"Best validation loss overall:\")\n",
    "    best_run, best_epoch, best_val, all_vals = get_best_metric_at_best_epoch(\n",
    "        models_path,\n",
    "        \"val_corr_losses\",\n",
    "        lambda values: np.mean(values),\n",
    "        lambda x, y: x < y,\n",
    "        max_epoch\n",
    "    )\n",
    "    print(\"\\tBest run: %s\" % best_run)\n",
    "    print(\"\\tBest epoch in run: %d\" % best_epoch)\n",
    "    print(\"\\tAssociated value: %s\" % best_val)\n",
    "    \n",
    "    print(\"Best epoch in each run:\")\n",
    "    for key in sorted(all_vals.keys(), key=lambda p: int(p[0])):\n",
    "        print(\"\\tRun %s, epoch %d: %6.3f\" % (key[0], key[1], all_vals[key]))\n",
    "        \n",
    "    print(\"All validation profile and prior losses:\")\n",
    "    for key in sorted(all_vals.keys(), key=lambda p: int(p[0])):\n",
    "        print(key[0])\n",
    "        metrics = import_metrics_json(models_path, key[0])\n",
    "        print(\"\\t\" + \" \".join([\"%6.3f\" % i for i in np.mean(metrics[\"train_corr_losses\"][\"values\"], axis=1)[:max_epoch]]))\n",
    "        print(\"\\t\" + \" \".join([\"%6.3f\" % i for i in np.mean(metrics[\"val_corr_losses\"][\"values\"], axis=1)[:max_epoch]]))\n",
    "        print(\"\\t\" + \" \".join([\"%6.3f\" % i for i in np.mean(metrics[\"val_att_losses\"][\"values\"], axis=1)[:max_epoch]]))\n",
    "    return all_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_models_path = \"/users/amtseng/att_priors/models/trained_models/binary/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss overall:\n",
      "\tBest run: 18\n",
      "\tBest epoch in run: 1\n",
      "\tAssociated value: 0.24132131622769895\n",
      "Best epoch in each run:\n",
      "\tRun 1, epoch 1:  0.248\n",
      "\tRun 3, epoch 1:  0.255\n",
      "\tRun 4, epoch 1:  0.252\n",
      "\tRun 5, epoch 1:  0.254\n",
      "\tRun 7, epoch 1:  0.242\n",
      "\tRun 8, epoch 1:  0.254\n",
      "\tRun 9, epoch 1:  0.253\n",
      "\tRun 11, epoch 1:  0.251\n",
      "\tRun 12, epoch 1:  0.249\n",
      "\tRun 13, epoch 1:  0.253\n",
      "\tRun 14, epoch 1:  0.245\n",
      "\tRun 15, epoch 1:  0.246\n",
      "\tRun 16, epoch 1:  0.265\n",
      "\tRun 18, epoch 1:  0.241\n",
      "\tRun 19, epoch 1:  0.247\n",
      "\tRun 20, epoch 1:  0.254\n",
      "\tRun 23, epoch 1:  0.248\n",
      "\tRun 24, epoch 1:  0.253\n",
      "\tRun 25, epoch 1:  0.249\n",
      "\tRun 28, epoch 1:  0.249\n",
      "\tRun 29, epoch 1:  0.249\n",
      "\tRun 30, epoch 1:  0.250\n",
      "All validation profile and prior losses:\n",
      "1\n",
      "\t 0.215  0.142  0.109  0.089  0.078\n",
      "\t 0.248  0.281  0.331  0.372  0.400\n",
      "\t 0.000  0.000  0.000  0.000  0.000\n",
      "3\n",
      "\t 0.219  0.143  0.109  0.090  0.078\n",
      "\t 0.255  0.314  0.346  0.384  0.423\n",
      "\t 0.000  0.000  0.000  0.000  0.000\n",
      "4\n",
      "\t 0.224  0.146  0.113  0.092  0.079\n",
      "\t 0.252  0.282  0.311  0.384  0.415\n",
      "\t 0.000  0.000  0.000  0.000  0.000\n",
      "5\n",
      "\t 0.214  0.140  0.106  0.089  0.077\n",
      "\t 0.254  0.270  0.334  0.370  0.409\n",
      "\t 0.000  0.000  0.000  0.000  0.000\n",
      "7\n",
      "\t 0.217  0.143  0.110  0.092  0.079\n",
      "\t 0.242  0.289  0.320  0.351  0.431\n",
      "\t 0.000  0.000  0.000  0.000  0.000\n",
      "8\n",
      "\t 0.218  0.144  0.110  0.091  0.079\n",
      "\t 0.254  0.290  0.344  0.413  0.413\n",
      "\t 0.000  0.000  0.000  0.000  0.000\n",
      "9\n",
      "\t 0.214  0.140  0.108  0.090  0.077\n",
      "\t 0.253  0.307  0.333  0.368  0.424\n",
      "\t 0.000  0.000  0.000  0.000  0.000\n",
      "11\n",
      "\t 0.218  0.143  0.109  0.091  0.078\n",
      "\t 0.251  0.293  0.334  0.397  0.451\n",
      "\t 0.000  0.000  0.000  0.000  0.000\n",
      "12\n",
      "\t 0.220  0.144  0.110  0.091  0.078\n",
      "\t 0.249  0.308  0.336  0.397  0.416\n",
      "\t 0.000  0.000  0.000  0.000  0.000\n",
      "13\n",
      "\t 0.215  0.140  0.108  0.089  0.077\n",
      "\t 0.253  0.297  0.330  0.382  0.418\n",
      "\t 0.000  0.000  0.000  0.000  0.000\n",
      "14\n",
      "\t 0.217  0.142  0.108  0.090  0.078\n",
      "\t 0.245  0.292  0.327  0.385  0.423\n",
      "\t 0.000  0.000  0.000  0.000  0.000\n",
      "15\n",
      "\t 0.216  0.140  0.107  0.089  0.078\n",
      "\t 0.246  0.288  0.334  0.367  0.416\n",
      "\t 0.000  0.000  0.000  0.000  0.000\n",
      "16\n",
      "\t 0.224  0.144  0.111  0.093  0.080\n",
      "\t 0.265  0.292  0.349  0.389  0.448\n",
      "\t 0.000  0.000  0.000  0.000  0.000\n",
      "18\n",
      "\t 0.216  0.140  0.108  0.090  0.078\n",
      "\t 0.241  0.290  0.317  0.362  0.401\n",
      "\t 0.000  0.000  0.000  0.000  0.000\n",
      "19\n",
      "\t 0.218  0.143  0.110  0.091  0.079\n",
      "\t 0.247  0.289  0.343  0.389  0.402\n",
      "\t 0.000  0.000  0.000  0.000  0.000\n",
      "20\n",
      "\t 0.216  0.141  0.108  0.089  0.079\n",
      "\t 0.254  0.293  0.350  0.405  0.414\n",
      "\t 0.000  0.000  0.000  0.000  0.000\n",
      "23\n",
      "\t 0.215  0.140  0.107  0.088  0.076\n",
      "\t 0.248  0.275  0.333  0.384  0.413\n",
      "\t 0.000  0.000  0.000  0.000  0.000\n",
      "24\n",
      "\t 0.214  0.141  0.109  0.089  0.077\n",
      "\t 0.253  0.298  0.349  0.405  0.442\n",
      "\t 0.000  0.000  0.000  0.000  0.000\n",
      "25\n",
      "\t 0.217  0.141  0.108  0.089  0.077\n",
      "\t 0.249  0.310  0.353  0.405  0.413\n",
      "\t 0.000  0.000  0.000  0.000  0.000\n",
      "28\n",
      "\t 0.221  0.144  0.110  0.091  0.079\n",
      "\t 0.249  0.287  0.326  0.359  0.415\n",
      "\t 0.000  0.000  0.000  0.000  0.000\n",
      "29\n",
      "\t 0.221  0.144  0.110  0.091  0.078\n",
      "\t 0.249  0.293  0.350  0.377  0.423\n",
      "\t 0.000  0.000  0.000  0.000  0.000\n",
      "30\n",
      "\t 0.215  0.140  0.108  0.090  0.077\n",
      "\t 0.250  0.289  0.333  0.373  0.415\n",
      "\t 0.000  0.000  0.000  0.000  0.000\n"
     ]
    }
   ],
   "source": [
    "noprior_bin_val_losses = print_binary_losses(os.path.join(binary_models_path, \"K562\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss overall:\n",
      "\tBest run: 9\n",
      "\tBest epoch in run: 8\n",
      "\tAssociated value: 0.2318139820654168\n",
      "Best epoch in each run:\n",
      "\tRun 1, epoch 3:  0.262\n",
      "\tRun 2, epoch 4:  0.255\n",
      "\tRun 3, epoch 7:  0.244\n",
      "\tRun 4, epoch 7:  0.243\n",
      "\tRun 5, epoch 3:  0.248\n",
      "\tRun 6, epoch 7:  0.236\n",
      "\tRun 7, epoch 7:  0.241\n",
      "\tRun 8, epoch 5:  0.245\n",
      "\tRun 9, epoch 8:  0.232\n",
      "\tRun 10, epoch 5:  0.238\n",
      "\tRun 11, epoch 3:  0.235\n",
      "All validation profile and prior losses:\n",
      "1\n",
      "\t 0.286  0.241  0.220  0.202  0.184  0.170  0.146  0.153  0.125  0.119\n",
      "\t 0.281  0.277  0.262  0.267  0.268  0.337  0.302  0.319  0.329  0.340\n",
      "\t 0.060  0.056  0.050  0.052  0.047  0.063  0.039  0.038  0.035  0.035\n",
      "2\n",
      "\t 0.299  0.247  0.224  0.219  0.205  0.193  0.185  0.156  0.138  0.122\n",
      "\t 0.303  0.260  0.264  0.255  0.263  0.286  0.277  0.291  0.319  0.361\n",
      "\t 0.082  0.061  0.087  0.057  0.070  0.078  0.058  0.045  0.043  0.040\n",
      "3\n",
      "\t 0.293  0.256  0.245  0.225  0.214  0.199  0.183  0.166  0.152  0.133\n",
      "\t 0.343  0.307  0.261  0.279  0.257  0.245  0.244  0.262  0.266  0.293\n",
      "\t 0.082  0.074  0.053  0.057  0.070  0.060  0.045  0.043  0.040  0.041\n",
      "4\n",
      "\t 0.326  0.263  0.253  0.233  0.222  0.209  0.196  0.202  0.199  0.199  0.184  0.170  0.159\n",
      "\t 0.396  0.300  0.269  0.259  0.251  0.261  0.243  0.251  0.256  0.248  0.261  0.273  0.278\n",
      "\t 0.087  0.086  0.057  0.062  0.054  0.068  0.057  0.066  0.066  0.069  0.068  0.059  0.066\n",
      "5\n",
      "\t 0.328  0.272  0.220  0.175  0.141  0.115\n",
      "\t 0.313  0.277  0.248  0.252  0.304  0.331\n",
      "\t 0.054  0.051  0.037  0.039  0.033  0.030\n",
      "6\n",
      "\t 0.314  0.268  0.238  0.225  0.208  0.199  0.187  0.165  0.152  0.137\n",
      "\t 0.325  0.271  0.262  0.245  0.258  0.241  0.236  0.250  0.272  0.287\n",
      "\t 0.069  0.045  0.051  0.044  0.079  0.064  0.046  0.053  0.047  0.040\n",
      "7\n",
      "\t 0.323  0.280  0.255  0.219  0.232  0.204  0.189  0.185  0.184  0.161  0.153  0.147\n",
      "\t 0.295  0.344  0.263  0.256  0.251  0.242  0.241  0.252  0.252  0.257  0.279  0.275\n",
      "\t 0.052  0.070  0.047  0.059  0.048  0.050  0.051  0.069  0.056  0.060  0.056  0.066\n",
      "8\n",
      "\t 0.320  0.278  0.239  0.230  0.206  0.176  0.148  0.126\n",
      "\t 0.349  0.288  0.253  0.252  0.245  0.257  0.280  0.330\n",
      "\t 0.076  0.067  0.054  0.059  0.040  0.041  0.033  0.032\n",
      "9\n",
      "\t 0.296  0.231  0.215  0.222  0.221  0.215  0.194  0.178  0.171  0.160  0.159\n",
      "\t 0.284  0.253  0.249  0.260  0.270  0.245  0.236  0.232  0.250  0.268  0.257\n",
      "\t 0.050  0.055  0.062  0.086  0.066  0.048  0.044  0.044  0.051  0.050  0.067\n",
      "10\n",
      "\t 0.330  0.256  0.219  0.211  0.192  0.175  0.154  0.132\n",
      "\t 0.286  0.261  0.246  0.247  0.238  0.248  0.274  0.285\n",
      "\t 0.080  0.047  0.097  0.056  0.051  0.042  0.036  0.043\n",
      "11\n",
      "\t 0.339  0.264  0.219  0.183  0.165  0.183\n",
      "\t 0.298  0.291  0.235  0.246  0.242  0.242\n",
      "\t 0.065  0.066  0.033  0.048  0.059  0.071\n"
     ]
    }
   ],
   "source": [
    "prior_bin_val_losses = print_binary_losses(os.path.join(binary_models_path, \"K562_prior\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean without priors: 0.250347\n",
      "Mean with priors: 0.243513\n",
      "One-sided t-test p: 0.004315\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bin_num = 20\n",
    "plt.figure()\n",
    "plt.hist(\n",
    "    [np.array(list(noprior_bin_val_losses.values())), np.array(list(prior_bin_val_losses.values()))],\n",
    "    bin_num, histtype=\"bar\",\n",
    "    label=[\"No prior\", \"With Fourier prior\"], color=[\"red\", \"blue\"])\n",
    "title = \"Histogram of validation loss without/with Fourier priors\"\n",
    "title += \"\\nK562, %d/%d binary models without/with priors\" % (len(noprior_bin_val_losses), len(prior_bin_val_losses))\n",
    "title += \"\\nTraining on all peaks\"\n",
    "plt.title(title)\n",
    "plt.xlabel(\"Validation loss\")\n",
    "plt.legend()\n",
    "\n",
    "np_vals, p_vals = np.array(list(noprior_bin_val_losses.values())), np.array(list(prior_bin_val_losses.values()))\n",
    "t, p = scipy.stats.ttest_ind(np_vals, p_vals)\n",
    "print(\"Mean without priors: %f\" % np.mean(np_vals))\n",
    "print(\"Mean with priors: %f\" % np.mean(p_vals))\n",
    "print(\"One-sided t-test p: %f\" % (p / 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
