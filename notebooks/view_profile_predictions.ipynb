{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../src/\"))\n",
    "import extract.data_loading as data_loading\n",
    "import extract.compute_predictions as compute_predictions\n",
    "import extract.compute_shap as compute_shap\n",
    "import extract.compute_ism as compute_ism\n",
    "import model.util as model_util\n",
    "import model.profile_models as profile_models\n",
    "import model.train_profile_model as train_profile_model\n",
    "import matplotlib.font_manager as font_manager\n",
    "import plot.viz_sequence as viz_sequence\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import json\n",
    "import tqdm\n",
    "tqdm.tqdm_notebook()  # It is necessary to call this before the tqdm.notebook submodule is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting defaults\n",
    "font_manager.fontManager.ttflist.extend(\n",
    "    font_manager.createFontList(\n",
    "        font_manager.findSystemFonts(fontpaths=\"/users/amtseng/modules/fonts\")\n",
    "    )\n",
    ")\n",
    "plot_params = {\n",
    "    \"figure.titlesize\": 22,\n",
    "    \"axes.titlesize\": 22,\n",
    "    \"axes.labelsize\": 20,\n",
    "    \"legend.fontsize\": 18,\n",
    "    \"xtick.labelsize\": 16,\n",
    "    \"ytick.labelsize\": 16,\n",
    "    \"font.family\": \"Roboto\",\n",
    "    \"font.weight\": \"bold\"\n",
    "}\n",
    "plt.rcParams.update(plot_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define paths for the model and data of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared paths/constants\n",
    "reference_fasta = \"/users/amtseng/genomes/hg38.fasta\"\n",
    "chrom_sizes = \"/users/amtseng/genomes/hg38.canon.chrom.sizes\"\n",
    "data_base_path = \"/users/amtseng/att_priors/data/processed/\"\n",
    "model_base_path = \"/users/amtseng/att_priors/models/trained_models/profile/\"\n",
    "chrom_set = [\"chr1\"]\n",
    "input_length = 1346\n",
    "profile_length = 1000\n",
    "fourier_att_prior_freq_limit = 200\n",
    "fourier_att_prior_freq_limit_softness = 0.2\n",
    "att_prior_grad_smooth_sigma = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPI1\n",
    "condition_name = \"SPI1\"\n",
    "files_spec_path = os.path.join(data_base_path, \"ENCODE_TFChIP/profile/config/SPI1/SPI1_training_paths.json\")\n",
    "num_tasks = 4\n",
    "num_strands = 2\n",
    "controls = \"matched\"\n",
    "task_index = None\n",
    "model_class = profile_models.ProfilePredictorWithMatchedControls\n",
    "noprior_model_path = os.path.join(model_base_path, \"SPI1/27/model_ckpt_epoch_17.pt\")\n",
    "prior_model_path = os.path.join(model_base_path, \"SPI1_prior/14/model_ckpt_epoch_18.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GATA2\n",
    "condition_name = \"GATA2\"\n",
    "files_spec_path = os.path.join(data_base_path, \"ENCODE_TFChIP/profile/config/GATA2/GATA2_training_paths.json\")\n",
    "num_tasks = 3\n",
    "num_strands = 2\n",
    "controls = \"matched\"\n",
    "task_index = None\n",
    "model_class = profile_models.ProfilePredictorWithMatchedControls\n",
    "noprior_model_path = os.path.join(model_base_path, \"GATA2/6/model_ckpt_epoch_18.pt\")\n",
    "prior_model_path = os.path.join(model_base_path, \"GATA2_prior/12/model_ckpt_epoch_19.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K562\n",
    "condition_name = \"K562\"\n",
    "files_spec_path = os.path.join(data_base_path, \"ENCODE_DNase/profile/config/K562/K562_training_paths.json\")\n",
    "num_tasks = 1\n",
    "num_strands = 1\n",
    "controls = \"shared\"\n",
    "task_index = None\n",
    "model_class = profile_models.ProfilePredictorWithSharedControls\n",
    "noprior_model_path = os.path.join(model_base_path, \"K562/19/model_ckpt_epoch_19.pt\")\n",
    "prior_model_path = os.path.join(model_base_path, \"K562_prior/16/model_ckpt_epoch_20.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BPNet\n",
    "condition_name = \"BPNet\"\n",
    "reference_fasta = \"/users/amtseng/genomes/mm10.fasta\"\n",
    "chrom_sizes = \"/users/amtseng/genomes/mm10.canon.chrom.sizes\"\n",
    "files_spec_path = os.path.join(data_base_path, \"BPNet_ChIPseq/profile/config/BPNet_training_paths.json\")\n",
    "num_tasks = 3\n",
    "num_strands = 2\n",
    "controls = \"shared\"\n",
    "task_index = None\n",
    "model_class = profile_models.ProfilePredictorWithSharedControls\n",
    "noprior_model_path = os.path.join(model_base_path, \"BPNet/20/model_ckpt_epoch_18.pt\")\n",
    "prior_model_path = os.path.join(model_base_path, \"BPNet_prior/25/model_ckpt_epoch_17.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(True)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "def restore_model(model_path):\n",
    "    model = model_util.restore_model(model_class, model_path)\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model without priors\n",
    "noprior_model = restore_model(noprior_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model with priors\n",
    "prior_model = restore_model(prior_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "Create an input data loader, that maps coordinates to data needed for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_func = data_loading.get_profile_input_func(\n",
    "    files_spec_path, input_length, profile_length, reference_fasta\n",
    ")\n",
    "pos_coords = data_loading.get_positive_profile_coords(\n",
    "    files_spec_path, chrom_set=chrom_set, task_ind=task_index\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP explainers\n",
    "Create DeepSHAP explainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noprior_shap_explainer = compute_shap.create_profile_explainer(\n",
    "    noprior_model, input_length, profile_length, num_tasks, num_strands, controls,\n",
    "    task_index=task_index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_shap_explainer = compute_shap.create_profile_explainer(\n",
    "    prior_model, input_length, profile_length, num_tasks, num_strands, controls,\n",
    "    task_index=task_index\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute loss values over test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a subset of peaks randomly to compute predictions for\n",
    "num_samples = 1000\n",
    "rng = np.random.RandomState(20200318)\n",
    "sample_coords = pos_coords[np.random.choice(len(pos_coords), size=num_samples, replace=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a random jitter to avoid center-bias\n",
    "jitters = np.random.randint(-128, 128 + 1, size=len(sample_coords))\n",
    "sample_coords[:, 1] = sample_coords[:, 1] + jitters\n",
    "sample_coords[:, 2] = sample_coords[:, 2] + jitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noprior_preds = compute_predictions.get_profile_model_predictions(                                              \n",
    "    noprior_model, sample_coords, num_tasks, input_func, controls=controls,                        \n",
    "    fourier_att_prior_freq_limit=fourier_att_prior_freq_limit,\n",
    "    fourier_att_prior_freq_limit_softness=fourier_att_prior_freq_limit_softness,\n",
    "    att_prior_grad_smooth_sigma=att_prior_grad_smooth_sigma,\n",
    "    return_losses=True, return_gradients=True, show_progress=True                                         \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_preds = compute_predictions.get_profile_model_predictions(                                              \n",
    "    prior_model, sample_coords, num_tasks, input_func, controls=controls,                        \n",
    "    fourier_att_prior_freq_limit=fourier_att_prior_freq_limit,\n",
    "    fourier_att_prior_freq_limit_softness=fourier_att_prior_freq_limit_softness,\n",
    "    att_prior_grad_smooth_sigma=att_prior_grad_smooth_sigma,\n",
    "    return_losses=True, return_gradients=True, show_progress=True                                         \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of profile loss and prior loss over these conditions\n",
    "bin_num = 20\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 6))\n",
    "all_vals = np.concatenate([noprior_preds[\"prof_losses\"], prior_preds[\"prof_losses\"]])\n",
    "bins = np.linspace(np.min(all_vals), np.max(all_vals), bin_num)\n",
    "ax[0].hist(noprior_preds[\"prof_losses\"], bins=bins, color=\"coral\", label=\"No prior\", alpha=0.7)\n",
    "ax[0].hist(prior_preds[\"prof_losses\"], bins=bins, color=\"slateblue\", label=\"With Fourier prior\", alpha=0.7)\n",
    "ax[0].set_title(\"Histogram of profile loss over %d random test peaks\" % num_samples)\n",
    "ax[0].set_xlabel(\"Profile NLL loss\")\n",
    "ax[0].legend()\n",
    "all_vals = np.concatenate([noprior_preds[\"att_losses\"], prior_preds[\"att_losses\"]])\n",
    "bins = np.linspace(np.min(all_vals), np.max(all_vals), bin_num)\n",
    "ax[1].hist(noprior_preds[\"att_losses\"], bins=bins, color=\"coral\", label=\"No prior\", alpha=0.7)\n",
    "ax[1].hist(prior_preds[\"att_losses\"], bins=bins, color=\"slateblue\", label=\"With Fourier prior\", alpha=0.7)\n",
    "ax[1].set_title(\"Histogram of Fourier prior loss over %d random test peaks\" % num_samples)\n",
    "ax[1].set_xlabel(\"Fourier prior loss\")\n",
    "ax[1].legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of gradients and SHAP scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_shap_scores(model, sample, batch_size=128):\n",
    "    \"\"\"\n",
    "    Given an array of N coordinates or bins, computes the SHAP scores\n",
    "    for the model, returning an N x I x 4 array of SHAP scores and an\n",
    "    N x I x 4 array of one-hot encoded sequence.\n",
    "    \"\"\"\n",
    "    num_samples = len(sample)\n",
    "    num_batches = int(np.ceil(num_samples / batch_size))\n",
    "    \n",
    "    all_shap_scores = np.empty((num_samples, input_length, 4))\n",
    "    all_one_hot_seqs = np.empty((num_samples, input_length, 4))\n",
    "        \n",
    "    shap_explainer = compute_shap.create_profile_explainer(\n",
    "        model, input_length, profile_length, num_tasks, num_strands, controls,\n",
    "        task_index=task_index\n",
    "    )\n",
    "\n",
    "    for i in tqdm.notebook.trange(num_batches):\n",
    "        batch_slice = slice(i * batch_size, (i + 1) * batch_size)\n",
    "        batch = sample[batch_slice]\n",
    "\n",
    "        input_seqs, profiles = input_func(batch)\n",
    "        shap_scores = shap_explainer(\n",
    "            input_seqs, cont_profs=profiles[:, num_tasks:], hide_shap_output=True\n",
    "        )\n",
    "        all_shap_scores[batch_slice] = shap_scores\n",
    "        all_one_hot_seqs[batch_slice] = input_seqs\n",
    "    return all_shap_scores, all_one_hot_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noprior_grads = noprior_preds[\"input_grads\"]\n",
    "prior_grads = prior_preds[\"input_grads\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noprior_shap, _ = compute_shap_scores(noprior_model, sample_coords)\n",
    "prior_shap, one_hot_seqs = compute_shap_scores(prior_model, sample_coords)\n",
    "assert np.all(one_hot_seqs == noprior_preds[\"input_seqs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dft(signal):\n",
    "    fourier_coeffs = np.fft.fft(signal)\n",
    "    fourier_freqs = 2 * np.pi * np.fft.fftfreq(signal.size)\n",
    "    fourier_freqs = fourier_freqs[:int(len(fourier_freqs) / 2)]  # Only the positive frequencies\n",
    "    mags = np.abs(fourier_coeffs)[:int(len(fourier_coeffs) / 2)]  # Frequency magnitudes are symmetric\n",
    "    return fourier_freqs, mags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier_highfreq_mags(imp_scores, freq_limit):\n",
    "    \"\"\"\n",
    "    For an N x I x 4 array of actual importance scores, computes the sum of the\n",
    "    Fourier magnitudes in high frequencies, defined by `freq_limit`. Returns an\n",
    "    N-array of Fourier scores (i.e. sum of low-frequency magnitudes)\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    # Normalize\n",
    "    imp_scores_sum = np.sum(np.abs(imp_scores), axis=2)  # Make into N x I\n",
    "    \n",
    "    for score_track in imp_scores_sum:\n",
    "        freqs, mags = dft(score_track)\n",
    "        freqs, mags = freqs[1:], mags[1:]  # Cut off DC\n",
    "        mags = mags / np.sum(mags)  # Normalize\n",
    "        scores.append(np.sum(mags[freq_limit:]))\n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(imp_scores, pseudocount=0.001):\n",
    "    \"\"\"\n",
    "    For an N x I x 4 array of actual importance scores, computes the entropy\n",
    "    of each track. Returns an N-array of entropy values.\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    # Normalize\n",
    "    imp_scores_sum = np.sum(np.abs(imp_scores), axis=2)  # Make into N x I\n",
    "    imp_scores_sum = imp_scores_sum + pseudocount\n",
    "    imp_scores_norm = imp_scores_sum / np.sum(imp_scores_sum, axis=1, keepdims=True)\n",
    "    \n",
    "    return -np.sum(imp_scores_norm * np.log2(imp_scores_norm), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noprior_grad_fourier_scores = fourier_highfreq_mags(noprior_grads * one_hot_seqs, fourier_att_prior_freq_limit)\n",
    "prior_grad_fourier_scores = fourier_highfreq_mags(prior_grads * one_hot_seqs, fourier_att_prior_freq_limit)\n",
    "noprior_grad_entropy_scores = entropy(noprior_grads * one_hot_seqs)\n",
    "prior_grad_entropy_scores = entropy(prior_grads * one_hot_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noprior_shap_fourier_scores = fourier_highfreq_mags(noprior_shap * one_hot_seqs, fourier_att_prior_freq_limit)\n",
    "prior_shap_fourier_scores = fourier_highfreq_mags(prior_shap * one_hot_seqs, fourier_att_prior_freq_limit)\n",
    "noprior_shap_entropy_scores = entropy(noprior_shap * one_hot_seqs)\n",
    "prior_shap_entropy_scores = entropy(prior_shap * one_hot_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_global_smoothness(\n",
    "    noprior_imp_fourier_scores, prior_imp_fourier_scores, noprior_imp_entropy_scores,\n",
    "    prior_imp_entropy_scores, imp_type\n",
    "):\n",
    "    bin_num = 20\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 6))\n",
    "    all_vals = np.concatenate([noprior_imp_fourier_scores, prior_imp_fourier_scores])\n",
    "    bins = np.linspace(np.min(all_vals), np.max(all_vals), bin_num)\n",
    "    ax[0].hist(noprior_imp_fourier_scores, bins=bins, color=\"coral\", label=\"No prior\", alpha=0.7)\n",
    "    ax[0].hist(prior_imp_fourier_scores, bins=bins, color=\"slateblue\", label=\"With Fourier prior\", alpha=0.7)\n",
    "    ax[0].set_xlabel(\"Sum of high-frequency Fourier magnitudes\")\n",
    "    all_vals = np.concatenate([noprior_imp_entropy_scores, prior_imp_entropy_scores])\n",
    "    bins = np.linspace(np.min(all_vals), np.max(all_vals), bin_num)\n",
    "    ax[1].hist(noprior_imp_entropy_scores, bins=bins, color=\"coral\", label=\"No prior\", alpha=0.7)\n",
    "    ax[1].hist(prior_imp_entropy_scores, bins=bins, color=\"slateblue\", label=\"With Fourier prior\", alpha=0.7)\n",
    "    ax[1].set_xlabel(\"Entropy\")\n",
    "    ax[1].legend()\n",
    "    title = \"Histograms of smoothness of %s\" % imp_type\n",
    "    title += \"\\n%s profile models\" % condition_name\n",
    "    title += \"\\nComputed on %d randomly drawn test peaks\" % num_samples\n",
    "    fig.suptitle(title)\n",
    "    plt.subplots_adjust(top=0.80)\n",
    "    plt.show()\n",
    "    \n",
    "    def draw_xy_line(ax):\n",
    "        limits = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "        ]\n",
    "        ax.plot(limits, limits, \"--\", alpha=0.5, color=\"black\")\n",
    "        ax.set_aspect(\"equal\")\n",
    "        ax.set_xlim(limits)\n",
    "        ax.set_ylim(limits)\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 6))\n",
    "    ax[0].scatter(noprior_imp_fourier_scores, prior_imp_fourier_scores, color=\"mediumorchid\")\n",
    "    ax[0].set_xlabel(\"High frequency sum without prior\")\n",
    "    ax[0].set_ylabel(\"High frequency sum with Fourier prior\")\n",
    "    ax[1].scatter(noprior_imp_entropy_scores, prior_imp_entropy_scores, color=\"mediumorchid\")\n",
    "    ax[1].set_xlabel(\"Entropy without prior\")\n",
    "    ax[1].set_ylabel(\"Entropy with Fourier prior\")\n",
    "    draw_xy_line(ax[0])\n",
    "    draw_xy_line(ax[1])\n",
    "    title = \"Pairwise comparison of %s smoothness\" % imp_type\n",
    "    title += \"\\n%s profile models\" % condition_name\n",
    "    title += \"\\nComputed on %d randomly drawn test peaks\" % num_samples\n",
    "    fig.suptitle(title)\n",
    "    plt.subplots_adjust(top=0.80)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"High-frequency Fourier sum:\")\n",
    "    print(\"Average without priors: %f\" % np.nanmean(noprior_imp_fourier_scores))\n",
    "    print(\"Average with priors: %f\" % np.nanmean(prior_imp_fourier_scores))\n",
    "    print(\"Standard error without priors: %f\" % scipy.stats.sem(noprior_imp_fourier_scores, nan_policy=\"omit\"))\n",
    "    print(\"Standard error with priors: %f\" % scipy.stats.sem(prior_imp_fourier_scores, nan_policy=\"omit\"))\n",
    "    w, p = scipy.stats.wilcoxon(noprior_imp_fourier_scores, prior_imp_fourier_scores, alternative=\"greater\")\n",
    "    print(\"One-sided Wilcoxon test: w = %f, p = %f\" % (w, p))\n",
    "    print(\"Entropy:\")\n",
    "    print(\"Average without priors: %f\" % np.nanmean(noprior_imp_entropy_scores))\n",
    "    print(\"Average with priors: %f\" % np.nanmean(prior_imp_entropy_scores))\n",
    "    print(\"Standard error without priors: %f\" % scipy.stats.sem(noprior_imp_entropy_scores, nan_policy=\"omit\"))\n",
    "    print(\"Standard error with priors: %f\" % scipy.stats.sem(prior_imp_entropy_scores, nan_policy=\"omit\"))\n",
    "    w, p = scipy.stats.wilcoxon(noprior_imp_entropy_scores, prior_imp_entropy_scores, alternative=\"greater\")\n",
    "    print(\"One-sided Wilcoxon test: w = %f, p = %f\" % (w, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_global_smoothness(\n",
    "    noprior_grad_fourier_scores, prior_grad_fourier_scores, noprior_grad_entropy_scores,\n",
    "    prior_grad_entropy_scores, \"input gradients\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_global_smoothness(\n",
    "    noprior_shap_fourier_scores, prior_shap_fourier_scores, noprior_shap_entropy_scores,\n",
    "    prior_shap_entropy_scores, \"DeepSHAP scores\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_profiles(pred_profs, true_profs, title=None):\n",
    "    \"\"\"\n",
    "    Plots the given profiles.\n",
    "    Both arguments should be T x O x S NumPy arrays, where the subarrays are the\n",
    "    tracks for the plus and minus strand (or unstranded), for each task.\n",
    "    If `normalize` is True, normalize the profiles to be probabilities (i.e.\n",
    "    each track sums to 1)\n",
    "    \"\"\"\n",
    "    num_tasks, prof_length, num_strands = pred_profs.shape\n",
    "    fig, ax = plt.subplots(num_tasks, figsize=(15, num_tasks * 2 * num_strands))\n",
    "    if num_tasks == 1:\n",
    "        ax = [ax]\n",
    "    for i in range(num_tasks):\n",
    "        ax[i].plot(true_profs[i,:,0], color=\"royalblue\", alpha=0.5)\n",
    "        ax[i].plot(pred_profs[i,:,0], color=\"darkslateblue\")\n",
    "        if num_strands == 2:\n",
    "            ax[i].plot(-true_profs[i,:,1], color=\"goldenrod\", alpha=0.5)\n",
    "            ax[i].plot(-pred_profs[i,:,1], color=\"darkorange\")\n",
    "    if title:\n",
    "        fig.suptitle(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fft(signal, include_dc=False, pos_limit=None, title=None):\n",
    "    abs_signal = np.abs(signal)\n",
    "    \n",
    "    freqs, mags = dft(abs_signal)\n",
    "    if not include_dc:\n",
    "        freqs, mags = freqs[1:], mags[1:]\n",
    "        \n",
    "    plt.figure(figsize=(20, 2))\n",
    "    plt.plot(freqs, mags, color=\"red\")\n",
    "    plt.xlabel(\"Frequency (radians)\")\n",
    "    plt.ylabel(\"|Frequency component|\")\n",
    "    if pos_limit is not None:\n",
    "        pos_limit_radians = pos_limit * 2 * np.pi / len(signal)\n",
    "        plt.axvline(x=pos_limit_radians, color=\"black\")\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_signal(signal, title=None, color=None):\n",
    "    plt.figure(figsize=(20, 2))\n",
    "    plt.plot(signal, color=color)\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_plot(\n",
    "    model, shap_explainer, chrom, start, end, with_priors, show_sequences=True,\n",
    "    seq_slices=[slice(650, 750)]\n",
    "):\n",
    "    if type(seq_slices) is not list:\n",
    "        seq_slices = [seq_slices]\n",
    "    results = compute_predictions.get_profile_model_predictions(                                              \n",
    "        model, [(chrom, start, end)] * 50, num_tasks, input_func, controls=controls,                        \n",
    "        return_losses=False, return_gradients=True, show_progress=False                                         \n",
    "    )\n",
    "    true_profs = results[\"true_profs\"]\n",
    "    log_pred_profs = results[\"log_pred_profs\"]\n",
    "    input_seqs = results[\"input_seqs\"]\n",
    "    input_grads = results[\"input_grads\"]\n",
    "\n",
    "    pred_prof_probs = np.exp(log_pred_profs)\n",
    "    true_prof_probs = true_profs / np.sum(true_profs, axis=2, keepdims=True)\n",
    "    \n",
    "    # plot_profiles(pred_prof_probs[0], true_prof_probs[0])\n",
    "    \n",
    "    color = \"slateblue\" if with_priors else \"coral\"\n",
    "    print(\"Input gradients and Fourier transform\")\n",
    "    plot_signal(np.sum(input_grads[0] * input_seqs[0], axis=1), title=\"Input gradients\", color=color)\n",
    "    plot_fft(np.sum(input_grads[0] * input_seqs[0], axis=1), pos_limit=200, title=\"Fourier transform of input gradients\")\n",
    "    if show_sequences:\n",
    "        for seq_slice in seq_slices:\n",
    "            viz_sequence.plot_weights(input_grads[0][seq_slice], subticks_frequency=1000)\n",
    "            viz_sequence.plot_weights((input_grads[0] * input_seqs[0])[seq_slice], subticks_frequency=1000)\n",
    "    \n",
    "    print(\"DeepSHAP scores\")\n",
    "    input_seqs, profiles = input_func([(chrom, start, end)] * 5)\n",
    "    hyp_shap_scores = shap_explainer(\n",
    "        input_seqs, cont_profs=profiles[:, num_tasks:], hide_shap_output=True\n",
    "    )\n",
    "    plot_signal(np.sum(hyp_shap_scores[0] * input_seqs[0], axis=1), title=\"DeepSHAP scores\", color=color)\n",
    "    if show_sequences:\n",
    "        for seq_slice in seq_slices:\n",
    "            viz_sequence.plot_weights(hyp_shap_scores[0][seq_slice], subticks_frequency=1000)\n",
    "            viz_sequence.plot_weights((hyp_shap_scores[0] * input_seqs[0])[seq_slice], subticks_frequency=1000)\n",
    "    \n",
    "    print(\"ISM scores\")\n",
    "    hyp_ism_scores = compute_ism.get_profile_model_ism(\n",
    "        model, input_seqs, cont_profs=profiles[:, num_tasks:], task_index=task_index\n",
    "    )\n",
    "    plot_signal(np.sum(hyp_ism_scores[0] * input_seqs[0], axis=1), title=\"ISM scores\", color=color)\n",
    "    if show_sequences:\n",
    "        for seq_slice in seq_slices:\n",
    "            viz_sequence.plot_weights(hyp_ism_scores[0][seq_slice], subticks_frequency=1000)\n",
    "            viz_sequence.plot_weights((hyp_ism_scores[0] * input_seqs[0])[seq_slice], subticks_frequency=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample some random peaks\n",
    "pos_coords[np.random.choice(len(pos_coords), size=10, replace=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The coordinates that show the most improvement in prior loss\n",
    "sample_coords[np.flip(np.argsort(noprior_preds[\"att_losses\"] - prior_preds[\"att_losses\"]))][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SPI1\n",
    "chrom, start, end = 'chr1', 35434438, 35434678\n",
    "seq_slices = [slice(200, 500), slice(525, 575)]\n",
    "show_sequences = True\n",
    "predict_and_plot(noprior_model, noprior_shap_explainer, chrom, start, end, False, show_sequences, seq_slices)\n",
    "predict_and_plot(prior_model, prior_shap_explainer, chrom, start, end, True, show_sequences, seq_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SPI1 (bQTL)\n",
    "chrom, start, end = 'chr1', 220718074 - (1346 // 2), 220718074 + (1346 // 2)\n",
    "seq_slices = [slice(663, 683)]\n",
    "show_sequences = True\n",
    "predict_and_plot(noprior_model, noprior_shap_explainer, chrom, start, end, False, show_sequences, seq_slices)\n",
    "predict_and_plot(prior_model, prior_shap_explainer, chrom, start, end, True, show_sequences, seq_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# GATA2\n",
    "chrom, start, end = 'chr1', 155117668, 155118072\n",
    "seq_slices = [slice(625, 675)]\n",
    "show_sequences = True\n",
    "predict_and_plot(noprior_model, noprior_shap_explainer, chrom, start, end, False, show_sequences, seq_slices)\n",
    "predict_and_plot(prior_model, prior_shap_explainer, chrom, start, end, True, show_sequences, seq_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# K562\n",
    "chrom, start, end = 'chr1', 153404765, 153405084\n",
    "seq_slices = [slice(575, 700)]\n",
    "show_sequences = True\n",
    "predict_and_plot(noprior_model, noprior_shap_explainer, chrom, start, end, False, show_sequences, seq_slices)\n",
    "predict_and_plot(prior_model, prior_shap_explainer, chrom, start, end, True, show_sequences, seq_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# BPNet (Nanog)\n",
    "chrom, start, end = 'chr1', 157459024, 157459288\n",
    "seq_slices = [slice(625, 700)]\n",
    "show_sequences = True\n",
    "predict_and_plot(noprior_model, noprior_shap_explainer, chrom, start, end, False, show_sequences, seq_slices)\n",
    "predict_and_plot(prior_model, prior_shap_explainer, chrom, start, end, True, show_sequences, seq_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# BPNet (Nanog)\n",
    "chrom, start, end = 'chr1', 186386397, 186386741\n",
    "seq_slices = [slice(625, 725)]\n",
    "show_sequences = True\n",
    "predict_and_plot(noprior_model, noprior_shap_explainer, chrom, start, end, False, show_sequences, seq_slices)\n",
    "predict_and_plot(prior_model, prior_shap_explainer, chrom, start, end, True, show_sequences, seq_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# BPNet (Oct4)\n",
    "chrom, start, end = 'chr1', 192763472, 192763816\n",
    "seq_slices = [slice(400, 450)]\n",
    "show_sequences = True\n",
    "predict_and_plot(noprior_model, noprior_shap_explainer, chrom, start, end, False, show_sequences, seq_slices)\n",
    "predict_and_plot(prior_model, prior_shap_explainer, chrom, start, end, True, show_sequences, seq_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# BPNet (Oct4)\n",
    "chrom, start, end = 'chr1', 171150446, 171150446\n",
    "seq_slices = [slice(525, 575), slice(900, 1200)]\n",
    "show_sequences = True\n",
    "predict_and_plot(noprior_model, noprior_shap_explainer, chrom, start, end, False, show_sequences, seq_slices)\n",
    "predict_and_plot(prior_model, prior_shap_explainer, chrom, start, end, True, show_sequences, seq_slices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
