{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting defaults\n",
    "font_manager.fontManager.ttflist.extend(\n",
    "    font_manager.createFontList(\n",
    "        font_manager.findSystemFonts(fontpaths=\"/users/amtseng/modules/fonts\")\n",
    "    )\n",
    ")\n",
    "plot_params = {\n",
    "    \"figure.titlesize\": 22,\n",
    "    \"axes.titlesize\": 22,\n",
    "    \"axes.labelsize\": 20,\n",
    "    \"axes.labelweight\": \"bold\",\n",
    "    \"legend.fontsize\": 18,\n",
    "    \"xtick.labelsize\": 16,\n",
    "    \"ytick.labelsize\": 16,\n",
    "    \"font.family\": \"Roboto\",\n",
    "    \"font.weight\": \"bold\"\n",
    "}\n",
    "plt.rcParams.update(plot_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define paths for the model and data of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"binary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type == \"binary\":\n",
    "    models_base_path = \"/users/amtseng/att_priors/models/trained_models/binary/\"\n",
    "else:\n",
    "    models_base_path = \"/users/amtseng/att_priors/models/trained_models/profile/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_name = \"SPI1\"\n",
    "noprior_models_path = os.path.join(models_base_path, \"%s\" % condition_name)\n",
    "prior_models_path = os.path.join(models_base_path, \"%s_prior\" % condition_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing saved metrics JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_metrics_json(models_path, run_num):\n",
    "    \"\"\"\n",
    "    Looks in `{models_path}/{run_num}/metrics.json` and returns the contents as a\n",
    "    Python dictionary. Returns None if the path does not exist, or if the JSON is\n",
    "    malformed.\n",
    "    \"\"\"\n",
    "    path = os.path.join(models_path, str(run_num), \"metrics.json\")\n",
    "    if not os.path.exists(path):\n",
    "        print(\"Path does not exist: %s\" % path)\n",
    "        return None\n",
    "    try:\n",
    "        with open(path, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Malformed JSON: %s\" % path)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_all_metrics_json(models_path):\n",
    "    \"\"\"\n",
    "    Looks in `models_path` and finds all instances of\n",
    "    `{models_path}/{run_num}/metrics.json`, returning a dictionary that maps\n",
    "    `{run_num}` to the metrics dictionary.\n",
    "    \"\"\"\n",
    "    all_metrics = {run_num : import_metrics_json(models_path, run_num) for run_num in os.listdir(models_path)}\n",
    "    all_metrics = {key : val for key, val in all_metrics.items() if val}  # Remove empties\n",
    "    return all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_config_json(models_path, run_num):\n",
    "    \"\"\"\n",
    "    Looks in `{models_path}/{run_num}/config.json` and returns the contents as a\n",
    "    Python dictionary. Returns None if the path does not exist, or if the JSON is\n",
    "    malformed.\n",
    "    \"\"\"\n",
    "    path = os.path.join(models_path, str(run_num), \"config.json\")\n",
    "    if not os.path.exists(path):\n",
    "        print(\"Path does not exist: %s\" % path)\n",
    "        return None\n",
    "    try:\n",
    "        with open(path, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Malformed JSON: %s\" % path)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_all_config_json(models_path):\n",
    "    \"\"\"\n",
    "    Looks in `models_path` and finds all instances of\n",
    "    `{models_path}/{run_num}/config.json`, returning a dictionary that maps\n",
    "    `{run_num}` to the config dictionary.\n",
    "    \"\"\"\n",
    "    all_config = {run_num : import_config_json(models_path, run_num) for run_num in os.listdir(models_path)}\n",
    "    all_config = {key : val for key, val in all_config.items() if val}  # Remove empties\n",
    "    return all_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metrics_values(metrics, key):\n",
    "    \"\"\"\n",
    "    From a single metrics dictionary (i.e. the imported metrics.json for a\n",
    "    single run), extracts the set of values with the given key.\n",
    "    \"\"\"\n",
    "    return metrics[key][\"values\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metrics_values_at_best_run(all_metrics, key):\n",
    "    \"\"\"\n",
    "    From a metrics dictionary of all runs (i.e. the imported metrics from\n",
    "    `import_all_metrics_json`, extracts the set of values with the given key,\n",
    "    but only for the run that yielded the minimal validation loss. Returns\n",
    "    the run number, epoch number, and the metric values.\n",
    "    \"\"\"\n",
    "    if model_type == \"binary\":\n",
    "        val_key = \"val_corr_losses\"\n",
    "    else:\n",
    "        val_key = \"val_prof_corr_losses\"\n",
    "    best_run, best_epcoh, best_val = None, None, None\n",
    "    for run in all_metrics:\n",
    "        metrics = all_metrics[run]\n",
    "        vals = np.mean(extract_metrics_values(metrics, val_key), axis=1)\n",
    "        epoch = np.argmin(vals)\n",
    "        val = vals[epoch]\n",
    "        if best_val is None or val < best_val:\n",
    "            best_run, best_epoch, best_val = run, epoch + 1, val\n",
    "    return best_run, best_epoch, extract_metrics_values(all_metrics[best_run], key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_signal(signal, sigma, axis=-1):\n",
    "    \"\"\"\n",
    "    Smooths a signal along the given axis using a Gaussian weight vector.\n",
    "    Smooths to 1 sigma (unless sigma is 0, and then it does no smoothing).\n",
    "    \"\"\"\n",
    "    if sigma == 0:\n",
    "        return scipy.ndimage.gaussian_filter1d(signal, 1, axis=axis, truncate=0)\n",
    "    else:\n",
    "        return scipy.ndimage.gaussian_filter1d(signal, sigma, axis=axis, truncate=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot training statistics tracked through time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noprior_metrics = import_all_metrics_json(noprior_models_path)\n",
    "prior_metrics = import_all_metrics_json(prior_models_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation correctness losses with vs without the prior\n",
    "if model_type == \"binary\":\n",
    "    train_key = \"train_corr_losses\"\n",
    "    val_key = \"val_corr_losses\"\n",
    "else:\n",
    "    train_key = \"train_prof_corr_losses\"\n",
    "    val_key = \"val_prof_corr_losses\"\n",
    "\n",
    "noprior_train_corr_losses = {key : extract_metrics_values(m, train_key) for key, m in noprior_metrics.items()}\n",
    "prior_train_corr_losses = {key : extract_metrics_values(m, train_key) for key, m in prior_metrics.items()}\n",
    "noprior_val_corr_losses = {key : extract_metrics_values(m, val_key) for key, m in noprior_metrics.items()}\n",
    "prior_val_corr_losses = {key : extract_metrics_values(m, val_key) for key, m in prior_metrics.items()}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "for key, corr_losses in noprior_train_corr_losses.items():\n",
    "    noprior_train_line, = ax.plot(np.nanmean(corr_losses, axis=1), color=\"forestgreen\", linestyle=\":\", alpha=0.7)\n",
    "for key, corr_losses in prior_train_corr_losses.items():\n",
    "    prior_train_line, = ax.plot(np.nanmean(corr_losses, axis=1), color=\"purple\", linestyle=\":\", alpha=0.7)\n",
    "for key, corr_losses in noprior_val_corr_losses.items():\n",
    "    noprior_val_line, = ax.plot(np.nanmean(corr_losses, axis=1), color=\"coral\", alpha=0.7)\n",
    "for key, corr_losses in prior_val_corr_losses.items():\n",
    "    prior_val_line, = ax.plot(np.nanmean(corr_losses, axis=1), color=\"royalblue\", alpha=0.7)\n",
    "ax.legend(\n",
    "    [noprior_train_line, noprior_val_line, prior_train_line, prior_val_line],\n",
    "    [\n",
    "        \"Training loss without prior\", \"Validation loss without prior\",\n",
    "        \"Training loss with Fourier prior\", \"Validation loss with Fourier prior\"\n",
    "    ]\n",
    ")\n",
    "if model_type == \"binary\":\n",
    "    title = \"Correctness loss without/with Fourier priors\"\n",
    "else:\n",
    "    title = \"Histogram of validation profile NLL loss without/with Fourier priors\"\n",
    "title += \"\\n%s, %d/%d %s models\" % (condition_name, len(noprior_metrics), len(prior_metrics), model_type)\n",
    "ax.set_title(title)\n",
    "ax.set_xlabel(\"Epoch number\")\n",
    "xticks = np.arange(0, np.max(ax.get_xticks())).astype(int)\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(xticks + 1)\n",
    "if model_type == \"binary\":\n",
    "    ax.set_ylabel(\"Cross-entropy loss\")\n",
    "else:\n",
    "    ax.set_ylabel(\"Profile NLL loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation correctness losses with vs without the prior\n",
    "if model_type == \"binary\":\n",
    "    train_key = \"train_corr_losses\"\n",
    "    val_key = \"val_corr_losses\"\n",
    "else:\n",
    "    train_key = \"train_prof_corr_losses\"\n",
    "    val_key = \"val_prof_corr_losses\"\n",
    "\n",
    "noprior_best_run, noprior_best_epoch, noprior_train_corr_losses = extract_metrics_values_at_best_run(noprior_metrics, train_key)\n",
    "prior_best_run, prior_best_epoch, prior_train_corr_losses = extract_metrics_values_at_best_run(prior_metrics, train_key)\n",
    "_, _, noprior_val_corr_losses = extract_metrics_values_at_best_run(noprior_metrics, val_key)\n",
    "_, _, prior_val_corr_losses = extract_metrics_values_at_best_run(prior_metrics, val_key)\n",
    "\n",
    "print(\"Best run/epoch without prior: run %s, epoch %d\" % (noprior_best_run, noprior_best_epoch))\n",
    "print(\"Best run/epoch with priors: run %s, epoch %d\" % (prior_best_run, prior_best_epoch))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "noprior_train_line, = ax.plot(np.nanmean(noprior_train_corr_losses, axis=1), color=\"forestgreen\", linestyle=\":\")\n",
    "prior_train_line, = ax.plot(np.nanmean(prior_train_corr_losses, axis=1), color=\"purple\", linestyle=\":\")\n",
    "noprior_val_line, = ax.plot(np.nanmean(noprior_val_corr_losses, axis=1), color=\"coral\")\n",
    "prior_val_line, = ax.plot(np.nanmean(prior_val_corr_losses, axis=1), color=\"royalblue\")\n",
    "plt.legend(\n",
    "    [noprior_train_line, noprior_val_line, prior_train_line, prior_val_line],\n",
    "    [\n",
    "        \"Training loss without prior\", \"Validation loss without prior\",\n",
    "        \"Training loss with Fourier prior\", \"Validation loss with Fourier prior\"\n",
    "    ]\n",
    ")\n",
    "if model_type == \"binary\":\n",
    "    title = \"Correctness loss without/with Fourier priors of best run\"\n",
    "else:\n",
    "    title = \"Histogram of validation profile NLL loss without/with Fourier priors\"\n",
    "title += \"\\nComparison of best-performing %s %s models\" % (condition_name, model_type)\n",
    "ax.set_title(title)\n",
    "ax.set_xlabel(\"Epoch number\")\n",
    "xticks = np.arange(0, np.max(ax.get_xticks())).astype(int)\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(xticks + 1)\n",
    "if model_type == \"binary\":\n",
    "    ax.set_ylabel(\"Cross-entropy loss\")\n",
    "else:\n",
    "    ax.set_ylabel(\"Profile NLL loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best validation loss without prior: %f\" % np.min(np.nanmean(noprior_val_corr_losses, axis=1)))\n",
    "print(\"Best validation loss with prior: %f\" % np.min(np.nanmean(prior_val_corr_losses, axis=1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
