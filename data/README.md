### `raw/`
Links to `/mnt/lab_data2/amtseng/att_priors/data/raw/`
- `DREAM/`
	- This contains the directly dowloaded ChIP-seq runs for selected transcription factors from the ENCODE-DREAM challenge
	- `DREAM_data_to_use.tsv` contains the files that are downloaded from the repository, and the original paths of each file from Synapse
	- `labels/` contains the actual labels
	- Downloaded from [Synapse repository](https://www.synapse.org/#!Synapse:syn6112317)
	- Downloads are done by `download_DREAM_data.sh`
	- Each TF training set is a set of genomic coordinates of length 200, and whether or not the TF is bound in a set of cell lines; the 200bp buckets are strided by 50 over the entire genome
	- The following is the key for each track:
		B = Bound
		U = Unbound
		A = Ambiguous
	- The held-out set is by chromosome
		- In each training set, chr1, chr8, and chr21 are missing from the coordinates
		- The held-out set has the bound state for these three chromosomes, for the same cell lines
	- For some TFs, there is an additional held-out set by cell-line
		- For these held-out sets, the bound state is given for the three chromosomes missing from the training set (i.e. chr1, chr8, and chr21), for a completely new cell line not seen in the training set
		- These are named "cell_holdout" instead
	- The data combined in the training and holdout sets are in the "all" set
		- Generated using the following code:
			```
			zcat $tf/$tf\_train_labels.bed.gz | awk 'NR > 1' | gzip > $tf/$tf\_all_labels.bed.gz.tmp
			zcat $tf/$tf\_holdout_labels.bed.gz | awk 'NR > 1' | gzip >> $tf/$tf\_all_labels.bed.gz.tmp
			zcat $tf/$tf\_train_labels.bed.gz | head -n 1 | gzip > $tf/$tf\_all_labels.bed.gz
			zcat $tf/$tf\_all_labels.bed.gz.tmp | bedtools sort | gzip >> $tf/$tf\_all_labels.bed.gz
			```
- `ENCODE/`
	- Contains ChIP-seq data fetched from ENCODE
	- `encode_tf_chip_experiments.tsv`
		- A metadata file listing various experiments from ENCODE, filtered for those that are TF-ChIPseq experiments, aligned to hg38, and status released (and not retracted, for example)
		- Downloaded with the following command:
			```
			wget -O encode_tf_chip_experiments.tsv "https://www.encodeproject.org/report.tsv?type=Experiment&status=released&assay_slims=DNA+binding&assay_title=TF+ChIP-seq&assembly=GRCh38"
			```
	- `encode_control_chip_experiments.tsv`
		- A metadata file listing various control experiments from ENCODE (i.e. for a particular cell-line, a ChIP-seq experiment with no immunoprecipitation), filtered for those that are aligned to hg38 and have a status of released
		- Downloaded with the following command:
			```
			wget -O encode_control_chip_experiments.tsv "https://www.encodeproject.org/report.tsv?type=Experiment&status=released&assay_slims=DNA+binding&assay_title=Control+ChIP-seq&assembly=GRCh38"
			```
	- `encode_tf_chip_files.tsv`
		- A metadata file listing various ENCODE files, filtered for those that are aligned to hg38, status released, and of the relevant output types (i.e. filtered alignments, called peaks, and optimal IDR-filtered peaks)
		- Downloaded with the following commands:
			```
			FIRST=1; for otype in "alignments" "peaks and background as input for IDR" "optimal IDR thresholded peaks"; do wget -O - "https://www.encodeproject.org/report.tsv?type=File&status=released&assembly=GRCh38&output_type=$otype" | awk -v first=$FIRST '(first == 1) || NR > 2' >> encode_tf_chip_files.tsv; FIRST=2; done
			```
		- The API for the download of the experiment and files metadata is described [here](https://app.swaggerhub.com/apis-docs/encodeproject/api/basic_search/)
	- The files for each TF are downloaded by `download_ENCODE_data.py`

### `processed/`
Links to `/mnt/lab_data2/amtseng/att_priors/data/processed/`
- Raw data that has been processed to its final form to be used for training
- `DREAM/`
	- `labels/`
		- Since the downloaded DREAM datasets are already formatted and processed in a way that is ready for training, this is a link to the same data under `raw/`, for convenience
	- `tests/`
		- Some smaller files based on DREAM data that serve as simple tests
		- `TF_test_n.bed.gz`, where `n` is an integer, are random samples of the validation set for that TF, where the positives and negatives are sampled somewhat evenly
		- `TF_chri.bed.gz` is the entire chromosome for that TF
	- `config/`
		- Config files for training specific TF datasets
- `ENCODE/`
	- `binary/`
		- Processed data needed to train binary models
		- `labels/`
			- Labels generated by the peaks from `raw/`, using `generate_ENCODE_binary_labels.sh`
		- `randomized_labels/`
			- Contains data with the labels randomized; this is based on an existing dataset so the relative quantities of positives and negatives are the same
			- Created using `randomize_binary_dataset.py`
		- `tests/`
			- Some smaller files based on DREAM data that serve as simple tests
			- `TF_test_n.bed.gz`, where `n` is an integer, are random samples of the validation set for that TF, where the positives and negatives are sampled somewhat evenly
		- `config/`
			- Config files for training specific TF datasets
	- `profile/`
		- Processed data needed to train profile models
		- `labels/`
			- Labels generated by the alignments and peaks from `raw/`, using `generate_ENCODE_profile_labels.sh`
			- In addition to bedTools, this script also requires bedGraphToBigWig from UCSC Tools, as well as the [hg38 chromosome sizes with chrEBV included](https://github.com/ENCODE-DCC/encValData/blob/master/GRCh38/GRCh38_EBV.chrom.sizes)
		- `randomized_labels/`
		- `tests/`
			- Some smaller files based on DREAM data that serve as simple tests
		- `config/`
			- Config files for training specific TF datasets
