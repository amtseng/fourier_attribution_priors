### `raw/`
Links to `/mnt/lab_data2/amtseng/att_priors/data/raw/`
- `DREAM/`
	- This contains the directly dowloaded ChIP-seq runs for selected transcription factors from the ENCODE-DREAM challenge
	- `DREAM_data_to_use.tsv` contains the files that are downloaded from the repository, and the original paths of each file from Synapse
	- `labels/` contains the actual labels
	- Downloaded from [Synapse repository](https://www.synapse.org/#!Synapse:syn6112317)
	- Downloads are done by `download_DREAM_data.sh`
	- Each TF training set is a set of genomic coordinates of length 200, and whether or not the TF is bound in a set of cell lines; the 200bp buckets are strided by 50 over the entire genome
	- The following is the key for each track:
		B = Bound
		U = Unbound
		A = Ambiguous
	- The held-out set is by chromosome
		- In each training set, chr1, chr8, and chr21 are missing from the coordinates
		- The held-out set has the bound state for these three chromosomes, for the same cell lines
	- For some TFs, there is an additional held-out set by cell-line
		- For these held-out sets, the bound state is given for the three chromosomes missing from the training set (i.e. chr1, chr8, and chr21), for a completely new cell line not seen in the training set
		- These are named "cell_holdout" instead
	- The data combined in the training and holdout sets are in the "all" set
		- Generated using the following code:
			```
			zcat $tf/$tf\_train_labels.bed.gz | awk 'NR > 1' | gzip > $tf/$tf\_all_labels.bed.gz.tmp
			zcat $tf/$tf\_holdout_labels.bed.gz | awk 'NR > 1' | gzip >> $tf/$tf\_all_labels.bed.gz.tmp
			zcat $tf/$tf\_train_labels.bed.gz | head -n 1 | gzip > $tf/$tf\_all_labels.bed.gz
			zcat $tf/$tf\_all_labels.bed.gz.tmp | bedtools sort | gzip >> $tf/$tf\_all_labels.bed.gz
			```
- `ENCODE/`
	- This contains the ChIP-seq peaks from ENCODE; the data was fetched from Sherlock:`/oak/stanford/groups/akundaje/projects/atlas/chip`
	- `ENCODE_data_to_use.tsv` contains the ID mapping, and is a subset of the table `augmented_withlinecounts_metadata_optimalandrelaxedpeaks_encodeprocessed.tsv` on Oak
		- It is simply all the entries in this large table for the TFs in `tf_list.txt`
		- Command: `cat augmented_withlinecounts_metadata_optimalandrelaxedpeaks_encodeprocessed.tsv | awk -F "\t" '$10 ~ /^(CEBPB|E2F6|GABPA|JUND|REST|SPI1|TEAD4|target_label)$/' > ENCODE_data_to_use.tsv`
	- Downloads are done by `download_ENCODE_data.py`

### `processed/`
Links to `/mnt/lab_data2/amtseng/att_priors/data/processed/`
- Raw data that has been processed to its final form to be used for training
- `DREAM/`
	- `labels/`
		- Since the downloaded DREAM datasets are already formatted and processed in a way that is ready for training, this is a link to the same data under `raw/`, for convenience
	- `tests/`
		- Some smaller files based on DREAM data that serve as simple tests
		- `TF_test_n.bed.gz`, where `n` is an integer, are random samples of the validation set for that TF, where the positives and negatives are sampled somewhat evenly
		- `TF_chri.bed.gz` is the entire chromosome for that TF
	- `config/`
		- Config files for training specific TF datasets
- `ENCODE/`
	- `labels/`
		- Labels generated by the peaks from `raw/`, using `generate_ENCODE_labels.sh` to get an HD5F file, then `hd5f_to_bed.py` to get a BED file; finally, this BED file is split into training and test set using `split_bed_train_val.sh`
	- `randomized_labels/`
		- Contains data with the labels randomized; this is based on an existing dataset so the relative quantities of positives and negatives are the same
		- Created using `randomize_dataset.py`
	- `tests/`
		- Some smaller files based on DREAM data that serve as simple tests
		- `TF_test_n.bed.gz`, where `n` is an integer, are random samples of the validation set for that TF, where the positives and negatives are sampled somewhat evenly
	- `config/`
		- Config files for training specific TF datasets
